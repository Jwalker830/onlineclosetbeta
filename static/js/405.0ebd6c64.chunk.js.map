{"version":3,"file":"static/js/405.0ebd6c64.chunk.js","mappings":"iFAgCA,IAAIA,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBG,EAAeH,EAAS,KAwC5BI,EAAOC,QA3BY,SAAWC,EAAOC,EAAUC,EAAKC,GAClD,IAEIC,EAFAC,EAASJ,EAAUD,GACnBM,EAAUH,GAAQP,EAAQW,WAAWC,IAAKL,GAAWA,EAAOV,EAAIgB,MAGpE,OAAKH,IAAUb,EAAIW,SAEjBA,EAASM,OAAOC,OAAQ,OACjBF,MAAQZ,EAAcQ,EAAQ,GAAKA,EAAQ,GAAKH,EAAKT,EAAIgB,MAAOd,EAAGiB,MAC1ER,EAAOS,KAAOR,EAAQ,GACfD,GAGJE,IAAUb,EAAIoB,KAEVR,EAAQ,GAGZC,IAAUb,EAAIqB,KAEVrB,EAAIqB,KAAMT,GAIZR,EAAcQ,EAAQ,GAAKA,EAAQ,GAAKH,EAAKI,EAAOX,EAAGiB,KAChE,C,gBCzCA,IAAIG,EAAYrB,EAAS,MAGrBsB,EAASD,EAAUC,OAEnBC,EAASF,EAAUE,OAQvBnB,EAAOC,QANiB,SAAWC,EAAOE,GACtC,IACIgB,EADQhB,EAAIiB,OAAUnB,EAAQgB,EAAW,GACzBC,EACpB,OAASC,EAAQ,MAAa,GAAGE,OAAQF,GAAYhB,EAAImB,kBAAmBrB,EAChF,C,gBCXA,MAAMe,EAAYrB,EAAS,MAErB4B,EAAaP,EAAUO,WAEvBC,EAAUR,EAAUQ,QAEpBP,EAASD,EAAUC,OAqFvBlB,EAAOC,QAzEsB,SAAWG,GAEtC,MAAMsB,EAAed,OAAOC,OAAO,MACnCa,EAAaC,KAAM,EACnBD,EAAaE,KAAM,EACnBF,EAAaG,MAAO,EACpBH,EAAaI,MAAO,EACpBJ,EAAaK,OAAQ,EACrBL,EAAaM,MAAO,EACpBN,EAAaO,KAAM,EACnBP,EAAaQ,KAAM,EAEnB,MACMC,EAAY/B,EAAI+B,UAChBd,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MAKZC,EAAsBzB,OAAOC,OAAQ,MAE3C,IAAM,IAAIyB,EAAI,EAAGA,EAAIH,EAAUI,OAAQD,GAAK,EAAI,CAC9C,MAAME,EAAM,IACJC,EAAOC,GAAQP,EAAWG,GAClC,IAAM,IAAIK,EAAIF,EAAOE,GAAKD,EAAKC,GAAK,EAAI,CACtC,MAAMC,EAAIR,EAAMS,QAAS,OAASxB,EAAUsB,EAAIzB,EAAW,GAAMO,KAAcD,GACpE,UAANoB,GAAuB,UAANA,GAAgBJ,EAAIM,KAAMF,EAClD,CAGA,KAAKJ,EAAID,OAAS,GAElB,IAAM,IAAIQ,EAAI,EAAGA,EArBL,EAqBiB,EAAIP,EAAID,OAAQQ,GAAK,EAAI,CACpD,MAAMC,EAAWR,EAAIS,MAAOF,EAAGA,EAtBrB,GAwBJG,EAAkBF,EAASG,QAC/B,CAAEC,EAAIC,IAAQD,GAAS1B,EAAa2B,GAAQ,EAAI,IAChD,GAEIC,EAAWN,EAASO,KAAM,KAChClB,EAAqBiB,GAAajB,EAAqBiB,IAAc1C,OAAOC,OAAQ,MACpFwB,EAAqBiB,GAAWE,MAAQF,EACxCjB,EAAqBiB,GAAWnB,UAAYE,EAAqBiB,GAAWnB,WAAa,GACzFE,EAAqBiB,GAAWnB,UAAUW,KAAMR,GAChDD,EAAqBiB,GAAWG,YAAsDC,IAA3CrB,EAAqBiB,GAAWG,OACjCP,EAAkB,EAChBb,EAAqBiB,GAAWG,OAAS,EACrFpB,EAAqBiB,GAAWK,GAAKT,CACvC,CACF,CAGA,MAAMU,EAAkBhD,OAAOiD,KAAMxB,GACVyB,KAAOC,GAAO1B,EAAqB0B,KACnCC,QAAUD,GAAOA,EAAEN,OAAS,IAGjDQ,EAAsB,IAAIC,MAAO/B,EAAUI,QACjD0B,EAAoBE,KAAM,GAC1BP,EAAgBQ,SAAWC,IACzBA,EAAIlC,UAAUiC,SAAWL,IACtBE,EAAqBF,IAAOM,EAAIZ,MAAM,GACpC,IAGP,IAAIa,EAAMC,KAAKD,OAAQL,GAIvB,OAFa,IAARK,IAAYA,EAAM,GAEhBL,EAAoBH,KAAK,CAAEC,EAAGS,KAAC,CAAUtE,MAAOsE,EAAGC,aAAeV,EAAIO,GAAMI,QAAS,MAC9F,C,gBCzFF,IAAIC,EAAU/E,EAAS,MACnBgF,EAAoBhF,EAAS,MAC7BC,EAAKe,OAAOC,OAAQ,MAUxBhB,EAAGgF,MAAQ,SAAWxD,GAEpB,OAAOA,CACT,EAUAxB,EAAGiF,IAAM,SAAWzD,GAElB,OAAO,IAAI0D,IAAK1D,EAClB,EAYAxB,EAAGmF,IAAM,SAAW3D,GAElB,IACIsB,EADAqC,EAAMpE,OAAOC,OAAQ,MAEzB,IAAM,IAAI2D,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAK,EAEvCQ,EADArC,EAAItB,EAAQmD,IACD,GAAMQ,EAAKrC,IAAO,GAG/B,OAAOqC,CACT,EAWAnF,EAAGoF,UAAY,SAAW5D,GAOxB,IALA,IAAI2D,EAAMnF,EAAGmF,IAAK3D,GACdwC,EAAOjD,OAAOiD,KAAMmB,GACpBzC,EAASsB,EAAKtB,OACd2C,EAAQ,IAAIhB,MAAO3B,GAEbiC,EAAI,EAAGA,EAAIjC,EAAQiC,GAAK,EAChCU,EAAOV,GAAM,CAAEX,EAAMW,GAAKQ,EAAKnB,EAAMW,KAGvC,OAAOU,EAAMC,KAAMR,EACrB,EAWA9E,EAAGuF,QAAU,SAAW/D,GAEtB,IAEImD,EAAGa,EAFHC,EAAM,GAIV,IAAMd,EAAI,EAAGa,EAAOhE,EAAOkB,OAAS,EAAGiC,EAAIa,EAAMb,GAAK,EACpDc,EAAIxC,KAAM,CAAEzB,EAAQmD,GAAKnD,EAAQmD,EAAI,KAEvC,OAAOc,CACT,EAEAzF,EAAG0F,OAAS,SAAWlE,GACrB,OAAO6C,MAAMsB,KAAM,IAAIT,IAAK1D,GAC9B,EAYAxB,EAAGiB,KAAO,SAAW2E,GAEnB,OAAOA,EAAKlC,KAAM,IAAKmC,MACzB,EAeA7F,EAAG8F,aAAe,SAAWF,EAAMrF,EAAKqC,EAAOC,GAE7C,MAAMkD,EAAWxF,EAAIwF,SAErB,IAAIC,EAAiB,EAARpD,EAETqD,EAAQlB,EAAmBgB,EAAUnD,EAAOC,GAChD,GAAe,OAAVoD,EAEH,OAAOL,EAAKlC,KAAM,IAAKmC,OAIzB,IAAM,IAAIlB,EAAIsB,EAAMC,KAAMvB,GAAKsB,EAAME,MAAOxB,GAAK,EAAI,CACnD,MAAMyB,EAAiC,EAArBL,EAAUpB,GAAK,GAAYqB,EAAW,EAClDK,EAAiC,EAArBN,EAAUpB,GAAK,GAAYqB,EAAW,EAClDM,OAAwCzC,IAAxBkC,EAAUpB,GAAK,GAAuB,SAAWoB,EAAUpB,GAAK,GAChF4B,OAAsC1C,IAAxBkC,EAAUpB,GAAK,GAAuB,UAAYoB,EAAUpB,GAAK,GAErFiB,EAAMQ,GAAUE,EAAcV,EAAMQ,GACpCR,EAAMS,IAAUE,CAClB,CAGA,OAAOX,EAAKlC,KAAM,IAAKmC,MACzB,EAEA7F,EAAGwG,OAAS,SAAWhF,EAAQjB,GAC7B,IAAMA,EAAIkG,YACR,MAAMC,MAAO,uGAGf,MAAMC,EAAOpG,EAAIkG,YAAYG,WACvBC,EAAYtG,EAAIkG,YAAYI,UAC5BC,EAAUvG,EAAIkG,YAAYK,QAC1BC,EAAcxG,EAAIkG,YAAYM,YAG9BC,EAAI,IAAI3C,MAAOsC,GACrBK,EAAE1C,KAAM,GAGR,IAAI2C,EAAc,EAClB,IAAM,IAAItC,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAK,EAAI,CAE3C,MAAMuC,EAAKJ,EAAStF,EAAQmD,GAAIwC,oBAKpBtD,IAAPqD,GAA0C,IAAtBA,EAAIH,KAAsBE,GAAe,GAClE,IAAM,IAAIG,EAAI,EAAGA,EAAIT,EAAMS,GAAK,EAE9BJ,EAAGI,SAAgBvD,IAAPqD,EAAqB,EAAIA,EAAIE,EAE7C,CAGA,GAAqB,IAAhBH,EAGH,OADAD,EAAE/D,KAAM,GACD+D,EAKT,IAAIK,EAAS,EACb,IAAM,IAAI1C,EAAI,EAAGA,EAAIgC,EAAMhC,GAAK,EAC9BqC,EAAGrC,KAASqC,EAAGrC,GAAMsC,GAAcpC,QAASgC,GAC5CQ,GAAUL,EAAGrC,GAAMqC,EAAGrC,GAKxB,OAFAqC,EAAE/D,MAASyB,KAAK4C,KAAMD,GAASxC,QAASgC,IAEjCG,CACT,EAEA7G,EAAOC,QAAUJ,C,gBC7MjB,IAAIuH,EAAiBxH,EAAS,MAC1ByH,EAAMzH,EAAS,MACf0H,EAAQ1H,EAAS,KACjB2H,EAAY3H,EAAS,MACrB4H,EAAc5H,EAAS,MACvB6H,EAAU7H,EAAS,MACnB8H,EAAa9H,EAAS,MACtB+H,EAAY/H,EAAS,KACrBgI,EAA2BH,EAAQG,yBACnCC,EAA+BJ,EAAQI,6BAEvCC,EAAWlI,EAAS,MAEpBqB,EAAYrB,EAAS,MAErBmI,EAAMnI,EAAS,MAEfoI,EAASpI,EAAS,MAClBqI,EAASrI,EAAS,MAElBsI,EAAStI,EAAS,MAGlBsB,EAASD,EAAUC,OA4avBlB,EAAOC,QA9ZG,SAAWkI,GAA+C,IAArCC,EAAIC,UAAA9F,OAAA,QAAAmB,IAAA2E,UAAA,GAAAA,UAAA,GAAG,KAAMC,EAAcD,UAAA9F,OAAA,QAAAmB,IAAA2E,UAAA,GAAAA,UAAA,GAAG,KAE3D,IAEIE,EAEAC,EAEApG,EAIAqG,EAGAC,EACAC,EAEAC,EACAC,EACAC,EAEAC,EACAC,EAEAC,EACAC,EAEAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EAEAC,EACAC,EAEAC,EAEAC,EAvCAC,EAAUjJ,OAAOC,OAAQ,MAiCzBiJ,EAAe,EASfC,EAAmBnJ,OAAOC,OAAQ,MAGlCmJ,EAAWpJ,OAAOC,OAAQ,MAC1BoJ,GAAmB,EA2RvB,IAAK/B,EAAOgC,SAAU/B,GAKpB,MAAM5B,MAAO,iCAJb,GAA8B,oBAAlB4B,EAASgC,KACnB,MAAM5D,MAAO,iCAejB,GAPAwD,EAAiBK,IAA8B,oBAAjBjC,EAASiC,IACvCL,EAAiBM,SAAwC,oBAAtBlC,EAASkC,SAC5CN,EAAiBO,UAAmC,oBAAhBnC,EAASoC,GAC7CR,EAAiBvH,IAA8B,oBAAjB2F,EAAS3F,IACvCuH,EAAiBS,IAA8B,oBAAjBrC,EAASqC,IACvCT,EAAiBU,IAAkC,oBAArBtC,EAASuC,QAEf,OAAnBpC,EAA0B,CAC7B,IAAMJ,EAAOgC,SAAU5B,GACrB,MAAM/B,MAAO,gFAAgF+B,OAE/F,IAAIqC,EAAY,EAChB,MAAMC,EAAiBhK,OAAOC,OAAQ,MACtC+J,EAAelE,WAAY,EAC3BkE,EAAehE,aAAc,EAC7BgE,EAAeC,WAAY,EAC3BD,EAAenE,YAAa,EAC5BmE,EAAeE,WAAY,EAC3BF,EAAepE,MAAO,EACtBoE,EAAeG,OAAQ,EACvBH,EAAejE,SAAU,EACzB,IAAM,MAAMqE,KAAO1C,EAEjB,GADAqC,GAAa,GACPC,EAAgBI,GACpB,MAAMzE,MAAO,0CAGjB,GAAmB,IAAdoE,EAAkB,MAAMpE,MAAO,sCACtC,CAEA,MAAM0E,EAAsB,OAAT7C,QAA0B1E,IAAT0E,EAAuBxH,OAAOiD,KAAMkG,GAAqB3B,EAC7F,IAAKF,EAAOgD,QAASD,GAMd,MAAM1E,MAAO,uEAAuE6B,OAiC3F,OAtCE6C,EAAS7G,SAAW+G,IAClB,IAAMpB,EAAkBoB,GAAO,MAAM5E,MAAO,sCAAsC4E,aAClFnB,EAAUmB,IAAO,EACjBlB,GAAmB,CAAK,IA3TjB,WAETzB,EAAQL,EAASgC,OAEjB/H,EAAQkF,EAAOkB,EAAOL,EAASiD,WAC/B7C,EAAOf,EAAagB,EAAMD,MAG1BE,EAAWlB,EAAWgB,EAAMC,EAAM6C,KAAKC,KAAM9C,EAAM+C,UAGnD,IAAIC,EAAWrD,EAASiC,MAExBxB,EAAc,IAAI1E,MAAOsH,EAASC,SAASlJ,QAC3CsG,EAAkB,IAAI3E,MAAOsH,EAASC,SAASlJ,QAC/C,IAAM,IAAIiC,EAAI,EAAGA,EAAIgH,EAASC,SAASlJ,OAAQiC,GAAK,EAClDoE,EAAapE,GAAMuD,EAAK3F,GACxBwG,EAAapE,GAAIkH,WAAYF,EAASC,SAAUjH,IAChDqE,EAAiBrE,GAAMgH,EAASG,aAAcnH,GAEhDsE,EAAY0C,EAASI,OAGrB,IAAIC,EAAW1D,EAASqC,MAExB9B,EAAc,IAAIxE,MAAO2H,EAASJ,SAASlJ,QAC3CoG,EAAkB,IAAIzE,MAAO2H,EAASJ,SAASlJ,QAC/C,IAAM,IAAIiC,EAAI,EAAGA,EAAIqH,EAASJ,SAASlJ,OAAQiC,GAAK,EAClDkE,EAAalE,GAAMuD,EAAK3F,GACxBsG,EAAalE,GAAIkH,WAAYG,EAASJ,SAAUjH,IAChDmE,EAAiBnE,GAAMqH,EAASF,aAAcnH,GAGhD,IAAIsH,EAAW3D,EAASkC,YACxBtB,EAAchB,EAAK3F,IACPsJ,WAAYI,EAASL,SAAU,IAC3CzC,EAAY8C,EAASF,OAErB,IAAIG,EAAU5D,EAASoC,MACvBtB,EAAalB,EAAK3F,IACPsJ,WAAYK,EAAQN,SAAU,IACzCvC,EAAW6C,EAAQH,OAEnB,IAAII,EAAW7D,EAAS3F,MACxB2G,EAAc,IAAIjF,MAAO8H,EAASP,SAASlJ,QAC3C6G,EAAkB,IAAIlF,MAAO2H,EAASJ,SAASlJ,QAC/C,IAAM,IAAIiC,EAAI,EAAGA,EAAIwH,EAASP,SAASlJ,OAAQiC,GAAK,EAElD2E,EAAa3E,GAAMuD,EAAK3F,EAAOA,EAAMzB,MAAO,IAC5CwI,EAAa3E,GAAIkH,WAAYM,EAASP,SAAUjH,IAChD4E,EAAiB5E,GAAMwH,EAASL,aAAcnH,GAEhD6E,EAAY2C,EAASJ,OACrBtC,EAAa0C,EAASC,QAGtB,IAAIC,EAAU/D,EAASuC,UACvBd,EAAesC,EAAQT,SACvBjC,EAAiB0C,EAAQP,aAAc,EAIzC,CAkQAQ,GAIAtC,EAAQuC,QAxPM,SAAWtL,GACvB,GAAqB,kBAATA,EACV,MAAMyF,MAAO,wEAAwEzF,OAGvF,IAAIV,EAAMQ,OAAOC,OAAQ,MAEzBT,EAAIgC,MAAQA,EAEZhC,EAAIkG,YAAcgC,EAUlBlI,EAAIiB,OAAS,GAEbjB,EAAI+B,UAAY,GAGhB/B,EAAIwF,SAAW,GAGfxF,EAAI4J,SAAWA,EAEf5J,EAAImB,kBAAoBX,OAAOC,OAAQ,MAEvC,IAAIwL,EAAiBjF,EAAgBhH,GAGrCqI,EAAU4D,EAAgBvL,GAE1BV,EAAI0G,YAAc1G,EAAIiB,OAAOkB,OAASrB,EAGtCd,EAAIkM,SAAW,CAAE,EAAKlM,EAAI0G,YAAc,EAAK,EAAG,GAGhD,IAEIyF,EAFAC,EAAoBvC,EAAqB,KAAOrC,EAA0BxH,GAG9E,GAAK4J,EAASI,IAAM,CAGlBmC,EAAK,KACL,IAAM,IAAI/H,EAAI,EAAGA,EAAIoE,EAAYrG,OAAQiC,GAAK,EAC5CoE,EAAapE,GAAIiI,eAAgBF,GAEjCA,EAAK3D,EAAapE,GAAIkI,UAAWF,EAAiB3D,EAAiBrE,GAAKpE,EAAIiB,QAI9EyH,EAAWyD,EAAInM,GAEfA,EAAIuM,eAAiBvM,EAAI+B,UAAUI,MACrC,MAEEnC,EAAIuM,eAAiB,EACrBvM,EAAI+B,UAAY,CAAE,CAAE,EAAK/B,EAAI0G,YAAc,EAAK,EAAG,IAGrD,GAAKkD,EAASQ,IAAM,CAElB+B,EAAK,KACL,IAAM,IAAI/H,EAAI,EAAGA,EAAIkE,EAAYnG,OAAQiC,GAAK,EAC5CkE,EAAalE,GAAIiI,eAAgBF,GACjCA,EAAK7D,EAAalE,GAAIkI,UAAWF,EAAiB7D,EAAiBnE,IAIrEpE,EAAID,SAAWoM,CACjB,MACEnM,EAAID,SAAW,GAiBjB,GAdK6J,EAASK,WAEZkC,EAAK,KACLA,EAAKxD,EAAY2D,UAAWF,GAC5BxD,EAAWuD,EAAInM,EAAKa,EAAW+G,IAG5BgC,EAASM,YAEZiC,EAAK,KACLA,EAAKtD,EAAWyD,UAAWF,GAC3BtD,EAAUqD,EAAInM,EAAKa,EAAWgH,IAG3B+B,EAASxH,IAAM,CAElB,MAAMoK,EAAU/E,EAA8BzH,GAC9CmM,EAAK,KACL,IAAM,IAAI/H,EAAI,EAAGA,EAAI2E,EAAY5G,OAAQiC,GAAK,EAC5C+H,EAAKpD,EAAa3E,GAAIkI,UAAWE,EAASxD,EAAiB,GAAKhJ,EAAIiB,QACpEiI,EAAYiD,EAAInK,EAAOwK,EAASJ,GAElCnD,EAAWjJ,EAAKwM,EAAS1L,EAAQD,EAAUO,WAC7C,CAEKwI,EAASS,KAEZ8B,EAAK,UACgB7I,IAAhB6F,GAA6BO,EAAe,IAC/CJ,EAAUtJ,IAAMA,EAChBsJ,EAAU6B,SAAW9B,EACrBC,EAAUzI,UAAYA,EACjByI,EAAUmD,WAAYtD,EAAYkD,eAAgBrM,EAAID,UAC3DoM,EAAKhD,EAAYmD,UAAWF,EAAiBhD,EAAgBE,IAI/DtJ,EAAI0M,eAAiBP,GAAM,IACtBnM,EAAI0M,eAAiB,GAS5B,IAAIC,EAAM1F,EAAKjH,EAAK+H,EAAS6E,QAI7B,OADAX,EAAeY,QACRF,CACT,EAsHAlD,EAAQqD,oBApHkB,SAAWC,EAAUC,GAE7C,IAAKlF,EAAOgD,QAASiC,GAiCnB,MAAM5G,MAAO,gEAAgE4G,OAK/E,GArCEA,EAAS/I,SAAWiJ,IAClB,IAAKnF,EAAOgC,SAAUmD,GA0BpB,MAAM9G,MAAO,uEAAuE8G,UAAWC,KAAKC,UAAWF,EAAI,KAAM,MAxBzH,GAA0B,kBAAZA,EAAGG,MAAqC,KAAZH,EAAGG,KAC3C,MAAMjH,MAAO,qDAAqD8G,EAAGG,aAAaF,KAAKC,UAAWF,EAAI,KAAM,MACvG,IAAKnF,EAAOgD,QAASmC,EAAGI,UAU7B,MAAMlH,MAAO,gEAAgE8G,EAAGI,iBAAiBH,KAAKC,UAAWF,EAAI,KAAM,MAT3H,IAAM,IAAItK,EAAI,EAAGA,EAAIsK,EAAGI,SAASlL,OAAQQ,GAAK,EAAI,CAChD,MAAMH,EAAIyK,EAAGI,SAAU1K,GAEvB,GAAoB,kBAANH,GAA4B,KAANA,EAClC,MAAM2D,MAAO,6DAA6D3D,UAAU0K,KAAKC,UAAWF,EAAI,KAAM,KAElH,CAOF,QAAmB3J,IAAZ2J,EAAGK,QACDxF,EAAOyF,eAAgBN,EAAGK,OACR,IAAnBL,EAAGK,KAAKnL,QACW,IAAnB8K,EAAGK,KAAKnL,QAAgB8K,EAAGK,KAAM,GAAML,EAAGK,KAAM,IACtD,MAAMnH,MAAO,uFAAuF+G,KAAKC,UAAWF,EAAGK,KAAM,KAAM,KAKvI,IAQJhE,OAAyBhG,IAAX0J,GAAmC,OAAXA,EAAoBxM,OAAOC,OAAQ,MAASyM,KAAKM,MAAON,KAAKC,UAAWH,KACxGlF,EAAOgC,SAAUR,GACrB,MAAMnD,MAAO,+DAA+DmD,OAE9EA,EAAUmE,aAAenE,EAAUmE,WACnCnE,EAAUoE,YAAgCpK,IAArBgG,EAAUoE,UAAkCpE,EAAUoE,OAC3EpE,EAAUmD,eAAsCnJ,IAAxBgG,EAAUmD,aAAqCnD,EAAUmD,UAIjFlD,EAAW7B,EAAU8B,EAAcxH,EAAOqG,EAAUiB,EAAUmE,YAE9DtE,EAAc,KACdO,EAAe,EACfP,EAAcxB,IACd,MAAMgG,EAAWpE,EAASqE,IAAKb,GAI/B,OAHA1D,EAAcsE,EAASxC,SACvBzB,EAAeP,EAAY0E,MAAOF,EAASZ,SAG7C,EA2DAtD,EAAQlK,IAAM+H,EACdmC,EAAQhK,GAAK8H,EAEbkC,EAAQqE,SAAW,SAAWC,GAAqB,IAAfC,IAAI/F,UAAA9F,OAAA,QAAAmB,IAAA2E,UAAA,KAAAA,UAAA,GACtC,IAAMC,EACN,MAAM/B,MAAO,uGAEb,MAAMI,EAAU2B,EAAe3B,QACzBmE,EAAYxC,EAAewC,UAC3BuD,EAAY/F,EAAe1B,YAAc,EAE/C,GAAqB,kBAATuH,EACV,MAAM5H,MAAO,+CAGf,MAAMQ,EAAKJ,EAASwH,EAAKnH,eACzB,YAAYtD,IAAPqD,EAEMqH,EAAStD,EAAU7H,MAAO,EAAGoL,GAAcvD,EAAU7H,QAEvDmL,EAASrH,EAAG9D,MAAO,EAAGoL,GAActH,EAAG9D,OAClD,EAEO4G,CACT,C,gBCjcA,IAAI5I,EAAYrB,EAAS,MACrB0O,EAASrN,EAAUqN,OACnBC,EAAsBtN,EAAUsN,oBAChCC,EAASvN,EAAUuN,OACnBC,EAAiBxN,EAAUwN,eA+hB/BzO,EAAOC,QAjhBK,SAAWuI,EAAO4C,GAC5B,MAAMsD,EAAa,YAEnB,IAAI7E,EAAUjJ,OAAOC,OAAQ,MAEzB8N,EAAcnG,EAAMoG,SAASC,OAAOvD,KACpCwD,EAAMtG,EAAMoG,SAASC,OACrBE,EAAsBvG,EAAMoG,SAASC,OAAOG,cAC5CC,EAASzG,EAAM0G,QAAQD,OACvBE,EAAS3G,EAAM0G,QAAQ1I,KACvB4I,EAAS5G,EAAM0G,QAAQE,OACvBC,EAAS7G,EAAM0G,QAAQG,OACvBC,EAAaD,EAAO9M,OACpBgN,EAAU/G,EAAM+G,QAChBC,EAAYhH,EAAMgH,UAClBC,EAAcjH,EAAMoG,SAASa,YAAYC,KAQzCC,EAAmB,GAKnBC,EAAgB,EAAIR,EAIpBS,EAAU,IAAIC,YAAaV,GAE3BW,EAAU3E,EAAW5C,EAAM0G,QAAQ9B,QAInC4C,EAASpP,OAAOC,OAAQ,MAE5BmP,EAAOC,WAAY,EAEnBZ,EAAOjL,SAAW8L,GAAUF,EAAQE,IAAO,IAoB3C,IAAIC,EAAmB,SAAW3C,EAAM7M,GAEtC,IAAIyP,EAAI5H,EAAMoG,SAAUpB,GAEpB6C,EAAID,EAAE9E,KACNgF,EAAIF,EAAEV,KAENa,EAAa,EAEbrQ,EAAQmQ,EAAG1P,GAaf,YAZe+C,IAAVxD,IAMHA,EAAQmQ,EAAG1P,GAAUyP,EAAElQ,MAEvBkQ,EAAElQ,MAAQoQ,EAAExN,KAAMnC,GAElB4P,EAAa,GAER,CAAEA,EAAYrQ,EACvB,EAmGIsQ,EAAS,SAAW1P,GAEtB,IAKI2P,EAEAC,EAAIC,EAAIC,EAPRC,EAAuB5B,EAAO6B,cAC9BC,EAAe9B,EAAOwB,MAEtBvQ,EAAQyO,EAAa7N,GAOzB,QAAe4C,IAAVxD,EAAsB,OAAO,KAElC,IAAImB,EAAS,GAEb,GAAKnB,EAAQ6O,EAGX,IADkBQ,EAASsB,EAAsB,GAAQ3Q,EAAQiP,GAAa0B,EAAsB,MAAUA,EAAsB,GASlI,IAHAF,EAAa,OAFbF,GAAWlB,EAASwB,EAAc,GAAQ7Q,EAAQiP,GAAa4B,EAAc,MAAUA,EAAc,IAGrGL,GAAOD,EAAUjC,GAAUC,IAAsBA,EAE3CmC,EAAM,EAAGA,EAAMF,EAAIE,GAAO,EAC9BvP,EAAOyB,KACL0M,EAAWmB,EAAKC,GAChBD,EAAKC,EAAM,EACXpB,EAAWmB,EAAKC,EAAM,GACtBpB,EAAWmB,EAAKC,EAAM,SAK1BvP,EAAOyB,KAAM5C,QAIfmB,EAAOyB,KAAM5C,GAEf,OAAOmB,CACT,EA4HI2P,EAAW,SAAW9Q,EAAO+Q,GAE/B,IAAIC,EAEAC,EAEAC,EAKJ,GAAKlR,EAAQ6O,EAAsB,CAEjC,QAAsBrL,KADtB0N,EAAcnC,EAAQgC,IACY,OAAO,KACzCC,GAAe3B,EAAS6B,EAAa,GAAQlR,EAAQiP,GAAaiC,EAAa,MAAUA,EAAa,GAE5E,IAArBA,EAAa,IAAkC,IAArBA,EAAa,KAAYF,EAAY1I,EAAMoG,SAAUqC,GAAOvB,KAAMwB,GACnG,KAAO,CAEH,IAAMlB,EAAQiB,GAAS,OAAO,EAE9BE,EAASjR,EAAQ6O,EACjBqC,EAAcnC,EAAQgC,GAOtBC,GAAevB,EAAoBwB,EAASvB,EApW1B,EAoWgEwB,EAAa,IAAQA,EAAa,MAAUA,EAAa,GAEjH,IAArBA,EAAa,IAAkC,IAArBA,EAAa,KAAYF,EAAY1I,EAAMoG,SAAUqC,GAAOvB,KAAMwB,GACrG,CACA,OAAOA,CACT,EAEIG,EAAc,SAAWC,EAAWC,GAEtC,OAAO9B,EAAauB,EAAUM,EAAW,cAAgB5Q,KAAM6Q,EACjE,EAuIA,OAfA1H,EAAQ2H,IAxZE,SAAW1Q,EAAM2Q,GAEzB,IAOIC,EAAKtB,EAAGuB,EAAIC,EAAM7O,EAPlB8O,EAAW/Q,EAAKkG,cAEhB8K,EAAY3B,EAAkB,SAAUrP,GAExCiR,EAAcF,IAAa/Q,EAASgR,EAAY3B,EAAkB,SAAU0B,GAQhF,GAAKC,EAAW,GAAM,CAMpB,IAFAjC,EAAQ1L,KAAM,GAERpB,EAAI,EAAGA,EAAIuM,EAAYvM,GAAK,EAChCqN,EAAIf,EAAQtM,GACZ2O,EAAMzC,EAAQmB,GAEduB,EAAK5B,EAASK,GAAKtP,EAAM2Q,EAAU5H,GACnC+H,EAASF,EAAK,GAAQC,EAAKxB,EAAkBC,EAAGuB,GAAM,GACtD9B,EAAS6B,EAAK,KAAWE,GAAQF,EAAK,GAIxCA,EAAMzC,EADNmB,EAAI1B,GAEJmB,EAAS6B,EAAK,KAAWD,GAAYC,EAAK,GAG1C/B,EAAiB7M,KAAMiP,EAAW,GAAKA,EAAW,MAAQlC,EAC5D,CAIA,GAAKiC,EAAW,KAAQC,EAAW,IAE5BA,EAAW,GAAM,CAKpB,IAFAlC,EAAQ1L,KAAM,GAERpB,EAAI,EAAGA,EAAIuM,EAAYvM,GAAK,EAChCqN,EAAIf,EAAQtM,GACZ2O,EAAMzC,EAAQmB,GAEduB,EAAK5B,EAASK,GAAKyB,EAAUJ,EAAU5H,GACvC+H,EAASF,EAAK,GAAQC,EAAKxB,EAAkBC,EAAGuB,GAAM,GACtD9B,EAAS6B,EAAK,KAAWE,GAAQF,EAAK,GAIxCA,EAAMzC,EADNmB,EAAI1B,GAEJmB,EAAS6B,EAAK,KAAWD,GAAYC,EAAK,GAG1C/B,EAAiB7M,KAAMiP,EAAW,GAAKA,EAAW,MAAQlC,EAC5D,CAIF,OAASiC,EAAW,EACtB,EAuVAjI,EAAQ2G,OAASA,EACjB3G,EAAQlJ,MAlRI,SAAWT,GACrB,OAAO4O,EAAIY,KAAMxP,EACnB,EAiRA2J,EAAQmH,SAAWA,EACnBnH,EAAQmI,OAtQK,SAAW9R,GAEtB,IAQI6R,EARAE,EAAgBhD,EAAO+C,OACvBE,EAAgBjD,EAAOkD,iBACvBpB,EAAgB9B,EAAOwB,MAoC3B,OAzBKvQ,EAAQ6O,GACXgD,GAAcxC,EAAS0C,EAAe,GAAQ/R,EAAQiP,GAAa8C,EAAe,MAAUA,EAAe,IACtF1C,EAAS2C,EAAe,GAAQhS,EAAQiP,GAAa+C,EAAe,MAAUA,EAAe,GAIhHH,GAAcxC,EAASwB,EAAc,GAAQ7Q,EAAQiP,GAAa4B,EAAc,MAAUA,EAAc,GAGxGgB,GAAa7R,IAKf6R,EAAYpC,GAFHzP,EAAQ6O,GAEsBa,IAGtBb,IACMQ,EAAS2C,EAAe,GAAQH,EAAY5C,GAAa+C,EAAe,MAAUA,EAAe,KAEpHH,GAAcxC,EAASwB,EAAc,GAAQgB,EAAY5C,GAAa4B,EAAc,MAAUA,EAAc,IAK3GgB,CACT,EA8NAlI,EAAQuI,IAlLE,SAAWC,GACnB,OAAO7C,GAAa6C,EAAa/D,KAAYC,EAC/C,EAiLA1E,EAAQyI,MAnHI,SAAWpS,GAErB,IAAIqS,EAEApB,EAEAC,EAiBJ,OAZKlR,EAAQ6O,GACTqC,EAAcnC,EAAOzM,IACrB+P,GAAchD,EAAS6B,EAAa,GAAQlR,EAAQiP,GAAaiC,EAAa,MAAUA,EAAa,KAGrGD,EAASjR,EAAQ6O,EACjBqC,EAAcnC,EAAOzM,IAIrB+P,GAAc5C,EAAoBwB,EAASvB,EA9YzB,EA8Y+DwB,EAAa,IAAQA,EAAa,MAAUA,EAAa,IAEvImB,CACT,EA4FA1I,EAAQhH,QAhFM,SAAWoO,EAAM/Q,GAC7B,OAAOsI,EAAMoG,SAAUqC,GAAOvB,KAAMxP,EACtC,EA+EA2J,EAAQ2I,YArEU,WAEhB,OAAS1D,EAAIY,KAAKnN,OAAS,CAC7B,EAmEAsH,EAAQmF,cAzDY,WAClB,OAAOD,CACT,EAwDAlF,EAAQ4I,MAlBI,SAAW3R,GACrB,IAAIgR,EAAYtB,EAAQ1P,GACxB,OAAMgR,KACDA,EAAUvP,OAAS,IACnBuP,EAAW,IAAO/C,CAEzB,EAaAlF,EAAQwH,YAAcA,EACtBxH,EAAQ6I,WA/CS,SAAW5R,EAAM0B,GAEhC,IAAIsP,EAAYtB,EAAQ1P,GAExB,QAAMgR,MAEDA,EAAUvP,OAAS,OAEnBuP,EAAW,IAAO/C,KAKsB,IAAxCiC,EAAUc,EAAW,eAEnBT,EAAaS,EAAW,GAAKtJ,EAAMhG,IAAI8I,KAAM9I,MACtD,EAgCAqH,EAAQ8I,eA3Na,SAAWzS,GAE9B,IAAIgS,EAAgBjD,EAAOkD,iBACvBpB,EAAgB9B,EAAOwB,MAIvBmC,EAAc1S,EAalB,OATKA,EAAQ6O,IACUQ,EAAS2C,EAAe,GAAQhS,EAAQiP,GAAa+C,EAAe,MAAUA,EAAe,KAIhHU,GAAgBrD,EAASwB,EAAc,GAAQ7Q,EAAQiP,GAAa4B,EAAc,MAAUA,EAAc,IAIvG6B,CACT,EAwMO/I,CACT,C,gBCjiBA,IAAIlK,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBiT,EAAoBjT,EAAS,KAuCjCI,EAAOC,QAxBY,SAAWwC,EAAOC,EAAKtC,EAAKC,EAAMyS,EAAK9F,GAExD,IAAI+F,EAAa,GACbvS,EAAUH,GAAQP,EAAQkT,WAAWtS,IAAKL,GAAWA,EAAOV,EAAIgB,MAChEsS,EAASH,GAAOhT,EAAQoT,UAAUxS,IAAKoS,GAAUA,EAAMjT,EAAGgF,MAE9D,GAAKrE,IAAUb,EAAIgB,OAASH,IAAUb,EAAIqS,QAAUxR,IAAUb,EAAI8Q,OAASwC,IAASpT,EAAGwG,OACrF,MAAME,MAAO,yEAIf,GAAK0M,IAASpT,EAAGiB,MAAQmS,IAASpT,EAAG8F,aACnC,IAAM,IAAInB,EAAI/B,EAAO+B,GAAK9B,EAAK8B,GAAK,EAClCuO,EAAWjQ,KAAM+P,EAAmBrO,EAAGpE,GAAOC,EAAMmE,EAAGpE,EAAK4M,SAG9D,IAAM,IAAIxI,EAAI/B,EAAO+B,GAAK9B,EAAK8B,GAAK,EAClCuO,EAAWjQ,KAAMtC,EAAOgE,EAAGpE,EAAK4M,IAIpC,OAAOiG,EAAMF,EAAY3S,EAAKqC,EAAOC,EACvC,C,gBCxCA,IAAI/C,EAAMC,EAAS,MACfE,EAAUF,EAAS,MAmBvBI,EAAOC,QANW,SAAWC,EAAOE,EAAKC,EAAM2M,GAG7C,OADUlN,EAAQqT,UAAUzS,IAAKL,GAAWA,EAAOV,EAAIgB,OAC7CT,EAAOE,EAAK4M,EACxB,C,WChCAhN,EAAOC,QATM,SAAWmQ,EAAG3N,EAAOC,EAAK0Q,GACrC,MAAMC,EAAS,GACf,IAAM,IAAItQ,EAAIN,EAAOM,GAAKL,EAAKK,GAAK,EAElCsQ,EAAOvQ,KAAKsN,EAAGgD,EAAQrQ,GAAOA,EAAIN,IAEpC,OAAO4Q,CACT,C,WCyDArT,EAAOC,QA3BM,SAAWqT,EAAOC,GAU7B,IATA,IAEIC,EACAC,EAHAC,EAAW,EACXC,EAAWJ,EAAMhR,OAAS,EAK1BqR,GAAQ,EAGJF,GAAYC,GAKlB,GAHAF,EAAYF,EADZC,GAAcE,EAAWC,GAAa,EAAI,GACV,GAG3BL,EAFQC,EAAOC,GAAa,GAG/BE,EAAWF,EAAY,EACvBI,EAAOJ,EARF,OASA,MAAKF,EAAQG,GAGb,OAAOD,EAFZG,EAAWH,EAAY,EACvBI,EAAOJ,EAXF,EAYgB,CAGzB,OAAOI,CACT,C,iBCpCA,IAAIC,EAAejU,EAAS,MAuN5BI,EAAOC,QAzMS,SAAWsI,EAAMuL,EAAYvI,GAE3C,IAAIwI,EAAqB,MACrBC,EAAmB,GACnBC,EAAkB1L,EAAK2L,IACvBC,EAAsBN,EAAcC,EAAYvI,GAEhD6I,EAAe7L,EAAK8L,QAAQC,UAC5BC,EAAehM,EAAK8L,QAAQG,UAC5BC,EAAalM,EAAK8L,QAAQK,QAC1BC,EAAcpM,EAAK8L,QAAQO,SAE3BC,EAAsB,SAAWvB,GAEnC,IAAIwB,EACJ,IAAMA,EAAM,EAAGA,EAAMb,EAAgB1R,OAAQuS,GAAO,EAElD,GAAKb,EAAiBa,GAAO,GAAIC,KAAMzB,GAAU,OAAOW,EAAiBa,GAAO,GAElF,OAAOhB,EAAWkB,GACpB,EAwGIC,EAAiB,SAAW3B,EAAOwB,EAAKI,EAAiBnI,EAAKoI,GAChEpI,EAAIqI,UAAW9B,EAAOwB,EAAKI,EAAiBC,EAC9C,EAwEA,OAvBAnB,EAAkBF,EAAWkB,KAxJZ,SAAWlU,EAAMgU,EAAKI,EAAiBnI,EAAKoI,GAE3D,IAAIE,EAEAC,GAGJD,EAAQvU,EAAKuU,MAAOjB,KAIlBkB,EAAWvI,EAAIwI,mBAAoBF,EAAO,GAAKH,EAAiBC,MAC9CrB,EAAWkB,KAE3BM,EAAWT,EAAqBQ,EAAO,OACpBvB,EAAWkB,IAE5Bb,EAAqB5L,EAAKiN,IAAK1U,EAAMoU,EAAiBnI,EAAKoI,IAG3DnB,EAAkBsB,GAAYD,EAAO,GAAKC,EAAUJ,EAAiBnI,EAAKoI,GAC1EpI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAa,EAAGN,IAIxDpI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAa,EAAGN,IAM1DE,EAAQvU,EAAKuU,MAAOd,IAKbxH,EAAI2I,SAAUL,EAAO,KACxBtI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAaP,EAAiBC,GACpEpI,EAAIwI,mBAAoBF,EAAO,GAAK,EAAGF,KAGvCG,EAAWT,EAAqBQ,EAAO,OACpBvB,EAAWkB,IAE5Bb,EAAqB5L,EAAKiN,IAAK1U,EAAMoU,EAAiBnI,EAAKoI,IAG3DpI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAaP,EAAiBC,GACpEnB,EAAkBsB,GAAYD,EAAO,GAAKC,EAAU,EAAGvI,EAAKoI,KAOlEE,EAAQvU,EAAKuU,MAAOZ,IAGb1H,EAAI2I,SAAUL,EAAO,KACxBtI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAaP,EAAiBC,GACpEpI,EAAIwI,mBAAoBF,EAAO,GAAK,EAAGF,GACvCpI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAa,EAAGN,KAGtDG,EAAWT,EAAqBQ,EAAO,OACpBvB,EAAWkB,IAE5Bb,EAAqB5L,EAAKiN,IAAK1U,EAAMoU,EAAiBnI,EAAKoI,IAG3DpI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAaP,EAAiBC,GACpEnB,EAAkBsB,GAAYD,EAAO,GAAKC,EAAU,EAAGvI,EAAKoI,GAC5DpI,EAAIqI,UAAWC,EAAO,GAAKvB,EAAW2B,YAAa,EAAGN,IAQ5DhB,EAAqB5L,EAAKiN,IAAK1U,EAAMoU,EAAiBnI,EAAKoI,EAC7D,EAwEAnB,EAAkBF,EAAW6B,QAlET,SAAWrC,EAAOwB,EAAKI,EAAiBnI,EAAKoI,GAE/D,IAAIS,EAAKtC,EAAM/Q,OACVqT,EAAK,GACR7I,EAAIqI,UAAW9B,EAAMrQ,MAAO,GAAI,GAAK6Q,EAAW3F,KAAM+G,EAAiBC,GACvEpI,EAAIqI,UAAW9B,EAAMrQ,OAAQ,GAAK6Q,EAAW2B,YAAa,EAAGN,IAC5C,IAAPS,GAAgC,MAApBtC,EAAOsC,EAAK,GAChC7I,EAAIqI,UAAW9B,EAAOQ,EAAW3F,KAAM+G,EAAiBC,IAExDpI,EAAIqI,UAAW9B,EAAMrQ,MAAO,GAAI,GAAK6Q,EAAW3F,KAAM+G,EAAiBC,GACvEpI,EAAIqI,UAAW9B,EAAMrQ,OAAQ,GAAK6Q,EAAW2B,YAAa,EAAGN,GAEnE,EAyDAnB,EAAkBF,EAAW+B,OAAUZ,EACvCjB,EAAkBF,EAAW3F,MAAS8G,EACtCjB,EAAkBF,EAAWgC,WAAcb,EAC3CjB,EAAkBF,EAAWiC,QAAWd,EACxCjB,EAAkBF,EAAWkC,KAAQf,EACrCjB,EAAkBF,EAAWmC,OAAUhB,EACvCjB,EAAkBF,EAAWoC,SAAYjB,EACzCjB,EAAkBF,EAAWqC,SAAYlB,EACzCjB,EAAkBF,EAAWsC,UAAanB,EAC1CjB,EAAkBF,EAAWuC,MAASpB,EACtCjB,EAAkBF,EAAWwC,SAAYrB,EACzCjB,EAAkBF,EAAWyC,UAAatB,EAC1CjB,EAAkBF,EAAW2B,aAAgBR,EAC7CjB,EAAkBF,EAAW0C,QAAWvB,EACxCjB,EAAkBF,EAAW2C,SAAYxB,EACzCjB,EAAkBF,EAAW4C,MAASzB,EACtCjB,EAAkBF,EAAW6C,OAAU1B,EACvCjB,EAAkBF,EAAW8C,QAAW3B,EApEzB,SAAWlI,EAAKjM,GAE7B,IAAI+V,EAMAjU,EAEAkS,EAEAnS,EARAuS,EAAkB,EAElB4B,EAAW,KAWf,IAHAD,EAAY/V,EAAKiW,MAAOpC,GAGlB/R,EAAI,EAAGA,EAAIiU,EAAUtU,OAAQK,GAAK,EAAI,CAG1C,KAFAD,EAAIkU,EAAWjU,IAEL,SAEV,MAAMoU,EAAY,gDAAkDjC,KAAMpS,GAC1D,MAAXA,EAAG,IAAeqU,GAErB9B,EAAkBvS,EAAEJ,OACfyU,GACHF,EAAWnU,EACXuS,EAAkBnB,GACRmB,EAAkBnB,QAAyBmB,EAAkBnB,UAKzEe,EAAM/H,EAAIwI,mBAAoB5S,EAAGuS,EAAiB4B,MACrChD,EAAWkB,MACtBF,EAAMD,EAAqBlS,GAC3BqR,EAAkBc,GAAOnS,EAAGmS,EAAKI,EAAiBnI,EAAK+J,IAEzD5B,EAAkB,EAClB4B,EAAW,KAEf,CACF,CA4BF,C,WChNA9W,EAAOC,QAAU,CAAEgX,EAAGC,IACfA,EAAG,GAAMD,EAAG,GACR,EACGC,EAAG,GAAMD,EAAG,IACP,EACEA,EAAG,GAAMC,EAAG,GAAa,GACpC,C,WCdV,IAAIhP,EAAStH,OAAOC,OAAQ,MAQ5BqH,EAAOgC,SAAW,SAAWrD,GAC3B,MAAiD,oBAAxCjG,OAAOuW,UAAUC,SAASC,KAAMxQ,EAC3C,EAQAqB,EAAOgD,QAAU,SAAWrE,GAC1B,MAAiD,mBAAxCjG,OAAOuW,UAAUC,SAASC,KAAMxQ,EAC3C,EAQAqB,EAAOoP,gBAAkB,SAAWC,GAClC,MACiB,kBAANA,IACRC,MAAOD,IACRE,SAAUF,IACRA,IAAMhT,KAAKmT,MAAOH,EAExB,EAQArP,EAAOyF,eAAiB,SAAWsJ,GAEjC,IAAM/O,EAAOgD,QAAS+L,GAAM,OAAO,EAGnC,GAAkB,IAAbA,EAAE1U,OAAe,OAAO,EAG7B,IAAM,IAAIiC,EAAI,EAAGA,EAAIyS,EAAE1U,OAAQiC,GAAK,EAElC,IAAM0D,EAAOoP,gBAAiBL,EAAGzS,IAAQ,OAAO,EAIlD,OAAO,CACT,EAEAxE,EAAOC,QAAUiI,C,iBC5DjB,IAAIvI,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBG,EAAeH,EAAS,KAkC5BI,EAAOC,QArBc,SAAWC,EAAOE,EAAKC,EAAM2M,GAChD,IAAI2K,EAAWvX,EAAI+B,UAAWjC,GAE1BM,EAAUH,GAAQP,EAAQ8X,aAAalX,IAAKL,GAAWA,EAAOV,EAAIgB,MAEtE,GAAKH,IAAUb,EAAIqB,MAAQR,IAAUb,EAAI2K,UACvC,OAAO9J,EAAOmX,GAIhB,GAAKnX,IAAUb,EAAIkY,aACjB,OAA2B,IAAlBF,EAAU,GAKrB,IAAI1E,EAASzS,IAAUb,EAAIgG,aAAiB9F,EAAG8F,aAAe9F,EAAGiB,KAEjE,OAAOf,EAAc4X,EAAU,GAAKA,EAAU,GAAKvX,EAAKI,EAAOyS,EAAMjG,EACvE,C,WCnCA,IAAI8K,EAAQ,WAmCRC,EAAiB,SAAWC,EAAMC,GACpC,IAAIC,EAEAtV,EADAuV,EAAOF,EAAK1V,OAEZ6V,EAAOJ,EAAKzV,OACZ8Q,EAAS,GAEb,IAAMzQ,EAAI,EAAGA,EAAIwV,EAAMxV,GAAK,EAC1B,IAAMsV,EAAI,EAAGA,EAAIC,EAAMD,GAAK,EAC1B7E,EAAOvQ,KAAMkV,EAAMpV,GAAIyV,OAAQJ,EAAMC,KAGzC,OAAS7E,CACX,EAyEArT,EAAOC,QAlCe,SAAWqY,GAC/B,IAAMA,GAAwB,kBAARA,EAAqB,MAAO,GAIlD,IAAIC,EAjFoB,SAAWzX,GACnC,IACI0X,EAAW,GAEXC,EAAU3X,EAAKuU,MAAOyC,GAC1B,IAAMW,GAAgC,IAAnBA,EAAQlW,OAAiB,OAAO,KAEnD,IAAM,IAAIQ,EAAI,EAAG2V,EAAOD,EAAQlW,OAAQQ,EAAI2V,EAAM3V,GAAK,EACrDyV,EAAS1V,KAAM2V,EAAS1V,GAAI4V,OAAQ,EAAGF,EAAS1V,GAAIR,OAAS,IAE/D,OAASiW,CACX,CAsEwBI,CAAqBN,GACvC7K,EAAW,GACXoL,EAAgB,GAEpB,IAAMN,EAAkB,MAAO,CAAE,CAAED,IACnCC,EAAgBnU,SAAS,SAAWL,GAClC0J,EAAS3K,KAAMiB,EAAEgT,MAAO,KAC1B,IAIA,MAAMvQ,EAAOiH,EAAStK,QAAU,CAAE6U,EAAMC,IAAUD,EAAOC,EAAK1V,QAAU,GA1C5D,IAAW0U,EAyDvB,OAVKzQ,EAlBU,KAkBOA,EAjBP,MAkBbsS,QAAQC,KAAM,+DACJvS,EAnBG,OAmBasS,QAAQE,MACR,kIAlDL/B,EAsDdxJ,EApDPwJ,EAAE9T,OAAQ4U,EAAgB,CAAE,MAoDV3T,SAAS,SAAWL,GACtC8U,EAAc/V,KAAMiB,EAAER,KAAM,KAAMmC,OAAOqR,MAAO,OAClD,IACS8B,CACX,C,WCxGA7Y,EAAOC,QANO,SAAWmQ,EAAG6I,EAAW7F,GACrC,IAAM,IAAIrQ,EAAI,EAAGA,EAAIkW,EAAU1W,OAAQQ,GAAK,EAC1CqN,EAAGgD,EAAQ6F,EAAWlW,IAAOA,EAEjC,C,WCNA,IAAImW,EAAkB,0BAClBC,EAAe,gCAEfC,EAAa,qBACbC,EAAY,SACZC,EAAY,QAqThBtZ,EAAOC,QAzSS,SAAW6T,EAAYvI,GAErC,IAAIgO,EACAC,EAEA9D,EAEA+D,EAAK,EAELlY,EAAoB,KAepBmY,EAAsB,SAAWC,EAAKtY,GAExC,IAAI0J,EAEA6O,EAEApV,EAAGzB,EAAGmD,EAGV,GAAKwP,EAAUiE,IAAQL,EAAUvE,KAAM4E,GACrCtY,EAAOyB,KAAM,CAAE6W,EAAK7F,EAAW3F,YAMjC,GAAiB,QAFjByL,EAAUD,EAAItE,MAAO+D,IAUrB,GADAlT,GADA6E,EAAQ4O,EAAI5C,MAAOqC,IACN7W,OAAS,EACjBgJ,EAASsO,OAAQ9O,EAAO,KAASQ,EAASuO,OAAQ/O,EAAO7E,IAC5D7E,EAAOyB,KAAM,CAAE6W,EAAK7F,EAAW3F,YAIjC,IADApL,EAAI,EACEyB,EAAI,EAAGA,EAAIuG,EAAMxI,OAAQiC,GAAK,EAEd,KAAfuG,EAAOvG,IACVnD,EAAOyB,KAAM,CAAEiI,EAAOvG,GAAKsP,EAAW3F,OAGnCpL,EAAI6W,EAAQrX,QACflB,EAAOyB,KAAM,CAAE8W,EAAS7W,GAAK+Q,EAAW2B,cAE1C1S,GAAK,OArBL1B,EAAOyB,KAAM,CAAE6W,EAAK7F,EAAW3F,MAuBnC,EAeI4L,EAAgB,SAAWJ,EAAKtY,GAElC,IAAI0J,EAEAiP,EAGAxV,EAAGzB,EAGHkX,EAAY,GACZC,EAAY,GAKhB,GAAKxE,EAAUiE,IAAST,EAAgBnE,KAAM4E,GAC5CtY,EAAOyB,KAAM,CAAE6W,EAAK7F,EAAW3F,YAOjC,GAAiB,QAFjB6L,EAAUL,EAAItE,MAAOgE,IAErB,CASA,IAHAtO,EAAQ4O,EAAI5C,MAAOsC,GACnBtW,EAAI,EAEEyB,EAAI,EAAGA,EAAIuG,EAAMxI,OAAQiC,GAAK,EAElC0V,EAAYD,EAAYlP,EAAOvG,GAE1B2U,EAAapE,KAAMmF,IAAiBxE,EAAUwE,IAAeA,EAAU3X,OAAS,GAAuB,KAAd0X,EAC5FA,EAAYC,GAGZR,EAAqBO,EAAW5Y,GAEhC4Y,EAAYlP,EAAOvG,GACnB0V,EAAY,IAGTnX,EAAIiX,EAAQzX,SAEf2X,EAAYD,EAAYD,EAASjX,GAC5BoW,EAAapE,KAAMmF,IAAiBxE,EAAUwE,IAAeA,EAAU3X,OAAS,EACnF0X,EAAYC,GAEZR,EAAqBO,EAAW5Y,GAChCA,EAAOyB,KAAM,CAAEkX,EAASjX,GAAK+Q,EAAW2B,cACxCwE,EAAY,GACZC,EAAY,KAGhBnX,GAAK,EAGY,KAAdkX,GAAmBP,EAAqBO,EAAW5Y,EAnCxD,MAFEqY,EAAqBC,EAAKtY,EAsC9B,EAwFI8Y,EAA0B,SAAWrZ,EAAMsZ,GAC7C,IACI/Y,EAEAmD,EAAGa,EAHHsS,EAAW7W,EAAK4E,OAMpB,IAAM0U,EAAQ7X,OAMZ,OAFAgX,EAAUzY,EAAMgT,EAAWkB,IAAKyE,EAAIlY,QACpCkY,EAAK,GAOP,IAFApY,EAzFqB,SAAWP,EAAMuZ,GAGtC,IAQI7V,EACAa,EACAtC,EACAJ,EAXA8V,EAAU3X,EAAKuU,MAAOgF,EAtLlB,IAwLJC,EAAUxZ,EAAKiW,MAAOsD,EAxLlB,IA0LJhZ,EAAS,GAETkZ,EAAMF,EA3LF,GA2NR,IAtBA5B,EAAYA,GAAsB,GAqBlC1V,EAAI,EACEyB,EAAI,EAAGa,EAAOiV,EAAQ/X,OAAQiC,EAAIa,EAAMb,GAAK,GAEjD7B,GADAA,EAAI2X,EAAS9V,IACPkB,SACGrE,EAAOyB,KAAMH,GACjBI,EAAI0V,EAAQlW,SACVgY,IAAQzG,EAAW3F,KAEtB4L,EAAetB,EAAS1V,GAAK1B,GAE7BA,EAAOyB,KAAM,CAAE2V,EAAS1V,GAAKwX,KAGjCxX,GAAK,EAGP,OAAS1B,CACX,CAgCWmZ,CAAkB7C,EADjByC,EAAS,IAGb5V,EAAI,EAAGa,EAAOhE,EAAOkB,OAAQiC,EAAIa,EAAMb,GAAK,EACpB,kBAAhBnD,EAAQmD,GAElB2V,EAAyB9Y,EAAQmD,GAAK4V,EAAQnX,MAAO,KAK/CuW,EAAmBnY,EAAQmD,GAAK,GAAKiV,EAAIlY,KAClCuS,EAAWkB,KAAMuE,EAAUlY,EAAQmD,GAAK,GAAKnD,EAAQmD,GAAK,GAAKiV,EAAIlY,GAGhFkY,EAAK,EAGX,EA8BA,OAZe,SAAWgB,EAAM3Z,EAAMoU,EAAiBnI,EAAKoI,GAE1DoE,EAAWxM,EAAIqI,UACfoE,EAAoBzM,EAAIwI,mBACxBG,EAAW3I,EAAI2I,SAGf+D,EAAKvE,EACL3T,EAAoB4T,EACpBgF,EAAyBrZ,EAAM2Z,EAAMvF,EACvC,CAGF,C,iBC/TA,IAAIjU,EAAYrB,EAAS,MAErBsB,EAASD,EAAUC,OAEnBC,EAASF,EAAUE,OAEnBK,EAAaP,EAAUO,WAEvBC,EAAUR,EAAUQ,QAmDxBzB,EAAOC,QAtCW,SAAWoB,EAAQe,GACnC,IACIoC,EAAGyC,EACHtE,EAAGoE,EAEHuR,EAJAjT,EAAOhE,EAAOkB,OAGdmY,EAAM,4BAENC,EAAQ,CAAE,SAAU,SAAU,QAAS,UAAW,UAAW,aAKjE,IAFA7B,QAAQ8B,IAAK,yFACb9B,QAAQ8B,IAAK,8gBACPpW,EAAI,EAAGA,EAAIa,EAAMb,GAAKtD,EAAS,CAMnC,IALAoX,EAAM,GACN3V,EAAItB,EAAQmD,GACZuC,EAAK3E,EAAMzB,MAAOgC,GAClB2V,IAAShL,KAAKC,UAAWxG,GAAK8T,QAAS,KAAM,IAAQH,GAAMzX,MAAO,EAAG,IACrEqV,KAAWjX,EAAQmD,EAAI,GAAMrD,GAAWuZ,GAAMzX,MAAO,EAAG,GAClDgE,EAAI,EAAGA,EAAI0T,EAAMpY,OAAQ0E,GAAK,EAClCqR,IAAShL,KAAKC,UAAWnL,EAAM4O,SAAUrO,EAAGgY,EAAO1T,KAAQ4T,QAAS,KAAM,IAAOH,GAAMzX,MAAO,EAAG,GAE9F5B,EAAQmD,EAAI,GAAM,OACrB8T,GAAO,IAAMlW,EAAMzB,MAAOyB,EAAMgQ,IAAK/Q,EAAQmD,EAAI,KACjD8T,GAAO,MAAQlW,EAAMS,QAAS,OAASxB,EAAQmD,EAAI,GAAM/C,KAAcD,KAEvE8W,GAAO,IAAMhL,KAAKC,UAAWnL,EAAMzB,MAAOyB,EAAM4P,OAAQrP,KAAQkY,QAAS,KAAM,IAC/EvC,GAAO,MAAQlW,EAAM4O,SAAUrO,EAAG,QAIpCmW,QAAQ8B,IAAKtC,GAEbA,GAAO,MAAQlW,EAAMS,QAAS,OAASxB,EAAQmD,EAAI,GAAM/C,KAAcD,EACzE,CAGAsX,QAAQ8B,IAAK,iCAAkCvZ,EAAOkB,OAASrB,EACjE,C,WCnCAlB,EAAOC,QATS,SAAWmQ,EAAG3N,EAAOC,EAAK0Q,EAAQ0H,GAChD,IAAIC,EAAW,GACf,IAAM,IAAIhY,EAAIN,EAAOM,GAAKL,EAAKK,GAAK,EAE7BqN,EAAGgD,EAAQrQ,GAAOA,EAAIN,IAAYsY,EAASjY,KAAMC,GAExD,OAAO+X,EAAeC,EACxB,C,WCpBA,IAAIC,EAASpa,OAAOC,OAAQ,MAE5Bma,EAAOC,IAAM,EAEbD,EAAOzM,oBAAsB,GAE7ByM,EAAOxZ,WAAa,GAEpBwZ,EAAOvZ,QAAU,SAEjBuZ,EAAO7Z,OAAS,MAEhB6Z,EAAO1M,OAAS,WAEhB0M,EAAOE,UAAY,QAEnBF,EAAO9Z,OAAS,EAEhB8Z,EAAOG,OAAS,EAEhBH,EAAOxM,OAAS,GAEhBwM,EAAOvM,eAAiB,GAExBuM,EAAOnD,aAAetT,KAAK6W,IAAK,EAAG,IAEnCpb,EAAOC,QAAU+a,C,WCVjBhb,EAAOC,QANY,SAAW8C,EAAGkW,EAAW7F,GAC1C,GAAKrQ,EAAI,GAAKA,GAAKkW,EAAU1W,OAC3B,MAAMgE,MAAO,uBAAuBxD,2CAC/B,OAAOqQ,EAAQ6F,EAAWlW,GACnC,C,iBCXA,IAAIsY,EAAoBzb,EAAS,MAK7B0b,EAAgB1b,EAAS,MACzB2b,EAAe3b,EAAS,MACxB4b,EAAe5b,EAAS,MAGxB6b,EAAU7b,EAAS,MACnB8b,EAAU9b,EAAS,MAEnB+b,EAAS/b,EAAS,MAClBgc,EAAShc,EAAS,MAGlBic,EAAYjc,EAAS,MACrBkc,EAAYlc,EAAS,MAGrBmc,EAAcnc,EAAS,KACvBG,EAAeH,EAAS,KACxBoc,EAAepc,EAAS,MAGxBqc,EAAerc,EAAS,KACxBsc,EAAiBtc,EAAS,MAC1Buc,EAAiBvc,EAAS,MAG1Bwc,EAAiBxc,EAAS,MAC1Byc,EAAkBzc,EAAS,MAG3B0c,EAAiB1c,EAAS,MAG1B2c,EAAc3c,EAAS,MAEvBD,EAAMC,EAAS,MAkhBnBI,EAAOC,QAngBG,SAAWuc,EAASxP,GAE5B,IA4BIyP,EACAC,EACAC,EACAC,EAGAC,EACAC,EACAC,EAGAC,EACAC,EACAC,EACAC,EAGAC,EA7CAhb,EAAQoa,EAAQpa,MAWhBf,EAASmb,EAAQnb,OAGjBlB,EAAWqc,EAAQrc,SACnB2M,EAAiB0P,EAAQ1P,eAGzB3K,EAAYqa,EAAQra,UAIpByD,EAAW4W,EAAQ5W,SA0BnB8P,EAAWtT,EAAMoO,OAGjB3G,EAAUjJ,OAAOC,OAAQ,MA2c7B,OA7bAmc,EAAY,SAAW9c,GACrB,IAAImd,EAAMzc,OAAOC,OAAQ,MAezB,OAbAwc,EAAIC,eAAiB,IAAMzT,EAE3BwT,EAAIE,aAAe,IAAMjC,EAAepb,EAAOC,EAAU8c,GAEzDI,EAAIG,mBAAqB,IAAMlC,EAAepb,EAAO4M,EAAgBoQ,GAErEG,EAAII,OAAS,CAAEtX,EAAaC,IAAeR,EAAS9C,KAAM,CAAE5C,EAAOA,EAAOiG,EAAaC,IAEvFiX,EAAIK,IAAQtN,GAAO2L,EAAa7b,EAAOsc,EAASpM,EAAGpD,GAEnDqQ,EAAIM,eAAiB,IAAMrC,EAAepb,EAAOiC,EAAWgb,GAE5DE,EAAInd,MAAQ,IAAQA,EACbmd,CACT,EAYAN,EAAoB,SAAWa,GAC7B,IAAIP,EAAMzc,OAAOC,OAAQ,MAczB,OAZAwc,EAAIQ,KAASzN,GAAOsL,EAAStL,EAAGwN,EAAgBZ,GAEhDK,EAAIvZ,IAAQsM,GAAOwL,EAAQxL,EAAGwN,EAAgBZ,GAE9CK,EAAIrZ,OAAWoM,GAAO0L,EAAW1L,EAAGwN,EAAgBZ,EAAWD,GAE/DM,EAAIS,OAAW/a,GAAOyY,EAAczY,EAAG6a,EAAgBZ,GAEvDK,EAAI9a,OAAS,IAAQqb,EAAerb,OAGpC8a,EAAIK,IAAM,CAAEtN,EAAG2N,IAAO/B,EAAc4B,EAAgBpB,EAASpM,EAAG2N,EAAG/Q,GAC5DqQ,CACT,EAYAV,EAAY,SAAWla,EAAOC,GAC5B,OACE,WACE,IAAI2a,EAAMzc,OAAOC,OAAQ,MAgBzB,OAdAwc,EAAIQ,KAASzN,GAAOqL,EAASrL,EAAG3N,EAAOC,EAAKsa,GAE5CK,EAAIvZ,IAAQsM,GAAOuL,EAAQvL,EAAG3N,EAAOC,EAAKsa,GAE1CK,EAAIrZ,OAAWoM,GAAOyL,EAAWzL,EAAG3N,EAAOC,EAAKsa,EAAWD,GAG3DM,EAAIS,OAAW/a,GAAOwY,EAAcxY,EAAGN,EAAOC,EAAKsa,GAEnDK,EAAI9a,OAAS,IAAQG,EAAMD,EAAQ,EAGnC4a,EAAIK,IAAM,CAAEtN,EAAG2N,IAAOhe,EAAc0C,EAAOC,EAAK8Z,EAASpM,EAAG2N,EAAG/Q,GAExDqQ,CACT,CAEJ,EAiBAJ,EAAa,SAAW/c,GACtB,IAAImd,EAAMzc,OAAOC,OAAQ,MAazB,OAXAwc,EAAIC,eAAiB,IAAMzT,EAE3BwT,EAAII,OAAS,CAAEtX,EAAaC,IAAeR,EAAS9C,KAAM,CAAE3C,EAAUD,GAAS,GAAKC,EAAUD,GAAS,GAAKiG,EAAaC,IAEzHiX,EAAIK,IAAQtN,GAAO6L,EAAc/b,EAAOC,EAAUqc,EAASpM,GAE3DiN,EAAIM,eAAkB,IAAMrC,EAAenb,EAAUD,GAAS,GAAKiC,EAAWgb,GAE9EE,EAAIhc,OAASsb,EAAWxc,EAAUD,GAAS,GAAKC,EAAUD,GAAS,IAEnEmd,EAAInd,MAAQ,IAAQA,EACbmd,CACT,EAYAR,EAAsB,SAAWmB,GAC/B,IAAIX,EAAMzc,OAAOC,OAAQ,MAczB,OAZAwc,EAAIQ,KAASzN,GAAOsL,EAAStL,EAAG4N,EAAkBf,GAElDI,EAAIvZ,IAAQsM,GAAOwL,EAAQxL,EAAG4N,EAAkBf,GAEhDI,EAAIrZ,OAAWoM,GAAO0L,EAAW1L,EAAG4N,EAAkBf,EAAYJ,GAElEQ,EAAIS,OAAW/a,GAAOyY,EAAczY,EAAGib,EAAkBf,GAEzDI,EAAI9a,OAAS,IAAQyb,EAAiBzb,OAGtC8a,EAAIK,IAAM,CAAEtN,EAAG2N,IAAO5B,EAAgB6B,EAAkB7d,EAAUqc,EAASpM,EAAG2N,GACvEV,CACT,EAUAZ,EAAc,WACZ,IAAIY,EAAMzc,OAAOC,OAAQ,MAczB,OAZAwc,EAAIQ,KAASzN,GAAOqL,EAASrL,EAAG,EAAGjQ,EAASoC,OAAS,EAAG0a,GAExDI,EAAIvZ,IAAQsM,GAAOuL,EAAQvL,EAAG,EAAGjQ,EAASoC,OAAS,EAAG0a,GAEtDI,EAAIrZ,OAAWoM,GAAOyL,EAAWzL,EAAG,EAAGjQ,EAASoC,OAAS,EAAG0a,EAAYJ,GAExEQ,EAAIS,OAAW/a,GAAOwY,EAAcxY,EAAG,EAAK5C,EAASoC,OAAS,EAAK0a,GAEnEI,EAAI9a,OAAS,IAAQpC,EAASoC,OAG9B8a,EAAIK,IAAM,CAAEtN,EAAG2N,IAAO7B,EAAgB/b,EAAUqc,EAASpM,EAAG2N,GACrDV,CACT,EAiBAH,EAAmB,SAAWhd,GAC5B,IAAImd,EAAMzc,OAAOC,OAAQ,MAazB,OAXAwc,EAAIC,eAAiB,IAAMzT,EAE3BwT,EAAII,OAAS,CAAEtX,EAAaC,IAAeR,EAAS9C,KAAM,CAAEgK,EAAgB5M,GAAS,GAAK4M,EAAgB5M,GAAS,GAAKiG,EAAaC,IAErIiX,EAAIK,IAAQtN,GAAO6L,EAAc/b,EAAO4M,EAAgB0P,EAASpM,GAEjEiN,EAAIM,eAAkB,IAAMrC,EAAexO,EAAgB5M,GAAS,GAAKiC,EAAWgb,GAEpFE,EAAIhc,OAASsb,EAAW7P,EAAgB5M,GAAS,GAAK4M,EAAgB5M,GAAS,IAE/Emd,EAAInd,MAAQ,IAAQA,EACbmd,CACT,EAYAP,EAA4B,SAAWmB,GACrC,IAAIZ,EAAMzc,OAAOC,OAAQ,MAczB,OAZAwc,EAAIQ,KAASzN,GAAOsL,EAAStL,EAAG6N,EAAwBf,GAExDG,EAAIvZ,IAAQsM,GAAOwL,EAAQxL,EAAG6N,EAAwBf,GAEtDG,EAAIrZ,OAAWoM,GAAO0L,EAAW1L,EAAG6N,EAAwBf,EAAkBJ,GAE9EO,EAAIS,OAAW/a,GAAOyY,EAAczY,EAAGkb,EAAwBf,GAE/DG,EAAI9a,OAAS,IAAQ0b,EAAuB1b,OAG5C8a,EAAIK,IAAM,CAAEtN,EAAG2N,IAAO5B,EAAgB8B,EAAwBnR,EAAgB0P,EAASpM,EAAG2N,GACnFV,CACT,EAUAX,EAAoB,WAClB,IAAIW,EAAMzc,OAAOC,OAAQ,MAczB,OAZAwc,EAAIQ,KAASzN,GAAOqL,EAASrL,EAAG,EAAGtD,EAAevK,OAAS,EAAG2a,GAE9DG,EAAIvZ,IAAQsM,GAAOuL,EAAQvL,EAAG,EAAGtD,EAAevK,OAAS,EAAG2a,GAE5DG,EAAIrZ,OAAWoM,GAAOyL,EAAWzL,EAAG,EAAGtD,EAAevK,OAAS,EAAG2a,EAAkBJ,GAEpFO,EAAIS,OAAW/a,GAAOwY,EAAcxY,EAAG,EAAK+J,EAAevK,OAAS,EAAK2a,GAEzEG,EAAI9a,OAAS,IAAQuK,EAAevK,OAGpC8a,EAAIK,IAAM,CAAEtN,EAAG2N,IAAO7B,EAAgBpP,EAAgB0P,EAASpM,EAAG2N,GAC3DV,CACT,EAgBAF,EAAe,SAAWjd,GACxB,IAAImd,EAAMzc,OAAOC,OAAQ,MAezB,OAbAwc,EAAIC,eAAiB,IAAMzT,EAE3BwT,EAAII,OAAS,CAAEtX,EAAaC,IAAeR,EAAS9C,KAAM,CAAEX,EAAWjC,GAAS,GAAKiC,EAAWjC,GAAS,GAAKiG,EAAaC,IAE3HiX,EAAIK,IAAQtN,GAAOgM,EAAgBlc,EAAOsc,EAASpM,EAAGpD,GAEtDqQ,EAAIld,SAAW,IAAM0c,EAAqBxB,EAAmBlb,EAAUgC,EAAWjC,GAAS,GAAKiC,EAAWjC,GAAS,KAEpHmd,EAAIvQ,eAAiB,IAAMgQ,EAA2BzB,EAAmBvO,EAAgB3K,EAAWjC,GAAS,GAAKiC,EAAWjC,GAAS,KAEtImd,EAAIhc,OAASsb,EAAWxa,EAAWjC,GAAS,GAAKiC,EAAWjC,GAAS,IAErEmd,EAAInd,MAAQ,IAAQA,EACbmd,CACT,EAUAT,EAAe,WACb,IAAIS,EAAMzc,OAAOC,OAAQ,MAWzB,OATAwc,EAAIQ,KAASzN,GAAOqL,EAASrL,EAAG,EAAGjO,EAAUI,OAAS,EAAG4a,GAEzDE,EAAIvZ,IAAQsM,GAAOuL,EAAQvL,EAAG,EAAGjO,EAAUI,OAAS,EAAG4a,GAEvDE,EAAIS,OAAW/a,GAAOwY,EAAcxY,EAAG,EAAKZ,EAAUI,OAAS,EAAK4a,GAEpEE,EAAI9a,OAAS,IAAQJ,EAAUI,OAE/B8a,EAAIK,IAAQtN,GAAOiM,EAAiBG,EAASpM,EAAGpD,GACzCqQ,CACT,EAYAD,EAAoB,WAA+G,IAApG,MAAE3M,GAAQ,EAAI,oBAAEyN,EAAsB,GAAE,mBAAEC,GAAqB,EAAK,iBAAEC,EAAmB,GAAG/V,UAAA9F,OAAA,QAAAmB,IAAA2E,UAAA,GAAAA,UAAA,GAAG,CAAC,EAE7H,GAA6B,OAAxBmU,EAAQlW,YACX,MAAMC,MAAO,kFACf,IAAMrC,MAAMgH,QAASgT,GACnB,MAAM3X,MAAO,6FAA6F2X,OAC5G,IAAMG,OAAOC,UAAWF,IAAsBA,GAAoB5B,EAAQlW,YAAYE,KACpF,MAAMD,MAAO,qEACf,GAAKkK,IAAU+L,EAAQxS,SAASxH,IAC9B,MAAM+D,MAAO,+EAEf,MAAMlD,EAAKzC,OAAOC,OAAQ,MAE1BwC,EAAGqD,UAAY8V,EAAQlW,YAAYI,UACnCrD,EAAGuD,YAAc4V,EAAQlW,YAAYM,YACrCvD,EAAGwH,UAAY2R,EAAQlW,YAAYuE,UACnCxH,EAAGoD,WAAa+V,EAAQlW,YAAYG,WACpCpD,EAAGyH,UAAY0R,EAAQlW,YAAYwE,UAAU7H,MAAO,GAEpDI,EAAGmD,KAAO,EACVnD,EAAG0H,MAAQ,GACX1H,EAAGsD,QAAU/F,OAAOC,OAAQ,MAE5B,MAAM0d,EAAO/B,EAAQlW,YAAYK,QAG3B6X,EAAY7B,EAAW,EAAGH,EAAQ1V,YAAc,EAApC6V,GACCe,MACA5Z,KAAOnB,GAAOA,EAAEqE,gBACnC,IAAIyX,EAAiB,GAChBhO,IAAQgO,EAAiB9B,EAAW,EAAGH,EAAQ1V,YAAc,EAApC6V,GACUe,IAAK/d,EAAI8Q,OACT3M,KAAOnB,GAAOA,EAAEqE,iBAIxD,IAAM,IAAIxC,EAAI,EAAGA,EAAIga,EAAUjc,OAAQiC,GAAK,EAAInB,EAAGsD,QAAS6X,EAAWha,KAAU+Z,EAAMC,EAAWha,KAASnB,EAAGyH,WAAY7H,MAAO,GACjI,IAAM,IAAIuB,EAAI,EAAGA,EAAIia,EAAelc,OAAQiC,GAAK,EAAInB,EAAGsD,QAAS8X,EAAgBja,KAAU+Z,EAAME,EAAgBja,KAASnB,EAAGyH,WAAY7H,MAAO,GAChJ,IAAM,IAAIuB,EAAI,EAAGA,EAAI0Z,EAAoB3b,OAAQiC,GAAK,EAAI,GACvC0Z,EAAqB1Z,IAAQ0Z,EAAqB1Z,GAAI4S,WAAW1R,SAEhFrC,EAAGsD,QAASuX,EAAqB1Z,KAAU+Z,EAAML,EAAqB1Z,KAASnB,EAAGyH,WAAY7H,MAAO,GACzG,CAEA,GAAKkb,EAAqB,CAExB,MAAMO,EAAkB9d,OAAOiD,KAAMR,EAAGsD,SAElCgY,EAAe,IAAIza,MAAOwa,EAAgBnc,QAE1Cqc,EAAoB,IAAI1a,MAAOwa,EAAgBnc,QAErDqc,EAAkBza,KAAM,KAGxBd,EAAGmD,KAAOkY,EAAgBnc,OAI1B,IAAM,IAAIiC,EAAI,EAAGA,EAAIka,EAAgBnc,OAAQiC,GAAK,EAAI,CACpD,MAAMqa,EAAMxb,EAAGsD,QAAS+X,EAAiBla,IAEzC,IAAM,MAAM2J,KAAQoQ,EAAO,CACzB,GAAKpQ,IAASuQ,EAAiBla,GAAM,SACrC,MAAMsa,EAAKP,EAAMpQ,GACjB,IAAI4Q,EAAW,EAEf,IAAM,IAAIhc,EAAI,EAAGA,EAAIM,EAAGoD,YAAcsY,EAAWH,EAAmBpa,GAAKzB,GAAK,EAC5Egc,GAAYxa,KAAKya,IAAKH,EAAK9b,GAAM+b,EAAI/b,IAGlCgc,EAAWH,EAAmBpa,KACjCoa,EAAmBpa,GAAMua,EACzBJ,EAAcna,GAAM2J,EAExB,CACF,CAGA,IAAM,IAAI3J,EAAI,EAAGA,EAAIma,EAAapc,OAAQiC,GAAK,OACJd,IAApCL,EAAGsD,QAASgY,EAAcna,MAE7BnB,EAAGsD,QAASgY,EAAcna,IAAQ+Z,EAAMI,EAAcna,IAAMvB,MAAO,GACnEI,EAAGmD,MAAQ,EAIjB,MAAOnD,EAAGmD,KAAO5F,OAAOiD,KAAMR,EAAGsD,SAAUpE,OAG3C,IAAM,IAAIiC,EAAI,EAAGnB,EAAGmD,KAAO4X,EAAkB5Z,GAAK,EAAI,CACpD,MAAM2J,EAAOqO,EAAQlW,YAAYyE,MAAOvG,GAClCnB,EAAGsD,QAASwH,KAChB9K,EAAGsD,QAASwH,GAASoQ,EAAMpQ,GAAOlL,MAAO,GACzCI,EAAGmD,MAAQ,EAEf,CAGAnD,EAAG0H,MAAQnK,OAAOiD,KAAMR,EAAGsD,SACN7C,KAAOmb,IAAC,CAAUA,EAAGA,EAAGza,EAAInB,EAAGsD,QAASsY,GAAK5b,EAAGwH,WAAc,EAAMqU,IAAW7b,EAAGsD,QAASsY,GAAK5b,EAAGwH,eACnG1F,MAAM,CAAC8R,EAAGC,IAAMD,EAAEzS,EAAI0S,EAAE1S,IACxBV,KAAOqb,GAAOA,EAAEF,IAGrC,IAAM,IAAIza,EAAI,EAAGA,EAAInB,EAAGmD,KAAMhC,GAAK,EAAInB,EAAGsD,QAAStD,EAAG0H,MAAOvG,IAAOnB,EAAGwH,WAAcrG,EAErF,OAAO8I,KAAKC,UAAWlK,EACzB,EAGAwG,EAAQ1J,SAAWsc,EACnB5S,EAAQiD,eAAiB4P,EACzB7S,EAAQ6L,SAAWA,EACnB7L,EAAQ4I,MAAQrQ,EAAMqQ,MACtB5I,EAAQ6T,IAAQtN,GAAOkM,EAAgBE,EAASpM,EAAGpD,GACnDnD,EAAQ1H,UAAYya,EACpB/S,EAAQxI,OAASsb,EAAW,EAAGH,EAAQ1V,YAAc,GAErD+C,EAAQ0S,YAAc,IAAMA,EAAalb,EAAQe,GAGjDyH,EAAQuV,WAAa,IAAM9R,KAAKM,MAAON,KAAKC,UAAWiP,EAAQxS,WAE/DH,EAAQuT,kBAAoBA,EAErBvT,CACT,C,iBC3jBA,IAAI5I,EAAYrB,EAAS,MAErBsB,EAASD,EAAUC,OAEnBM,EAAaP,EAAUO,WAEvBC,EAAUR,EAAUQ,QAEpBgG,EAAU7G,OAAOC,OAAQ,MAgF7B4G,EAAQG,yBArEuB,SAAWxH,GAExC,IAIIoE,EAAGzB,EAJH1B,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MAEZid,EAAe,IAAInb,MAAO9D,EAAI0G,aAElC,IAAMtC,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAKtD,EACnC6B,EAAIyB,EAAI,EACR6a,EAAc7a,EAAItD,GAAaG,EAAQ0B,GAAM,MAEnBX,EAAMgQ,IAAK/Q,EAAQ0B,IAEnBX,EAAM4P,OAAQ3Q,EAAQmD,IAGlD,OAAO6a,CACT,EAqDA5X,EAAQ6X,wBA1CsB,SAAWlf,GAEvC,IAIIoE,EAJAnD,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MAEZid,EAAe,IAAInb,MAAO9D,EAAI0G,aAElC,IAAMtC,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAKtD,EAGnCme,EAAc7a,EAAItD,GAAWkB,EAAMuQ,eAAgBtR,EAAQmD,IAE7D,OAAO6a,CACT,EA8BA5X,EAAQI,6BAnB2B,SAAWzH,GAE5C,IAAIiB,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MACZwK,EAAU,IAAI1I,MAAO9D,EAAI0G,aAC7B,IAAIyY,EAAK,EACT,IAAM,IAAI/a,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAKtD,EAAQqe,GAAM,EACrD3S,EAAS2S,GAAiC,IAAxBle,EAAUmD,EAAM,GAIdpC,EAAMkQ,MAAOlQ,EAAMuQ,eAAgBtR,EAAQmD,MAAW,GACpDnD,EAAUmD,EAAM,GAAM/C,KAAcD,EAE5D,OAAOoL,CACT,EAMA5M,EAAOC,QAAUwH,C,WCzFjB,IAAI+X,EAAc,SAAWpS,GAC3B,IAEI5I,EAFAib,EAAM,GACNpa,EAAO+H,EAAO7K,OAGlB,IAAMiC,EAAI,EAAGA,EAAIa,EAAMb,GAAK,EAC1Bib,EAAI3c,KAAM,CAAI,IAAI4c,OAAQtS,EAAQ5I,GAAK,GAAK4I,EAAQ5I,GAAK,IAAS4I,EAAQ5I,GAAK,KAEjF,OAAOib,CACT,EAyBAzf,EAAOC,QAvBY,SAAWsI,GAC5B,IAAIiN,EACAtB,EACAG,EAAUzT,OAAOC,OAAQ,MAE7B,IACE2U,EAAMgK,EAAajX,EAAKiN,KAExBtB,EAAMsL,EAAajX,EAAK2L,KAGxB,IAAM,MAAM7D,KAAK9H,EAAK8L,QACpBA,EAAShE,GAAM,IAAIqP,OAAQnX,EAAK8L,QAAShE,GAAK,GAAK9H,EAAK8L,QAAShE,GAAK,GAK1E,CAAE,MAAQhD,GACR,MAAM9G,MAAO,wCAA0C8G,EAAGsS,QAC5D,CACA,MAAQ,CAAEnK,IAAKA,EAAKtB,IAAKA,EAAKG,QAASA,EACzC,C,iBCjCA,IAAIpT,EAAYrB,EAAS,MAGrB2O,EAAsBtN,EAAUsN,oBAEhC4M,EAASla,EAAUka,OAEnB3Z,EAAaP,EAAUO,WAEvByZ,EAAMha,EAAUga,IAEhB/Z,EAASD,EAAUC,OA2HvBlB,EAAOC,QAzHc,SAAW2f,GAG9B,IAAIxd,EAAQwd,EAAKxd,MAEbf,EAASue,EAAKve,OAGdwI,EAAUjJ,OAAOC,OAAQ,MA8G7B,OALAgJ,EAAQuL,UAzFO,SAAWtU,EAAM2Q,EAAUyD,EAAiBC,GAEzD,IAAI0K,EAIJ,OAHAA,EAAMxe,EAAOyB,KAAMV,EAAMoP,IAAK1Q,EAAM2Q,GAAYyD,EAAiB,EAAG,GAEtD,OAATC,GAAiBD,EAAkB,IAAI0K,EAAKre,kBAAqBse,EAAM3e,EAAW,GAAMiU,IACtF,CACT,EAmFAtL,EAAQ0L,mBAjEgB,SAAWzU,EAAMoU,EAAiBC,GAIxD,IAEIsE,EAEAhJ,EAAOjO,EAEPqd,EANAC,EAAa1d,EAAMoO,OAAQ1P,GAS/B,GAAoB,OAAfgf,EAAsB,OAAO7E,EAElC,GAA2B,IAAtB6E,EAAWvd,OACdsd,EAAMxe,EAAOyB,KAAMgd,EAAY,GAAK5K,EAAiB,EAAG,GAM1C,OAATC,GAAiBD,EAAkB,IAAI0K,EAAKre,kBAAqBse,EAAM3e,EAAW,GAAMiU,QAG7F,IAAM,IAAIpS,EAAI,EAAGA,EAAI+c,EAAWvd,OAAQQ,GAAKoY,EAE3C1B,EAAa,IAAN1W,EAAYmS,EAAkB,EAGrCuE,GAAQqG,EAAY/c,EAAI,IAAOwL,EAE/BkC,EAAQqP,EAAY/c,EAAI,GACxBP,EAAQsd,EAAY/c,EAAI,GAExB8c,EAAMxe,EAAOyB,KAAMgd,EAAY/c,GAAK0W,EAAMhJ,EAAUjO,GAAOhB,EAAgB,GAE7D,OAAT2T,GAAiBD,EAAkB,IAAI0K,EAAKre,kBAAqBse,EAAM3e,EAAW,GAAMiU,GAIjG,OAAO,EACT,EAwBAtL,EAAQ6L,SAbO,SAAW5U,GAGxB,OAAOsB,EAAMoO,OAAQ1P,EACvB,EAUA+I,EAAQoD,MARI,WACV5L,EAAS,KACTe,EAAQ,IACV,EAOOyH,CACT,C,WC1JA7J,EAAOC,QAJM,SAAWmQ,EAAG6I,EAAW7F,GACpC,OAAO6F,EAAUnV,KAAK,CAAEic,EAAMvb,IAAO4L,EAAGgD,EAAQ2M,GAAQvb,IAC1D,C,iBCsBA,IAAI7E,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUc,OAAOC,OAAQ,MAE7Bf,EAAQqT,UAAY,IAAIpO,IAAK,CAC3BpF,EAAIqgB,KACJrgB,EAAIsgB,SACJtgB,EAAIkY,aACJlY,EAAIqS,OACJrS,EAAIugB,gBACJvgB,EAAI6C,IACJ7C,EAAIuV,gBACJvV,EAAIka,OACJla,EAAIwgB,MACJxgB,EAAIygB,aACJzgB,EAAI0gB,WACJ1gB,EAAIma,OACJna,EAAIoB,KACJpB,EAAIgB,MACJhB,EAAI2gB,KACJ3gB,EAAI8Q,QAGN3Q,EAAQkT,WAAalT,EAAQqT,UAE7BrT,EAAQygB,cAAgBzgB,EAAQqT,UAEhCrT,EAAQoT,UAAY,IAAInO,IAAK,CAC3BlF,EAAGgF,MACHhF,EAAGiF,IACHjF,EAAGiB,KACHjB,EAAGmF,IACHnF,EAAGoF,UACHpF,EAAGuF,QACHvF,EAAG0F,OACH1F,EAAG8F,aACH9F,EAAGwG,SAILvG,EAAQ0gB,aAAe,IAAIzb,IAAK,CAC9BlF,EAAGgF,MACHhF,EAAGiF,IACHjF,EAAGiB,KACHjB,EAAGmF,IACHnF,EAAGoF,UACHpF,EAAGuF,QACHvF,EAAG0F,OACH1F,EAAGwG,SAGLvG,EAAQW,WAAa,IAAIsE,IAAK,CAC5BpF,EAAIgB,MACJhB,EAAIqS,OACJrS,EAAIoB,KACJpB,EAAIW,OACJX,EAAIqB,OAGNlB,EAAQ2gB,YAAc,IAAI1b,IAAK,CAC7BlF,EAAGgF,MACHhF,EAAGiF,IACHjF,EAAGmF,IACHnF,EAAGoF,UACHpF,EAAG0F,SAGLzF,EAAQ4gB,eAAiB5gB,EAAQ2gB,YAEjC3gB,EAAQ8X,aAAe,IAAI7S,IAAK,CAC9BpF,EAAIgB,MACJhB,EAAIqS,OACJrS,EAAIqB,KACJrB,EAAIgG,aACJhG,EAAIkY,aACJlY,EAAI2K,UACJ3K,EAAI2gB,OAGNxgB,EAAQ6gB,aAAe,IAAI5b,IAAK,CAC9BpF,EAAIgB,MACJhB,EAAIqS,OACJrS,EAAIqB,KACJrB,EAAIgG,aACJhG,EAAIkY,aACJlY,EAAI2K,UACJ3K,EAAI2gB,KACJ3gB,EAAIihB,iBACJjhB,EAAIkhB,yBAIN7gB,EAAOC,QAAUH,C,WC3DjBE,EAAOC,QArBoB,SAAWyN,EAAMnL,GAE1C,MAAMue,EAAMve,EAAS,EACrB,IAAMwe,EAAYC,GAActT,EAehC,OAbKqT,EAAa,IAAIA,GAAcxe,GACpCwe,EAAaxc,KAAKD,IAAKyc,EAAY,GAC9BA,EAAaD,IAAMC,EAAa,GAEhCC,EAAY,IAAIA,GAAaze,GAClCye,EAAYzc,KAAK0c,IAAKD,EAAWF,GAC5BE,EAAYD,IAAaC,EAAYF,GAM1CE,EAAYze,EAASye,EAAY,EAC1B,CAAED,EAAYC,EACvB,C,iBC/BA,IAAI5E,EAAiBxc,EAAS,MAoB9BI,EAAOC,QARe,SAAWG,EAAKC,EAAM2M,GAC1C,IAAIkU,EAAQ,GACZ,IAAM,IAAI1c,EAAI,EAAGA,EAAIpE,EAAI+B,UAAUI,OAAQiC,GAAK,EAC9C0c,EAAMpe,KAAMsZ,EAAgB5X,EAAGpE,EAAKC,EAAM2M,IAE5C,OAAOkU,CACT,C,WCDAlhB,EAAOC,QAPO,SAAWmQ,EAAG3N,EAAOC,EAAK0Q,GACtC,IAAM,IAAIrQ,EAAIN,EAAOM,GAAKL,EAAKK,GAAK,EAElCqN,EAAGgD,EAAQrQ,GAAOA,EAAIN,EAE1B,C,iBCbA,MAAM0e,EAAkBvhB,EAAS,MAC3BwhB,EAAqBxhB,EAAS,MAqdpCI,EAAOC,QA9cS,SAAWmC,EAAOif,GAEhC,IAAIxX,EAAUjJ,OAAOC,OAAQ,MAIzBkH,EAAMnH,OAAOC,OAAQ,MAKzB,IAQIygB,EAEAC,EAVAC,EAAiB,EAEjBC,EAAiB7gB,OAAOC,OAAQ,MAEhC6gB,EAAe9gB,OAAOC,OAAQ,MAE9B8gB,EAAyB/gB,OAAOC,OAAQ,MAO5C,MAAM+gB,OAAuCle,IAAjB2d,EAA+B,KAAOA,EAO5DQ,OAAoBne,IAAVtB,GAAiC,OAAVA,EAAmBwf,EAAmBxf,EAAMoO,OAAQoR,GAAoB,GACzGE,OAAuBpe,IAAVtB,GAAiC,OAAVA,EApC1B,YADA,MAyCV2f,OAAwBre,IAAVtB,EAtCH,aADA,QAsDjB,IAAI4f,EAAe,SAAW9hB,EAAOgG,EAAM+b,GAEzC,OAAK/hB,IAAUgG,GAAQ+b,EAAgBA,EAGvCT,GAAiB,CAEnB,EAcIU,EAAqB,SAAW1U,EAAM2U,EAASzU,EAAM0U,GACvD,MAAM7f,EAAS4f,EAAQ5f,OAEjB2D,EAAO3D,EAAS,EAGhB0f,OAASve,EAGf,IAII2e,EAAIC,EAJJC,EAzEO,EA2EPC,EA3EO,EAiFX,IAAM,IAAIzf,EAAI,EAAGA,EAAIR,EAAQQ,GAAK,EAChCsf,EAAKF,EAASpf,QAEQW,IAAjBqE,EAAKwa,KACRxa,EAAKwa,GAAU3hB,OAAOC,OAAQ,MAC9BkH,EAAKwa,GAASR,GAAcS,QAGF9e,IAAvBqE,EAAKwa,GAASF,IAGjBC,EAAYN,EAAcjf,EAAGmD,EAAM+b,GACnCla,EAAKwa,GAASF,GAAOC,EAIrBC,EAAQD,GACEb,EAAgB1Z,EAAKwa,GAASF,KAlGjC,IAqGAta,EAAKwa,GAASR,KAAuBha,EAAKwa,GAASR,GAAcS,GACtEA,EAAWza,EAAKwa,GAASF,GACzBC,EAAYN,EAAcjf,EAAGmD,EAAM+b,GACnCla,EAAKwa,GAASF,GAAOC,EAErBC,EAAQD,GACEvf,IAAMmD,GAGdoc,EAAYN,EAAcjf,EAAGmD,EAAM+b,GACnCla,EAAKA,EAAKwa,GAASF,IAAQN,GAAcO,EACzCC,EAAQD,GAKRC,EAAQxa,EAAKwa,GAASF,GAG9BZ,EAAgBc,GAAU/U,EAErBE,IAGHgU,EAAca,GAAUnB,EAAoB1T,EAAMnL,SAG5BmB,IAAnB0e,IACHT,EAAwBY,GAAUH,EAEtC,EAyEIK,EAAqB,SAAWhV,EAAU4H,GAE5C,IAAIqN,EAAKrN,EAAO,GAEhB,GAA8B,MAAzBoM,EAAgBiB,GAArB,CAEA,IAAIhV,EAAOgU,EAAcgB,GACrBN,EAAiBT,EAAwBe,GACxChV,IACH2H,EAAO,IAAO3H,EAAM,GACpB2H,EAAO,IAAO3H,EAAM,IAIjB6T,GACHA,EAAsBlM,EAAO+M,GAE/B/M,EAAO,GAAMoM,EAAgBiB,GAE7BjV,EAAS3K,KAAMuS,EAf2B,CAgB5C,EAmOA,OAbAxL,EAAQoE,MApSI,SAAWR,GAErB,IAAIkV,EAAM/hB,OAAOC,OAAQ,MAErB+hB,EAAK,GACT,IAAM,IAAIpe,EAAI,EAAGA,EAAIiJ,EAASlL,OAAQiC,GAAK,EAAI,CAC7C,MAAMqe,EAAKpV,EAAUjJ,GACrB,GAA2B,kBAAfqe,EAAGV,QAAuB,CACpC,MAAMW,EAAM3B,EAAiB0B,EAAGV,SAChC,IAAM,IAAIlb,EAAI,EAAGA,EAAI6b,EAAIvgB,OAAQ0E,GAAK,EACpC2b,EAAG9f,KAAM,CAAE0K,KAAMqV,EAAGrV,KAAM2U,QAASW,EAAK7b,GAAKyG,KAAMmV,EAAGnV,KAAM0U,eAAgBS,EAAGT,gBACnF,MAAOQ,EAAG9f,KAAM,CAAE0K,KAAMqV,EAAGrV,KAAM2U,QAASU,EAAGV,QAASzU,KAAMmV,EAAGnV,KAAM0U,eAAgBS,EAAGT,gBAC1F,CAEAQ,EAAGzd,MAAM,CAAE8R,EAAGC,IAASA,EAAEiL,QAAQ5f,OAAS0U,EAAEkL,QAAQ5f,SAEpD,IAAM,IAAIiC,EAAI,EAAGA,EAAIoe,EAAGrgB,OAAQiC,GAAK,EACnC0d,EAAoBU,EAAIpe,GAAIgJ,KAAMoV,EAAIpe,GAAI2d,QAASS,EAAIpe,GAAIkJ,KAAMkV,EAAIpe,GAAI4d,gBAG3E,IAAM,MAAMW,KAAMtB,EAAiBkB,EAAKlB,EAAgBsB,KAAS,EACjE,OAAWniB,OAAOiD,KAAM8e,GAAQpgB,MAClC,EA+QAsH,EAAQ6C,UAhLQ,SAAWrL,EAAQ2hB,EAAgBC,GAEjD,MAAM1gB,EAASlB,EAAOkB,OAEtB,IAaI2gB,EACAC,EAEAxgB,EAhBAygB,EAA+C,oBAAnBJ,EAAkCA,EAAiB,KAG/EvV,EAAW,GAGXxH,EAAQ,EACRsc,EAlRO,EAoRPc,EApRO,EA8RPC,EAAQ,EAEZ,IAAM,IAAI9e,EAAI,EAAGA,GAAKjC,EAAQiC,GAAK,EAKjC,IAAM,IAAIyC,EAAIzC,EAAGyC,GAAK1E,EAAQ0E,GAAKqc,GAEjC3gB,EAAMsE,IAAM1E,EAAYuf,EAAWzgB,EAAQ4F,MAIhC4a,IAGNP,GAAiBA,EAAera,IACnCtE,EAAI2e,EAAera,GAAK,GACxBqc,EAAQhC,EAAera,GAAK,GAAMA,EAAI,GACjCqc,EAAQ,EAIVF,GAAsBnc,EAAI1E,IAAWI,EAAIygB,EAAkBzgB,EAAGP,EAAO6gB,EAAOhc,IAGjFoc,EAAKtb,EAAKwa,GAAS5f,IAxTZ,GA4TD4f,GAASc,IAAKpd,EAAQgB,GAEvBwa,EAAgB4B,IAGnBZ,EAAoBhV,EADhB,CAAExH,EAAOgB,EAAIqc,EAAQ,EAAGD,IAI5B7e,EAAIyC,EAEJA,EAAI1E,EAAS,IAEb8gB,EAxUK,EA0ULF,EA1UK,OA2UKE,IAELF,GAIHV,EAAoBhV,EADhB,CAAExH,EAAOid,EAAoBC,IAIjC3e,EAAI0e,EAEJjc,EAAI1E,EAAS,IAEb8gB,EAxVG,EA0VHF,EA1VG,GA+VHlc,EAAI1E,EAAS,KAMZwF,EAFLwa,EAAQc,GAEWtB,KAEjBmB,EAAqBjc,EAAIqc,EAAQ,EACjCH,EAAqBpb,EAAKwa,GAASR,KAKzC,OAAOtU,CACT,EA0EA5D,EAAQ4C,eA5Ma,SAAWgB,GACxBA,GAAavJ,MAAMgH,QAASuC,IAKlC6T,EAAgB1gB,OAAOC,OAAQ,MAE/B4M,EAAStI,MAAM,CAAE8R,EAAGC,IAASD,EAAG,GAAMC,EAAG,KAEzCzJ,EAASrJ,SAAWL,GAASud,EAAevd,EAAG,IAAQ,CAAEA,EAAG,GAAKA,EAAG,OARlEud,OAAgB5d,CASpB,EAkMAmG,EAAQ0Z,wBAtQsB,SAAWnT,GACvC,MAAkB,oBAANA,IACVmR,EAAuBnR,GAChB,EAGX,EAiQAvG,EAAQ2Z,WAlES,WACf,OAAOlW,KAAKC,UACV,CAAE,IAAKiU,EAAezZ,EAAK0Z,EAAgBC,EAAcC,GAE7D,EA+DA9X,EAAQ6B,WA9BS,SAAW+X,GAC1B,IAAIjb,EAAS8E,KAAKM,MAAO6V,GACzBjC,EAAgBhZ,EAAO,GACvBT,EAAMS,EAAO,GACbiZ,EAAiBjZ,EAAO,GACxBkZ,EAAelZ,EAAO,GACtBmZ,EAAyBnZ,EAAO,EAClC,EAwBAqB,EAAQ6Z,eAvDa,WAEnB,MAAMhB,EAAK9hB,OAAOC,OAAQ,MAE1B,OADA6hB,EAAI,GAAM9hB,OAAOC,OAAQ,MAClByM,KAAKC,UACV,CAAE,IACA,EACAmV,EACA9hB,OAAOC,OAAQ,MACfD,OAAOC,OAAQ,MACfD,OAAOC,OAAQ,OAGrB,EA4CAgJ,EAAQ8Z,WAvBS,WACf7K,QAAQ8B,IAAK,kBACb9B,QAAQ8B,IAAKtN,KAAKC,UAAWxF,EAAK,KAAM,IACxC+Q,QAAQ8B,MACR9B,QAAQ8B,IAAK,oBACb9B,QAAQ8B,IAAKtN,KAAKC,UAAWkU,EAAgB,KAAM,IACnD3I,QAAQ8B,MACR9B,QAAQ8B,IAAK,kBACb9B,QAAQ8B,IAAKtN,KAAKC,UAAWmU,EAAc,KAAM,IACjD5I,QAAQ8B,MACR9B,QAAQ8B,IAAK,0BACb9B,QAAQ8B,IAAKtN,KAAKC,UAAWoU,EAAwB,KAAM,GAC7D,EAeAK,EAAc,EAAG,EAAG,IACbnY,CACT,C,iBCtdA,IAAIlK,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBqc,EAAerc,EAAS,KAwB5BI,EAAOC,QAVc,SAAW2jB,EAAazjB,EAAUC,EAAKC,EAAMyS,GAChE,IAAI+Q,EAAO,GACX,IAAM,IAAIrf,EAAI,EAAGA,EAAIof,EAAYrhB,OAAQiC,GAAK,EAC5Cqf,EAAK/gB,KAAMmZ,EAAc2H,EAAapf,GAAKrE,EAAUC,EAAKC,IAI5D,OADaP,EAAQ4gB,eAAehgB,IAAKoS,IAASzS,IAASV,EAAIW,QAAUD,IAASV,EAAIqB,KAAS8R,EAAMjT,EAAGgF,OAC3Fgf,EACf,C,WCNA7jB,EAAOC,QARY,SAAW8C,EAAGN,EAAOC,EAAK0Q,GAE3C,IAAI0Q,EAAK/gB,EAAIN,EACb,GAAKqhB,EAAKrhB,GAASqhB,EAAKphB,EACtB,MAAM6D,MAAO,aAAaxD,2CACrB,OAAOqQ,EAAQ0Q,EACxB,C,iBCjBA,IAAI1c,EAAiBxH,EAAS,MAC1BmkB,EAAWnkB,EAAS,MACpB6H,EAAU7H,EAAS,MACnB0f,EAA0B7X,EAAQ6X,wBAClC1X,EAA2BH,EAAQG,yBAEnC2B,EAAcwa,IAEdC,EAAQ,wEACRC,EAAU,MAWVC,EAAwB,SAAWC,EAAOC,GAC5C,MAAQC,KAAOC,GAAWH,EAC1B,YAAkBzgB,IAAP2gB,EAAqBD,EAAQ,CAAEC,KAAOH,EAAuBE,EAAOE,GACjF,EA4OAtkB,EAAOC,QAnNQ,SAAWskB,EAAUniB,EAAOqG,EAAUoF,GAEnD,IAEItC,EAFA1B,EAAUjJ,OAAOC,OAAQ,MAI7B0I,EAAYmC,WAAY6Y,GAGxBhb,EAAYga,yBAAyB,CAAElO,EAAO+M,IAAsB/M,EAAMvS,KAAMsf,KAUhF,IAYIoC,EAAyB,SAAWzgB,GAEtC,MAAO,IAAMA,EAAK,GACpB,EAgCI0gB,EAAuB,SAAW3jB,GAEpC,MAAM8hB,EAAK,GAELvhB,EA3BW,SAAWP,GAE5B,IAAIV,EAAMQ,OAAOC,OAAQ,MACzBT,EAAIgC,MAAQA,EACZhC,EAAIiB,OAAS,GACb,IAAIgL,EAAiBjF,EAAgBhH,GAErCqI,EAAU4D,EAAgBvL,GAC1B,MAAMO,EAAS,GACTqjB,EAASpF,EAAyBlf,GAAM0D,KAAOnB,GAAOP,EAAMzB,MAAOgC,KACnEgiB,EAAU/c,EAA0BxH,GAAM0D,KAAOnB,GAAOP,EAAMzB,MAAOgC,KAC3E,IAAM,IAAI6B,EAAI,EAAGA,EAAIkgB,EAAOniB,OAAQiC,GAAK,EAAInD,EAAOyB,KAAM,CAAEnC,MAAO+jB,EAAQlgB,GAAKwN,OAAQ2S,EAASngB,KACjG,OAAOnD,CACT,CAciBujB,CAAc9jB,GAGvByS,EAAQhK,EAAYmD,UAAWrL,EAAOyC,KAAOnB,GAAOA,EAAEhC,SAItDkkB,EAAejkB,OAAOC,OAAQ,MACpC0S,EAAMnP,SAAWL,GAAS8gB,EAAc9gB,EAAG,IAAQ,CAAEA,EAAG,GAAKA,EAAG,GAAKA,EAAG,MAExE,IAAM,IAAIS,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAK,EAIvC,GAAKqgB,EAAcrgB,GAAM,CAEvB,GAAiC,KAA5BqgB,EAAcrgB,GAAK,GAGtB,GAAKqgB,EAAcrgB,GAAK,GAAI+G,SAAW,CAKrC,MAAMuZ,EAASjX,EAAexM,EAAQwjB,EAAcrgB,GAAK,IAAM7D,MAAQU,EAAQwjB,EAAcrgB,GAAK,IAAMwN,OAElG+S,EAAQlX,EAAegX,EAAcrgB,GAAK,GAAMqgB,EAAcrgB,GAAK,GAAIwC,cAE7EuE,EAAUuZ,GAASC,EACnBnC,EAAG9f,KAAMiiB,EACX,MAGEnC,EAAG9f,KAAM+hB,EAAcrgB,GAAK,IAIhCA,EAAIqgB,EAAcrgB,GAAK,EACzB,KAAO,CAEL,MAAMwgB,EAAOnX,EAAexM,EAAQmD,GAAI7D,MAAQU,EAAQmD,GAAIwN,OAC5D4Q,EAAG9f,KAAMkiB,GACTzZ,EAAUyZ,GAAOA,CACnB,CAGF,OAAOpC,CACT,EA+CIqC,EAAuB,SAAWnkB,GAEpC,MAAMokB,EAAQpkB,EAAK4E,OAAOqR,MAAO,OAEjC,OAnJ2D,IAmJxCmO,EAnJHC,WAAaphB,GAAOigB,EAAMjP,KAAMhR,KAyG3B,SAAW1C,GAChC,MAAM8gB,EAAU,GAChB,IAAM,IAAI3d,EAAI,EAAGA,EAAInD,EAAOkB,OAAQiC,GAAK,EACvC,GAAKwf,EAAMjP,KAAM1T,EAAQmD,IAAQ,CAE/B,MAAMwgB,EAAK3jB,EAAQmD,GAAI4gB,UAAW,EAAG/jB,EAAQmD,GAAIjC,OAAS,GAEpDkW,EAAUuM,EAAG3P,MAAO4O,IAAa,GAEjCK,EAASU,EAAGjO,MAAOkN,GAGzB,IAAM,IAAIhd,EAAI,EAAGA,EAAIqd,EAAO/hB,OAAQ0E,GAAK,EAAI,CAC3C,MAAMoe,EAAuB,KAAhBf,EAAQrd,GAAe,CAAE,IAAOwd,EAAsBH,EAAQrd,IAC3E,GAAKoe,EAAG9iB,OAAS,EAChB,MAAMgE,MAAO,8BAA8B8e,EAAG9hB,KAAM,8DAErD+gB,EAAQrd,GAAMoe,EAAI,EACpB,CAEAlD,EAAQrf,KAAM0hB,EAAwBN,EAAuBI,EAAQ7L,GAAUlV,KAAM,KACvF,MAEEkhB,EAAsBpjB,EAAQmD,IAAMJ,SAAWzB,GAAOwf,EAAQrf,KAAM0hB,EAAwB7hB,MAGhG,OAAOwf,EAAQ5e,KAAM,IACvB,CAgBW+hB,CAAkBJ,GAEpBT,EAAsB3jB,EAC/B,EAoCA,OAFA+I,EAAQmE,IArBE,SAAWb,GAEnB,MAAMoY,EAAM,GAEZha,EAAW3K,OAAOC,OAAQ,MAC1B,IAAM,IAAI2D,EAAI,EAAGA,EAAI2I,EAAS5K,OAAQiC,GAAK,EAAI,CAC7C,MAAMghB,EAAUrY,EAAU3I,GACpBiJ,EAAW+X,EAAQ/X,SACzB,IAAM,IAAIxG,EAAI,EAAGA,EAAIwG,EAASlL,OAAQ0E,GAAK,EAAI,CAC7C,MAAM2b,EAAKqC,EAAsBxX,EAAUxG,IACrCwe,EAAK7kB,OAAOC,OAAQ,MAC1B4kB,EAAGjY,KAAOgY,EAAQhY,KAClBiY,EAAGtD,QAAUS,EACR4C,EAAQ9X,OAAO+X,EAAG/X,KAAO8X,EAAQ9X,MACtC6X,EAAIziB,KAAM2iB,EACZ,CACF,CAEA,MAAO,CAAEtY,SAAUoY,EAAKha,SAAUA,EACpC,EAIO1B,CACT,C,iBCjQA,IAAIlK,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBqc,EAAerc,EAAS,KAuB5BI,EAAOC,QAVc,SAAWE,EAAUC,EAAKC,EAAMyS,GACnD,IAAI+Q,EAAO,GACX,IAAM,IAAIrf,EAAI,EAAGA,EAAIrE,EAASoC,OAAQiC,GAAK,EACzCqf,EAAK/gB,KAAMmZ,EAAczX,EAAGrE,EAAUC,EAAKC,IAI7C,OADaP,EAAQ2gB,YAAY/f,IAAKoS,IAASzS,IAASV,EAAIW,QAAUD,IAASV,EAAIqB,KAAS8R,EAAMjT,EAAGgF,OACxFgf,EACf,C,iBCxBA,IAAI7b,EAASpI,EAAS,MAkBtBI,EAAOC,QANa,SAAWylB,EAAeC,EAAkBC,GAC9D,IAAI7iB,EAAIiF,EAAQ0d,EAAeC,GAC/B,GAAW,OAAN5iB,EACL,OAAO6iB,EAAc7iB,EACvB,C,iBChBA,IAAIkF,EAASrI,EAAS,MAyDtBI,EAAOC,QA3CiB,SAAW2F,EAAUnD,EAAOC,GAClD,QAAkBgB,IAAbkC,QAAoClC,IAAVjB,QAA+BiB,IAARhB,EACpD,OAAO,KAIT,IAGImjB,EAAIC,EAHJ/f,EAAOkC,EAAQxF,EAAOmD,GACtBI,EAAQiC,EAAQvF,EAAKkD,GACrB+N,EAAW/N,EAASrD,OAAS,EAKjC,GAAOwD,EAAO,GAAKC,EAAQ,GAASD,EAAO4N,GAAY3N,EAAQ2N,EAC7D,OAAO,KAST,GAJAkS,EAAO9f,EAAO,EAAM,EAAIxB,KAAKwhB,KAAMhgB,GAI5BA,IAASC,GAAa6f,IAAO9f,EAClC,OAAO,KAQT,GALA+f,EAAKvhB,KAAKyhB,MAAOhgB,GAGZJ,EAAUigB,GAAM,GAAMpjB,IAAQojB,GAAM,GACpCjgB,EAAUkgB,GAAM,GAAMpjB,IAAQojB,GAAM,GACpCD,EAAKC,EACR,OAAO,KAGT,IAAIhgB,EAAQlF,OAAOC,OAAQ,MAI3B,OAHAiF,EAAMC,KAAO8f,EACb/f,EAAME,MAAQ8f,EAEPhgB,CACT,C,iBCvDA,IAAInB,EAAU/E,EAAS,MACnBqB,EAAYrB,EAAS,MACrBqmB,EAAU,CAAE,QAAS,YAAa,YAAa,aAC/CC,EAAMtmB,EAAS,KACfiT,EAAoBjT,EAAS,KAG7BsB,EAASD,EAAUC,OAEnBM,EAAaP,EAAUO,WAEvBC,EAAUR,EAAUQ,QAEpByZ,EAAYja,EAAUia,UAEtBvb,EAAMiB,OAAOC,OAAQ,MAEzBlB,EAAIqgB,KAAO,SAAW9f,EAAOE,GAC3B,OAAO6lB,EAAS7lB,EAAIgC,MAAM4O,SAAU5Q,EAAIiB,OAAQnB,EAAQgB,GAAU,WACpE,EAEAvB,EAAIsgB,SAAW,SAAW/f,EAAOE,GAC/B,OAAOA,EAAIiB,OAAQnB,EAAQgB,EAC7B,EAEAvB,EAAIkY,aAAe,SAAW3X,EAAOE,GACnC,OAAOA,EAAIiB,OAAUnB,EAAQgB,EAAW,IAAOD,EAAU4W,YAC3D,EAEAlY,EAAIqS,OAAS,SAAW9R,EAAOE,GAC7B,IAAIiB,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MAChB,OACIf,EAAUnB,EAAQgB,EAAW,GAAM,MACnCkB,EAAMzB,MAAOyB,EAAMgQ,IAAK/Q,EAAUnB,EAAQgB,EAAW,KACrDkB,EAAMzB,MAAOyB,EAAM4P,OAAQ3Q,EAAQnB,EAAQgB,IAEjD,EAEAvB,EAAIugB,gBAAkB,SAAWhgB,EAAOE,GACtC,OAASA,EAAIiB,OAAUnB,EAAQgB,EAAW,GAAM,KAClD,EAEAvB,EAAI6C,IAAM,SAAWtC,EAAOE,GAC1B,OAAOA,EAAIgC,MAAMS,QAAS,OAASzC,EAAIiB,OAAUnB,EAAQgB,EAAW,GAAMO,KAAcD,EAC1F,EAEA7B,EAAIuV,gBAAkB,SAAWhV,EAAOE,GACtC,OAAOyS,EAAmB3S,EAAOE,EACnC,EAEAT,EAAIka,OAAS,SAAW3Z,EAAOE,GAC7B,OAAOA,EAAIgC,MAAM4O,SAAU5Q,EAAIiB,OAAQnB,EAAQgB,GAAU,SAC3D,EAEAvB,EAAIwgB,MAAQ,SAAWjgB,EAAOE,GAC5B,OAAOA,EAAIgC,MAAM4O,SAAU5Q,EAAIiB,OAAQnB,EAAQgB,GAAU,QAC3D,EAEAvB,EAAIygB,aAAe,SAAWlgB,EAAOE,GACnC,IAAIiB,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MAGZ4P,EAAW3Q,EAAUnB,EAAQgB,EAAW,GAAM,MAChDkB,EAAMgQ,IAAK/Q,EAAUnB,EAAQgB,EAAW,IACxCkB,EAAM4P,OAAQ3Q,EAAQnB,EAAQgB,IAChC,OAAoD,IAA3CkB,EAAM4O,SAAUgB,EAAQ,aACnC,EAEArS,EAAI0gB,WAAa,SAAWngB,EAAOE,GACjC,OAA4E,IAAnEA,EAAIgC,MAAM4O,SAAU5Q,EAAIiB,OAAQnB,EAAQgB,GAAU,WAC7D,EAEAvB,EAAIma,OAAS,SAAW5Z,EAAOE,GAC7B,OAAOA,EAAIgC,MAAM4O,SAAU5Q,EAAIiB,OAAQnB,EAAQgB,GAAU,SAC3D,EAEAvB,EAAIoB,KAAO,SAAWb,EAAOE,GAC3B,OAAOA,EAAIgC,MAAM4O,SAAU5Q,EAAIiB,OAAQnB,EAAQgB,GAAU,YAC3D,EAEAvB,EAAIgB,MAAQ,SAAWT,EAAOE,GAC5B,OAAOA,EAAIgC,MAAMzB,MAAOP,EAAIiB,OAAQnB,EAAQgB,GAC9C,EAEAvB,EAAI2gB,KAAO,SAAWpgB,EAAOE,EAAK4M,GAChC,OAAOA,EAAOsT,KAAMlgB,EAAIgC,MAAMzB,MAAOP,EAAIiB,OAAQnB,EAAQgB,IAC3D,EAEAvB,EAAI8Q,MAAQ,SAAWvQ,EAAOE,EAAK4M,GACjC,IAAI3L,EAASjB,EAAIiB,OACbe,EAAQhC,EAAIgC,MAEhB,GAAKf,EAAUnB,EAAQgB,EAAW,GAAM,MACtC,OAAOkB,EAAMzB,MAAOU,EAAUnB,EAAQgB,EAAW,GAAMga,GAGzD,MAAMiL,EAAY/jB,EAAMuQ,eAAgBtR,EAAQnB,EAAQgB,IAExD,GAAiD,IAA5CkB,EAAM4O,SAAUmV,EAAW,YAC9B,OAAO/jB,EAAMzB,MAAOyB,EAAM4O,SAAUmV,EAAW,UAGjD,MAAM3jB,EAAM7C,EAAI6C,IAAKtC,EAAOE,GACtBO,EAAQyB,EAAMzB,MAAOyB,EAAM4P,OAAQ3Q,EAAQnB,EAAQgB,KACzD,OAAO8L,EAAOoZ,UAAWzlB,EAAO6B,EAAKJ,EACvC,EAEAzC,EAAI0G,OAAS,WACX,OAAS,IAAInC,MAAO,KAAMC,KAAM,EAClC,EAEAxE,EAAIW,OAAS,WACX,OAAO,CACT,EAEAX,EAAIgG,aAAe,SAAWzF,EAAOE,GAInC,OAAOT,EAAIgB,MAAOT,EAAOE,EAC3B,EAEAT,EAAIqB,KAAO,SAAWqlB,GACpB,OAAOA,EAASpjB,MAAO,EAAG,EAC5B,EAEAtD,EAAI2K,UAAY,SAAW+b,GACzB,OAAOA,EAAU,EACnB,EAEA1mB,EAAIihB,iBAAmB,SAAWxgB,EAAK4M,GACrC,OAAOA,EAAO4T,iBAAkBxgB,EAAKT,EACvC,EAEAA,EAAIkhB,uBAAyB,SAAWzgB,GACtC,OAAO8lB,EAAK9lB,EACd,EAIAT,EAAI2mB,MAAQ,SAAWC,EAAIC,EAAKF,GAC9B,OAAOA,CACT,EAEA3mB,EAAI8mB,cAAgB,SAAWF,EAAIC,EAAKF,GACtC,MAAMI,EAAM,IAAIxiB,MAAOqiB,EAAGhkB,QAC1B,IAAM,IAAIokB,EAAK,EAAGA,EAAKJ,EAAGhkB,OAAQokB,GAAM,EAAI,CAC1CD,EAAKC,GAAO,GACZ,IAAM,IAAIniB,EAAI,EAAGA,EAAI8hB,EAAM/jB,OAAQiC,GAAK,EACtCkiB,EAAKC,GAAK7jB,KAAMyjB,EAAII,GAAML,EAAO9hB,KAAS,EAE9C,CACA,OAAOkiB,CACT,EAEA/mB,EAAIinB,YAAc,SAAWL,GAC3B,OAAOA,CACT,EAEA5mB,EAAIqF,IAAM,SAAWuhB,GACnB,OAAOA,CACT,EAEA5mB,EAAI6mB,IAAM,SAAWD,EAAIC,GACvB,IAAIK,EAAM,GACV,IAAM,MAAMlkB,KAAK6jB,EACfK,EAAI/jB,KAAM,CAAEH,EAAG6jB,EAAK7jB,KAGtB,OAAOkkB,EAAI1hB,KAAMR,EACnB,EAEAhF,EAAI4mB,GAAK,SAAWA,GAClB,MAAMM,EAAM,GACZ,IAAM,MAAMlkB,KAAK4jB,EACfM,EAAI/jB,KAAM,CAAEH,EAAG4jB,EAAI5jB,KAGrB,OAAOkkB,EAAI1hB,KAAMR,EACnB,EAEAhF,EAAImnB,UAAY,SAAWP,EAAIC,EAAKF,EAAOS,EAAOC,GAChD,OAAO1Z,KAAKC,UAAW,CACnB0Z,IAAK,qCACLV,GAAIA,EACJC,IAAKA,EACLF,MAAOA,EACPS,MAAOA,EACPC,YAAaA,GAEnB,EAEAhnB,EAAOC,QAAUN,C,WC9KjBK,EAAOC,QARS,SAAWmQ,EAAG6I,EAAW7F,EAAQ0H,GAC/C,IAAIC,EAAW,GACf,IAAM,IAAIhY,EAAI,EAAGA,EAAIkW,EAAU1W,OAAQQ,GAAK,EACrCqN,EAAGgD,EAAQ6F,EAAWlW,IAAOA,IAAMgY,EAASjY,KAAMmW,EAAWlW,IAEpE,OAAO+X,EAAeC,EACxB,C,iBClBA,IAAIpb,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBiT,EAAoBjT,EAAS,KAC7BqB,EAAYrB,EAAS,MAEZqB,EAAUC,OAEVD,EAAUE,OAuCvBnB,EAAOC,QAzBY,SAAWinB,EAAW9mB,EAAKC,EAAMyS,EAAK9F,GAEvD,IAAI+F,EAAa,GACbvS,EAAUH,GAAQP,EAAQygB,cAAc7f,IAAKL,GAAWA,EAAOV,EAAIgB,MACnEsS,EAASH,GAAOhT,EAAQ0gB,aAAa9f,IAAKoS,GAAUA,EAAMjT,EAAGgF,MAEjE,GAAKrE,IAAUb,EAAIgB,OAASH,IAAUb,EAAIqS,QAAUxR,IAAUb,EAAI8Q,OAASwC,IAASpT,EAAGwG,OACrF,MAAME,MAAO,yEAKf,GAAK0M,IAASpT,EAAGiB,KACf,IAAM,IAAI0D,EAAI,EAAGA,EAAI0iB,EAAU3kB,OAAQiC,GAAK,EAC1CuO,EAAWjQ,KAAM+P,EAAmBqU,EAAW1iB,GAAKpE,GAAOC,EAAM6mB,EAAW1iB,GAAKpE,EAAK4M,SAGxF,IAAM,IAAIxI,EAAI,EAAGA,EAAI0iB,EAAU3kB,OAAQiC,GAAK,EAC1CuO,EAAWjQ,KAAMtC,EAAO0mB,EAAW1iB,GAAKpE,EAAK4M,IAIjD,OAAOiG,EAAMF,EAAY3S,EAC3B,C,iBC7CA,IAAIT,EAAMC,EAAS,MACfC,EAAKD,EAAS,KACdE,EAAUF,EAAS,MACnBG,EAAeH,EAAS,KAyC5BI,EAAOC,QA7Bc,SAAWG,EAAKC,EAAM2M,GACzC,IAAIV,EAAWlM,EAAIkM,SAEf9L,EAAUH,GAAQP,EAAQ6gB,aAAajgB,IAAKL,GAAWA,EAAOV,EAAIgB,MAEtE,GAAKH,IAAUb,EAAIqB,MAAQR,IAAUb,EAAI2K,UACvC,OAAO9J,EAAO8L,GAIhB,GAAK9L,IAAUb,EAAIkY,aACjB,OAA2B,IAAlBvL,EAAU,GAGrB,GAAK9L,IAAUb,EAAIihB,iBACjB,OAAOpgB,EAAOJ,EAAK4M,GAGrB,GAAKxM,IAAUb,EAAIkhB,uBACjB,OAAOrgB,EAAOJ,GAKhB,IAAI6S,EAASzS,IAAUb,EAAIgG,aAAiB9F,EAAG8F,aAAe9F,EAAGiB,KAEjE,OAAOf,EAAcuM,EAAU,GAAKA,EAAU,GAAKlM,EAAKI,EAAOyS,EAAMjG,EACvE,C,WCRAhN,EAAOC,QAtBM,SAAWqT,EAAOC,GAO7B,IANA,IAEIC,EACAC,EAHAC,EAAW,EACXC,EAAWJ,EAAMhR,OAAS,EAKtBmR,GAAYC,GAKlB,GAHAF,EAAYF,EADZC,GAAcE,EAAWC,GAAa,EAAI,GACV,GAG3BL,EAFQC,EAAOC,GAAa,GAG/BE,EAAWF,EAAY,MAClB,MAAKF,EAAQG,GAEb,OAAOD,EADZG,EAAWH,EAAY,CACF,CAGzB,OAAO,IACT,C,iBChCA,IAAIvL,EAASrI,EAAS,MAiDtBI,EAAOC,QAnCiB,SAAWE,EAAUgnB,EAAeC,GAC1D,IAMIvB,EAAIC,EAEJthB,EARAuB,EAAOkC,EAAQkf,EAAehnB,GAC9B6F,EAAQiC,EAAQmf,EAAajnB,GAC7BwT,EAAWxT,EAASoC,OAAS,EAE7B8kB,EAAY,GAQhB,GAAOthB,EAAO,GAAKC,EAAQ,GAASD,EAAO4N,GAAY3N,EAAQ2N,EAC7D,OAAO0T,EAQT,GAHAxB,EAAO9f,EAAO,EAAM,EAAIxB,KAAKwhB,KAAMhgB,GAG5BA,IAASC,GAAa6f,IAAO9f,EAClC,OAAOshB,EAKT,IADAvB,EAAKvhB,KAAKyhB,MAAOhgB,GACXxB,EAAIqhB,EAAIrhB,GAAKshB,EAAIthB,GAAK,EAC1B6iB,EAAUvkB,KAAM0B,GAGlB,OAAO6iB,CACT,C","sources":["../node_modules/wink-nlp/src/api/itm-entity-out.js","../node_modules/wink-nlp/src/reconstruct-spaces.js","../node_modules/wink-nlp/src/sentence-wise-importance.js","../node_modules/wink-nlp/src/as.js","../node_modules/wink-nlp/src/wink-nlp.js","../node_modules/wink-nlp/src/cache.js","../node_modules/wink-nlp/src/api/col-tokens-out.js","../node_modules/wink-nlp/src/api/itm-token-out.js","../node_modules/wink-nlp/src/api/col-map.js","../node_modules/wink-nlp/src/locate.js","../node_modules/wink-nlp/src/tokenizer.js","../node_modules/wink-nlp/src/sort4FT.js","../node_modules/wink-nlp/src/helper.js","../node_modules/wink-nlp/src/api/itm-sentence-out.js","../node_modules/wink-nlp/src/compose-patterns.js","../node_modules/wink-nlp/src/api/sel-each.js","../node_modules/wink-nlp/src/recursive-tokenizer.js","../node_modules/wink-nlp/src/api/print-tokens.js","../node_modules/wink-nlp/src/api/col-filter.js","../node_modules/wink-nlp/src/constants.js","../node_modules/wink-nlp/src/api/sel-get-item.js","../node_modules/wink-nlp/src/doc-v2.js","../node_modules/wink-nlp/src/tokens-mappers.js","../node_modules/wink-nlp/src/compile-trex.js","../node_modules/wink-nlp/src/dd-wrapper.js","../node_modules/wink-nlp/src/api/sel-map.js","../node_modules/wink-nlp/src/allowed.js","../node_modules/wink-nlp/src/identify-marked-area.js","../node_modules/wink-nlp/src/api/col-sentences-out.js","../node_modules/wink-nlp/src/api/col-each.js","../node_modules/wink-nlp/src/automaton.js","../node_modules/wink-nlp/src/api/sel-entities-out.js","../node_modules/wink-nlp/src/api/col-get-item.js","../node_modules/wink-nlp/src/examples-compiler.js","../node_modules/wink-nlp/src/api/col-entities-out.js","../node_modules/wink-nlp/src/api/get-parent-item.js","../node_modules/wink-nlp/src/contained-markings.js","../node_modules/wink-nlp/src/its.js","../node_modules/wink-nlp/src/api/sel-filter.js","../node_modules/wink-nlp/src/api/sel-tokens-out.js","../node_modules/wink-nlp/src/api/itm-document-out.js","../node_modules/wink-nlp/src/search.js","../node_modules/wink-nlp/src/contained-entities.js"],"sourcesContent":["//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar colTokensOut = require( './col-tokens-out.js' );\n\n// ## itmEntityOut\n/**\n * Out method for an entity. Note: the out always returns a Javascript\n * data type or data structure. There is no word vector support for entity.\n * @param  {number}   index       The index of desired entity.\n * @param  {Object}   entities    The entities from the `rdd`; could be custom.\n * @param  {Object}   rdd         Raw Document Data-structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @return {*}                    Mapped value.\n * @private\n */\nvar itmEntityOut = function ( index, entities, rdd, itsf ) {\n  var entity = entities[ index ];\n  var itsfn = ( itsf && allowed.its4entity.has( itsf ) ) ? itsf : its.value;\n  var detail;\n\n  if ( itsfn === its.detail ) {\n    // In case of `detail`, return an object containing entity's `text` & `type`.\n    detail = Object.create( null );\n    detail.value = colTokensOut( entity[ 0 ], entity[ 1 ], rdd, its.value, as.text );\n    detail.type = entity[ 2 ];\n    return detail;\n  }\n\n  if ( itsfn === its.type ) {\n    // Extract `type` and return directly.\n    return entity[ 2 ];\n  }\n\n  if ( itsfn === its.span ) {\n    // Extract span and return.\n    return its.span( entity );\n  }\n\n  // Balance cases ( i.e. value, normal, and type ) are handled via `colTokensOut()`.\n  return colTokensOut( entity[ 0 ], entity[ 1 ], rdd, itsfn, as.text );\n}; // itmEntityOut()\n\nmodule.exports = itmEntityOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar constants = require( './constants.js' );\n\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Mask for preceding spaces.\nvar psMask = constants.psMask;\n\nvar reconstructSpaces = function ( index, rdd ) {\n    var token = rdd.tokens[ ( index * tkSize ) + 1 ];\n    var count = token & psMask;  // eslint-disable-line no-bitwise\n    return ( count < 0xFFFF ) ? ( ''.padEnd( count ) ) : rdd.nonBreakingSpaces[ index ];\n}; // reconstructSpaces()\n\nmodule.exports = reconstructSpaces;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nconst constants = require( './constants.js' );\n// Bits reserved for `lemma`.\nconst bits4lemma = constants.bits4lemma;\n// Mask for extracting pos\nconst posMask = constants.posMask;\n// Size of a single token.\nconst tkSize = constants.tkSize;\n\n/**\n * This implementation is inspired by the hypothesis that *content salience is proportional\n * to the frequency of part-of-speech n-grams* as outlined in the paper titled,\n * [Examining the Content Load of Part of Speech Blocks for Information Retrieval](https://dl.acm.org/doi/10.5555/1273073.1273142).\n *\n * @param {object} rdd  Raw Document Data structure containing the document whose\n *                      sentence wise importance will be determined.\n * @returns {object[]}  array of objects, in form of `{ index: <integer>, importance: <01>}`,\n *                      where index points to the sentence; 1 means highest importance and 0 indicates lowest.\n */\nconst sentenceWiseImportance = function ( rdd ) {\n    // Define open class part-of-speeches; used to compute intitial information content\n    const openClassPOS = Object.create(null);\n    openClassPOS.ADJ = true;\n    openClassPOS.ADV = true;\n    openClassPOS.INTJ = true;\n    openClassPOS.NOUN = true;\n    openClassPOS.PROPN = true;\n    openClassPOS.VERB = true;\n    openClassPOS.NUM = true;\n    openClassPOS.SYM = true;\n    // N-gram to use to construct a pos group.\n    const NGram = 4;\n    const sentences = rdd.sentences;\n    const tokens = rdd.tokens;\n    const cache = rdd.cache;\n\n    // Used to build table of weights of pos groups. Apart from frequency, it also maintains\n    // (a) array of sentences, where a given pos group was found, (b) total weight computed as\n    // frequency minus count of closed class part-of-speech in the group.\n    const posGroupWeightTable = Object.create( null );\n\n    for ( let s = 0; s < sentences.length; s += 1 ) {\n      const pos = [];\n      const [ start, end ] = sentences[ s ];\n      for ( let t = start; t <= end; t += 1 ) {\n        const p = cache.valueOf( 'pos', ( tokens[ ( t * tkSize ) + 2 ] & posMask ) >>> bits4lemma ); // eslint-disable-line no-bitwise\n        if ( p !== 'SPACE' && p !== 'PUNCT' ) pos.push( p );\n      }\n\n      // Ignore sentences where we cannot build NGram i.e. sentences shorter than NGram.\n      if ( pos.length < 4 ) continue; // eslint-disable-line no-continue\n      // Determine NGrams;\n      for ( let k = 0; k + NGram - 1 < pos.length; k += 1 ) {\n        const pos4Gram = pos.slice( k, k + NGram );\n        // Used to compute the weight for a pos group.\n        const initInfoContent = pos4Gram.reduce(\n          ( pv, cv ) => pv - ( ( openClassPOS[cv] ) ? 0 : 1 ),\n          0\n        );\n        const posGroup = pos4Gram.join( '_' );\n        posGroupWeightTable[ posGroup ] = posGroupWeightTable[ posGroup ] || Object.create( null );\n        posGroupWeightTable[ posGroup ].group = posGroup;\n        posGroupWeightTable[ posGroup ].sentences = posGroupWeightTable[ posGroup ].sentences || [];\n        posGroupWeightTable[ posGroup ].sentences.push( s ); // ?\n        posGroupWeightTable[ posGroup ].weight = ( posGroupWeightTable[ posGroup ].weight === undefined ) ?\n                                                  initInfoContent + 1 :\n                                                  ( posGroupWeightTable[ posGroup ].weight + 1 );\n        posGroupWeightTable[ posGroup ].iv = initInfoContent;\n      }\n    }\n\n    // Transform object into an array, and filter out elements with weight <= 0.\n    const posGroupWeights = Object.keys( posGroupWeightTable )\n                              .map( ( e ) => posGroupWeightTable[ e ] )\n                              .filter( ( e ) => e.weight > 0 );\n    // This is an array index by each sentence's index and would contain the total weight\n    // computed by adding all the weights of each pos group found in that sentence.\n    const sentenceWiseWeights = new Array( sentences.length );\n    sentenceWiseWeights.fill( 0 );\n    posGroupWeights.forEach( ( pgw ) => {\n      pgw.sentences.forEach( ( e ) => {\n         sentenceWiseWeights[ e ] += pgw.weight;\n        } );\n    });\n    // Normalize weights by dividing them by the max.\n    let max = Math.max( ...sentenceWiseWeights );\n    // Avoid divide by zero situation\n    if ( max === 0 ) max = 1;\n\n    return sentenceWiseWeights.map( ( e, i ) => ( { index: i, importance: +( e / max ).toFixed( 4 ) } ) );\n  };\n\n  module.exports = sentenceWiseImportance;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar sort4FT = require( './sort4FT.js' );\nvar containedMarkings = require( './contained-markings.js' );\nvar as = Object.create( null );\n\n// ### array\n/**\n * It is a simple passthru function i.e. input is returned as-is.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {string[]}        the input `tokens` as-is.\n * @private\n */\nas.array = function ( tokens ) {\n  // Return the input tokens as-is.\n  return tokens;\n}; // array()\n\n// ### set\n/**\n * Constructs set from the `tokens`.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {set}      the set of `tokens`.\n * @private\n */\nas.set = function ( tokens ) {\n  // Create set & return.\n  return new Set( tokens );\n}; // set()\n\n// ### bow\n/**\n *\n * Constructs the bag of words from the `tokens`.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {objects}         the bag of words object containing `token/frequency`\n *                           `key/value` pairs.\n * @private\n */\nas.bow = function ( tokens ) {\n  // Bag of words.\n  var bow = Object.create( null );\n  var t;\n  for ( let i = 0; i < tokens.length; i += 1 ) {\n    t = tokens[ i ];\n    bow[ t ] = 1 + ( bow[ t ] || 0 );\n  }\n\n  return bow;\n}; // bow()\n\n// ### freqTable\n/**\n * Constructs the frequency table of `tokens`, which sorted in a descending\n * order of token's frequency.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {array[]}         array of `[ token, frequency ]` pairs.\n * @private\n */\nas.freqTable = function ( tokens ) {\n  // NOTE: build FT based on argument type i.e. array or object (its.detail)\n  var bow = as.bow( tokens );\n  var keys = Object.keys( bow );\n  var length = keys.length;\n  var table = new Array( length );\n\n  for ( var i = 0; i < length; i += 1 ) {\n    table[ i ] = [ keys[ i ], bow[ keys[ i ] ] ];\n  }\n\n  return table.sort( sort4FT );\n}; // freqTable()\n\n// ### bigrams\n/**\n * Generates bigrams of the input tokens.\n *\n * @param  {string[]} tokens The input tokens.\n * @return {array[]}         array of `[ token`<sub>i</sub>`, token`<sub>i+1</sub> `  ]`\n *                           bigrams.\n * @private\n */\nas.bigrams = function ( tokens ) {\n  // Bigrams will be stored here.\n  var bgs = [];\n  // Helper variables.\n  var i, imax;\n  // Create bigrams.\n  for ( i = 0, imax = tokens.length - 1; i < imax; i += 1 ) {\n    bgs.push( [ tokens[ i ], tokens[ i + 1 ] ] );\n  }\n  return bgs;\n}; // bigrams()\n\nas.unique = function ( tokens ) {\n  return Array.from( new Set( tokens ) );\n}; // unique()\n\n// ### text\n/**\n *\n * Generates the text by joining the contents of `twps` array (tokens with\n * preceding spaces).\n *\n * @param  {array} twps Array containing tokens with preceding spaces.\n * @return {string}     the text.\n * @private\n*/\nas.text = function ( twps ) {\n  // Join on empty-space as preceding spaces are part of `twps`!\n  return twps.join( '' ).trim();\n}; // text()\n\n// ### markedUpText\n/**\n *\n * Generates the marked up text of the span specified by the `start` and `end` using\n * `twps` and `markings`.\n *\n * @param  {array}  twps     Array containing tokens with preceding spaces.\n * @param  {object}  rdd     Raw Document Data structure.\n * @param  {number} start    The start index of the tokens.\n * @param  {number} end      The end index of the tokens.\n * @return {string}          the markedup text.\n * @private\n*/\nas.markedUpText = function ( twps, rdd, start, end ) {\n  // Extract markings.\n  const markings = rdd.markings;\n  // Offset to be added while computing `first` and `last` indexes of `twps`.\n  var offset = start * 2;\n  // Compute the `range` of `markings` to consider on the basis `start` and `end`.\n  var range = containedMarkings( markings, start, end );\n  if ( range === null ) {\n    // Means no valid range, return the text as is.\n    return twps.join( '' ).trim();\n  }\n  // For every marking prefix the `first` one with `beginMarker` and suffix\n  // the `last` one with `endMarker`.\n  for ( let i = range.left; i <= range.right; i += 1 ) {\n    const first = ( ( markings[ i ][ 0 ] * 2 ) - offset ) + 1;\n    const last  = ( ( markings[ i ][ 1 ] * 2 ) - offset ) + 1;\n    const beginMarker = ( markings[ i ][ 2 ]  === undefined ) ? '<mark>' : markings[ i ][ 2 ];\n    const endMarker = ( markings[ i ][ 3 ]  === undefined ) ? '</mark>' : markings[ i ][ 3 ];\n\n    twps[ first ] = beginMarker + twps[ first ];\n    twps[ last ] += endMarker;\n  }\n\n  // Join all the elements and return the `markedUpText`.\n  return twps.join( '' ).trim();\n}; // markedUpText()\n\nas.vector = function ( tokens, rdd ) {\n  if ( !rdd.wordVectors )\n    throw Error( 'wink-nlp: word vectors are not loaded, use const nlp = winkNLP( model, pipe, wordVectors ) to load.' );\n\n  // Get size of a vector from word vectors\n  const size = rdd.wordVectors.dimensions;\n  const precision = rdd.wordVectors.precision;\n  const vectors = rdd.wordVectors.vectors;\n  const l2NormIndex = rdd.wordVectors.l2NormIndex;\n\n  // Set up a new initialized vector of `size`\n  const v = new Array( size );\n  v.fill( 0 );\n  // Compute average.\n  // We will count the number of tokens as some of them may not have a vector.\n  let numOfTokens = 0;\n  for ( let i = 0; i < tokens.length; i += 1 ) {\n    // Extract token vector for the current token.\n    const tv = vectors[ tokens[ i ].toLowerCase() ];\n    // Increment `numOfTokens` if the above operation was successful\n    // AND l2Norm is non-zero, because for UNK vectors it is set to 0.\n    // The later is applicable for the contextual vectors, where in event\n    // of UNK, an all zero vectors is set for UNK word.\n    if ( tv !== undefined && tv[ l2NormIndex ] !== 0 ) numOfTokens += 1;\n    for ( let j = 0; j < size; j += 1 ) {\n      // Keep summing, eventually it will be divided by `numOfTokens` to obtain avareage.\n      v[ j ] += ( tv === undefined ) ? 0 : tv[ j ];\n    }\n  }\n\n  // if no token's vector is found, return a 0-vector!\n  if ( numOfTokens === 0 ) {\n    // Push l2Norm, which is 0 in this case.\n    v.push( 0 );\n    return v;\n  }\n\n  // Non-0 vector, find average by dividing the sum by numOfTokens\n  // also compute l2Norm.\n  let l2Norm = 0;\n  for ( let i = 0; i < size; i += 1 ) {\n    v[ i ] = +( v[ i ] / numOfTokens ).toFixed( precision );\n    l2Norm += v[ i ] * v[ i ];\n  }\n  // `l2Norm` becomes the `size+1th` element for faster cosine similarity/normalization.\n  v.push( +( Math.sqrt( l2Norm ).toFixed( precision ) ) );\n\n  return v;\n}; // vector()\n\nmodule.exports = as;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar DocDataWrapper = require( './dd-wrapper.js' );\nvar Doc = require( './doc-v2.js' );\nvar Cache = require( './cache.js' );\nvar tokenizer = require( './tokenizer.js' );\nvar compileTRex = require( './compile-trex.js' );\nvar mappers = require( './tokens-mappers.js' );\nvar itsHelpers = require( './its.js' );\nvar asHelpers = require( './as.js' );\nvar mapRawTokens2UIdOfNormal = mappers.mapRawTokens2UIdOfNormal;\nvar mapRawTokens2UIdOfDefaultPOS = mappers.mapRawTokens2UIdOfDefaultPOS;\n\nvar Compiler = require( './examples-compiler.js' );\n\nvar constants = require( './constants.js' );\n\nvar fsm = require( './automaton.js' );\n\nvar search = require( './search.js' );\nvar locate = require( './locate.js' );\n\nvar helper = require( './helper.js' );\n\n// Size of a single token.\nvar tkSize = constants.tkSize;\n\n/**\n * Creates an instance of nlp.\n * @private\n *\n * @param {object} theModel language model.\n * @param {string[]} pipe of nlp annotations.\n * @param {object} wordEmbeddings object read using node require.\n * @returns {object} conatining set of API methods for natural language processing.\n * @example\n * const nlp = require( 'wink-nlp' );\n * var myNLP = nlp();\n*/\nvar nlp = function ( theModel, pipe = null, wordEmbeddings = null ) {\n\n  var methods = Object.create( null );\n  // Token Regex; compiled from `model`\n  var trex;\n  // wink-nlp language `model`.\n  var model;\n  // Holds instance of `cache` created using the `model`.\n  var cache;\n  // NLP Pipe Config.\n  // var nlpPipe = Object.create( null );\n  // Configured tokenize.\n  var tokenize;\n  // Automata\n  // 1. NER\n  var nerAutomata;\n  var nerTransformers;\n  // 2. SBD\n  var sbdAutomata;\n  var sbdTransformers;\n  var sbdSetter;\n  // 3. NEG\n  var negAutomata;\n  var negSetter;\n  // SA\n  var saAutomata;\n  var saSetter;\n  // POS\n  var posAutomata;\n  var posTransformers;\n  var posSetter;\n  var posUpdater;\n  // Patterns or Custom Entities\n  var cerAutomata;\n  var cerTransformer;\n  var cerLearnings = 0;\n  var cerPreserve;\n  var cerConfig;\n  // Used for compiling examples.\n  var compiler;\n  // Used to innstantiate the compiler.\n  var cerMetaModel;\n\n  // Contains a list of valid annotations built from `theModel`.\n  var validAnnotations = Object.create( null );\n\n  // Current pipe.\n  var currPipe = Object.create( null );\n  var onlyTokenization = true;\n\n  // Private methods.\n\n  // ## load\n  /**\n   * Loads the model containing the core model along with other applicable\n   * models.\n   * @private\n   *\n   * @returns {void} nothing!.\n   * @private\n  */\n  var load = function () {\n    // Load language model.\n    model = theModel.core();\n    // With `intrinsicSize` captured, instantiate cache etc.\n    cache = Cache( model, theModel.featureFn ); // eslint-disable-line new-cap\n    trex = compileTRex( model.trex );\n\n    // Instantiate tokenizer.\n    tokenize = tokenizer( trex, model.tcat.hash, model.preserve );\n\n    // Load & setup SBD model.\n    var sbdModel = theModel.sbd();\n\n    sbdAutomata = new Array( sbdModel.machines.length );\n    sbdTransformers = new Array( sbdModel.machines.length );\n    for ( let i = 0; i < sbdModel.machines.length; i += 1 ) {\n      sbdAutomata[ i ] = fsm( cache );\n      sbdAutomata[ i ].importJSON( sbdModel.machines[ i ] );\n      sbdTransformers[ i ] = sbdModel.transformers[ i ];\n    }\n    sbdSetter = sbdModel.setter;\n\n    // Load & setup NER model.\n    var nerModel = theModel.ner();\n\n    nerAutomata = new Array( nerModel.machines.length );\n    nerTransformers = new Array( nerModel.machines.length );\n    for ( let i = 0; i < nerModel.machines.length; i += 1 ) {\n      nerAutomata[ i ] = fsm( cache );\n      nerAutomata[ i ].importJSON( nerModel.machines[ i ] );\n      nerTransformers[ i ] = nerModel.transformers[ i ];\n    }\n\n    var negModel = theModel.negation();\n    negAutomata = fsm( cache );\n    negAutomata.importJSON( negModel.machines[ 0 ] );\n    negSetter = negModel.setter;\n\n    var saModel = theModel.sa();\n    saAutomata = fsm( cache );\n    saAutomata.importJSON( saModel.machines[ 0 ] );\n    saSetter = saModel.setter;\n\n    var posModel = theModel.pos();\n    posAutomata = new Array( posModel.machines.length );\n    posTransformers = new Array( nerModel.machines.length );\n    for ( let i = 0; i < posModel.machines.length; i += 1 ) {\n      // Ignore only OOV literal and not new line character in the case of POS Tagging.\n      posAutomata[ i ] = fsm( cache, cache.value( 0 ) );\n      posAutomata[ i ].importJSON( posModel.machines[ i ] );\n      posTransformers[ i ] = posModel.transformers[ i ];\n    }\n    posSetter = posModel.setter;\n    posUpdater = posModel.updater;\n\n\n    var cmModel = theModel.metaCER();\n    cerMetaModel = cmModel.machines;\n    cerTransformer = cmModel.transformers[ 0 ];\n    // posAutomata = fsm( cache, cache.value( 0 ) );\n    // posAutomata.importJSON( posModel.machines[ 0 ] );\n    // posTransformer = posModel.transformers[ 0 ];\n  }; // load()\n\n  // Public Methods.\n  // ## readDoc\n  /**\n   * Loads a single document to be processed.\n   * @private\n   *\n   * @param {string} text of the document that you want to process.\n   * @returns {object} the document in terms of an object that exposes the API.\n   * @example\n   * const DOC = \"The quick brown fox jumps over the lazy dog\";\n   * myNLP.readDoc(DOC);\n  */\n  var readDoc = function ( text ) {\n    if ( typeof text !== 'string' ) {\n      throw Error( `wink-nlp: expecting a valid Javascript string, instead found \"${typeof text}\".`);\n    }\n    // Raw Document Data-structure gets populated here as NLP pipe taks execute!\n    var rdd = Object.create( null );\n    // The `cache` is also part of document data structure.\n    rdd.cache = cache;\n    // Each document gets a pointer to the word vectors.\n    rdd.wordVectors = wordEmbeddings;\n    // Document's tokens; each token is represented as an array of numbers:\n    // ```\n    // [\n    //   hash, // of tokenized lexeme\n    //   (nox) + preceding spaces, // expansion's normal\n    //   pos + lemma, // pos & lemma are contextual\n    //   negation flag // 1 bit at msb\n    // ]\n    // ```\n    rdd.tokens = [];\n    // Sentences  stored as array of pairs of `[ start, end ]` pointing to the `tokens`.\n    rdd.sentences = [];\n    // Markings are 4-tuples of `start`, `end` **token indexes**,  and `begin & end markers`.\n    // The begin & end markers are used to markup the tokens specified.\n    rdd.markings = [];\n    // Publish the current annotation pipeline so that code can inquire about\n    // active annotations!\n    rdd.currPipe = currPipe;\n    // Set storage for non braking spaces\n    rdd.nonBreakingSpaces = Object.create( null );\n\n    var wrappedDocData = DocDataWrapper( rdd );  // eslint-disable-line new-cap\n\n    // Start of NLP Pipe\n    tokenize( wrappedDocData, text ); // eslint-disable-line new-cap\n    // Compute number of tokens.\n    rdd.numOfTokens = rdd.tokens.length / tkSize;\n    // This structure is identical to sentences ( or entities ), for the sake of uniformity.\n    // The structure is `[ start, end, negationFlag, sentimentScore ]`.\n    rdd.document = [ 0, ( rdd.numOfTokens - 1 ), 0, 0 ];\n\n    // Map tokens for automata if there are other annotations to be performed.\n    var tokens4Automata = ( onlyTokenization ) ? null : mapRawTokens2UIdOfNormal( rdd );\n\n    var px;\n    if ( currPipe.sbd ) {\n      // Sentence Boundary Detection.\n      // Set first `Pattern Swap (x)` as `null`.\n      px = null;\n      for ( let i = 0; i < sbdAutomata.length; i += 1 ) {\n        sbdAutomata[ i ].setPatternSwap( px );\n        // For SBD, all tokens are required to extract preceeding spaces.\n        px = sbdAutomata[ i ].recognize( tokens4Automata, sbdTransformers[ i ], rdd.tokens );\n      }\n      // The structure of sentence is:<br/>\n      // `[ start, end, negationFlag, sentimentScore ]`\n      sbdSetter( px, rdd );\n      // Compute number of sentences!\n      rdd.numOfSentences = rdd.sentences.length;\n    } else {\n      // Setup default sentence as entire document!\n      rdd.numOfSentences = 1;\n      rdd.sentences = [ [ 0, ( rdd.numOfTokens - 1 ), 0, 0 ] ];\n    }\n\n    if ( currPipe.ner ) {\n      // Named entity detection.\n      px = null;\n      for ( let i = 0; i < nerAutomata.length; i += 1 ) {\n        nerAutomata[ i ].setPatternSwap( px );\n        px = nerAutomata[ i ].recognize( tokens4Automata, nerTransformers[ i ] );\n      }\n      // Entities  storted as array of `[ start, end, entity type ].`\n      // There are no setter for entities as no transformation is needed.\n      rdd.entities = px;\n    } else {\n      rdd.entities = [];\n    }\n\n    if ( currPipe.negation ) {\n      // Negation\n      px = null;\n      px = negAutomata.recognize( tokens4Automata );\n      negSetter( px, rdd, constants, search );\n    }\n\n    if ( currPipe.sentiment ) {\n      // Sentiment Analysis\n      px = null;\n      px = saAutomata.recognize( tokens4Automata );\n      saSetter( px, rdd, constants, locate );\n    }\n\n    if ( currPipe.pos ) {\n      // PoS Tagging\n      const posTags = mapRawTokens2UIdOfDefaultPOS( rdd );\n      px = null;\n      for ( let i = 0; i < posAutomata.length; i += 1 ) {\n        px = posAutomata[ i ].recognize( posTags, posTransformers[ 0 ], rdd.tokens );\n        posUpdater( px, cache, posTags, tokens4Automata );\n      }\n      posSetter( rdd, posTags, tkSize, constants.bits4lemma );\n    }\n\n    if ( currPipe.cer ) {\n      // Patterns\n      px = null;\n      if ( cerAutomata !== undefined && cerLearnings > 0 ) {\n        cerConfig.rdd = rdd;\n        cerConfig.preserve = cerPreserve;\n        cerConfig.constants = constants;\n        if ( cerConfig.useEntity ) cerAutomata.setPatternSwap( rdd.entities );\n        px = cerAutomata.recognize( tokens4Automata, cerTransformer, cerConfig );\n      }\n      // If there are no custom entities, then `px` will be `null`; in such a case\n      // set `customEntities` to an empty array.\n      rdd.customEntities = px || [];\n    } else rdd.customEntities = [];\n\n\n    // Word Vector\n    // if ( theModel.wordVectors !== undefined ) {\n    //\n    // }\n\n    // Now create the document!\n    var doc = Doc( rdd, theModel.addons ); // eslint-disable-line new-cap\n\n    // All done  cleanup document's data.\n    wrappedDocData.clean();\n    return doc;\n  }; // readDoc()\n\n  var learnCustomEntities = function ( examples, config ) {\n    // Ensure (a) `examples` is an array and (b) and its each element is an object.\n    if ( helper.isArray( examples ) ) {\n      examples.forEach( ( ex ) => {\n        if ( helper.isObject( ex ) ) {\n          // The object must contain name  & patterns property of string and array type respectively.\n          if ( ( typeof ex.name !== 'string' ) || ( ex.name === '' ) ) {\n            throw Error( `wink-nlp: name should be a string, instead found \"${ex.name}\":\\n\\n${JSON.stringify( ex, null, 2 )}` );\n          } else if ( helper.isArray( ex.patterns ) ) {\n            for ( let k = 0; k < ex.patterns.length; k += 1 ) {\n              const p = ex.patterns[ k ];\n              // Each pattern should be a string.\n              if ( ( typeof p !== 'string' ) || ( p === '' ) ) {\n                throw Error( `wink-nlp: each pattern should be a string, instead found \"${p}\":\\n\\n${JSON.stringify( ex, null, 2 )}` );\n              }\n            } // for ( let k = 0;... )\n          } else {\n            // Pattern is not an array.\n            throw Error( `wink-nlp: patterns should be an array, instead found \"${typeof ex.patterns}\":\\n\\n${JSON.stringify( ex, null, 2 )}` );\n          }\n          // If mark is present then it should be an array of integers **and** its length must\n          // be equal to 2 **and** start index <= end index.\n          if ( ( ex.mark !== undefined ) &&\n                ( !helper.isIntegerArray( ex.mark ) ||\n                ( ex.mark.length !== 2 ) ||\n                ( ex.mark.length === 2 && ex.mark[ 0 ] > ex.mark[ 1 ] ) ) ) {\n            throw Error( `wink-nlp: mark should be an array containing start & end indexes, instead found:\\n\\n${JSON.stringify( ex.mark, null, 2 )}` );\n          }\n        } else {\n          // Example is not an object.\n          throw Error( `wink-nlp: each example should be an object, instead found a \"${typeof ex}\":\\n\\n${JSON.stringify( ex, null, 2 )}` );\n        }\n      } );\n    } else {\n      // Examples is not an array.\n      throw Error( `wink-nlp: examples should be an array, instead found \"${typeof examples}\".` );\n    }\n\n    // Validate config\n    cerConfig = ( config === undefined || config === null ) ? Object.create( null ) : JSON.parse( JSON.stringify( config ) );\n    if ( !helper.isObject( cerConfig ) ) {\n      throw Error( `wink-nlp: config should be an object, instead found \"${typeof cerConfig}\".` );\n    }\n    cerConfig.matchValue = !!cerConfig.matchValue;\n    cerConfig.usePOS = ( cerConfig.usePOS === undefined ) ? true : !!cerConfig.usePOS;\n    cerConfig.useEntity = ( cerConfig.useEntity === undefined ) ? true : !!cerConfig.useEntity;\n\n\n    // Instantiate compiler.\n    compiler = Compiler( cerMetaModel, cache, tokenize, cerConfig.matchValue ); // eslint-disable-line new-cap\n\n    cerAutomata = null;\n    cerLearnings = 0;\n    cerAutomata = fsm();\n    const compiled = compiler.run( examples );\n    cerPreserve = compiled.preserve;\n    cerLearnings = cerAutomata.learn( compiled.examples );\n    // cerAutomata.printModel();\n    return cerLearnings;\n  }; // learnCustomEntities()\n\n  if ( helper.isObject( theModel ) ) {\n    if ( typeof theModel.core !== 'function' ) {\n      throw Error( 'wink-nlp: invalid model used.' );\n    }\n  } else {\n    throw Error( 'wink-nlp: invalid model used.' );\n  }\n\n  // Build a list of valid annotations from `theModel`. This will ensure that\n  // only **available** annotations from the model can be used in the pipe.\n  validAnnotations.sbd = typeof theModel.sbd === 'function';\n  validAnnotations.negation = typeof theModel.negation === 'function';\n  validAnnotations.sentiment = typeof theModel.sa === 'function';\n  validAnnotations.pos = typeof theModel.pos === 'function';\n  validAnnotations.ner = typeof theModel.ner === 'function';\n  validAnnotations.cer = typeof theModel.metaCER === 'function';\n\n  if ( wordEmbeddings !== null ) {\n    if ( !helper.isObject( wordEmbeddings ) )\n      throw Error( `wink-nlp: invalid word vectors, it must be an object instead found a \"${typeof wordEmbeddings}\".` );\n\n    let numOfKeys = 0;\n    const wordVectorKeys = Object.create( null );\n    wordVectorKeys.precision = true;\n    wordVectorKeys.l2NormIndex = true;\n    wordVectorKeys.wordIndex = true;\n    wordVectorKeys.dimensions = true;\n    wordVectorKeys.unkVector = true;\n    wordVectorKeys.size = true;\n    wordVectorKeys.words = true;\n    wordVectorKeys.vectors = true;\n    for ( const key in wordEmbeddings ) { // eslint-disable-line guard-for-in\n      numOfKeys += 1;\n      if ( !wordVectorKeys[ key ] )\n        throw Error( 'wink-nlp: invalid word vectors format.' );\n    }\n\n    if ( numOfKeys === 0 ) throw Error( 'wink-nlp: empty word vectors found.' );\n  }\n\n  const tempPipe = ( pipe === null || pipe === undefined ) ? Object.keys( validAnnotations ) : pipe;\n  if ( helper.isArray( tempPipe ) ) {\n    tempPipe.forEach( ( at ) => {\n      if ( !validAnnotations[ at ] ) throw Error( `wink-nlp: invalid pipe annotation \"${at}\" found.` );\n      currPipe[ at ] = true;\n      onlyTokenization = false;\n    } );\n  } else throw Error( `wink-nlp: invalid pipe, it must be an array instead found a \"${typeof pipe}\".` );\n\n  // Load the model.\n  load();\n  // Setup default configuration.\n  // definePipeConfig();\n  // Methods.\n  methods.readDoc = readDoc;\n  methods.learnCustomEntities = learnCustomEntities;\n  // Expose `its` and `as` helpers.\n  methods.its = itsHelpers;\n  methods.as = asHelpers;\n  // Vector of a token method.\n  methods.vectorOf = function ( word, safe = true )  {\n    if ( !wordEmbeddings )\n    throw Error( 'wink-nlp: word vectors are not loaded, use const nlp = winkNLP( model, pipe, wordVectors ) to load.' );\n\n    const vectors = wordEmbeddings.vectors;\n    const unkVector = wordEmbeddings.unkVector;\n    const sliceUpTo = wordEmbeddings.l2NormIndex + 1;\n\n    if ( typeof word !== 'string' ) {\n      throw Error( 'winkNLP: input word must be of type string.' );\n    }\n\n    const tv = vectors[ word.toLowerCase() ];\n    if ( tv === undefined ) {\n      // If unsafe, return the entire array.\n      return ( safe ) ? unkVector.slice( 0, sliceUpTo ) : unkVector.slice();\n    }\n    return ( safe ) ? tv.slice( 0, sliceUpTo ) : tv.slice();\n  }; // vectorOf()\n\n  return methods;\n}; // wink\n\nmodule.exports = nlp;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar constants = require( './constants.js' );\nvar xnMask = constants.xnMask;\nvar bits4PrecedingSpace = constants.bits4PrecedingSpace;\nvar xcMask = constants.xcMask;\nvar bits4xpPointer = constants.bits4xpPointer;\n\n// ## cache\n/**\n *\n * Creates an instance of `cache`. It is typically instantiated in each `winkNLP`\n * instance and there it is responsible for caching token properties acrosss the\n * documents i.e. the `doc()`.\n *\n * @param {Array} model containing language model.\n * @param {Array} featureFn extracts language specific features of a lexeme.\n * @return {object} of methods.\n * @private\n*/\nvar cache = function ( model, featureFn ) {\n  const fTokenType = 'tokenType';\n  // Returned!\n  var methods = Object.create( null );\n  // Extract frequently used properties.\n  var lexemesHash = model.features.lexeme.hash;\n  var lxm = model.features.lexeme;\n  var lexemeIntrinsicSize = model.features.lexeme.intrinsicSize;\n  var layout = model.packing.layout;\n  var pkSize = model.packing.size;\n  var efSize = model.packing.efSize;\n  var efList = model.packing.efList;\n  var efListSize = efList.length;\n  var lexicon = model.lexicon;\n  var xpansions = model.xpansions;\n  var posClusters = model.features.posClusters.list;\n  // Contains quantas of UInt32Array of size `model.packing.size`. A quanta\n  // at an `index` contains the features of the corresponding OOV lexeme loacted\n  // at `model.features.lexeme.list[ index ]`. This simplifies information access,\n  // as it remains identical to the **intrinsic lexicon** with the only difference\n  // that this not a continuous array of UInt32s. It follows\n  // `[ normal, lemma, <extractable features> ]` structure. The extractable\n  // features will be dynamically determined using the language model.\n  var extrinsicLexicon = [];\n  // Base Packing Size is `2` because one word each for normal & lemma is needed.\n  var elBasePackingSize = 2;\n  // Packing size for each lexeme in `extrinsicLexicon`  base plus additional\n  // words needed for extractable features.\n  var elPackingSize = 2 + efSize;\n  // Extractable Features temp storage; eventually its contents will be pushed\n  // inside `extrinsicLexicon`. Space is allocated right in the beginning to save\n  // time. Its contents are filled i.e. initialized with 0 whenever needed.\n  var efArray = new Uint32Array( efSize );\n\n  var feature = featureFn( model.packing.config );\n\n  // Extractable Features Hash: used during property extraction for OOV tokens.\n  // If a token is not found in this then a **0** is returned.\n  var efHash = Object.create( null );\n  // Since `tokenType` is determined during tokenization, it is always extractable.\n  efHash.tokenType = true;\n  // Copy rest from the list in to the hash.\n  efList.forEach( ( ef ) => ( efHash[ ef ] = true ) );\n\n  // ## getFeaturesIndex\n  /**\n   *\n   * Returns the `index` of `value` from the feature `name`. If the value is\n   * missing then it is added and its `index` is returned accordingly alongwith\n   * a flag indicating that it is a new value.\n   *\n   * @param {string} name of the feature.\n   * @param {string} value of the feature, whoes index will be returned.\n   * @return {number[]} `[ isNewValue, index ]`.\n   * @example\n   * // Returns the index (hash) of **lexeme**  `you`:\n   * getFeaturesIndex( 'lexeme', 'you' );\n   * // -> [ 0, 47 ]\n   * // If `you` was absent then it would have been added and the return value\n   * // would have been [ 1, index of added value ]\n   * @private\n  */\n  var getFeaturesIndex = function ( name, value ) {\n    // Extract the named feature.\n    var f = model.features[ name ];\n    // And its hash & list.\n    var h = f.hash;\n    var l = f.list;\n    // New `value` flag.\n    var isNewValue = 0;\n    // Check if `value` is present.\n    var index = h[ value ];\n    if ( index === undefined ) {\n      // Feature's storage limit check.  not required right now!\n      // if ( f.index > f.maxIndex ) {\n      //   throw Error( `wink-nlp: memory limit for \"${name}\" exceeded.` );\n      // }\n      // Missing  add `value`.\n      index = h[ value ] = f.index;\n      // No need to increment index because push returns the required value!\n      f.index = l.push( value );\n      // Set new value flag.\n      isNewValue = 1;\n    }\n    return [ isNewValue, index ];\n  }; // getFeaturesIndex()\n\n  // ## add\n  /**\n   *\n   * Adds a token in the cache corresponding to the **text**. If the same is\n   * present in the cache then a pointer to its cached value is retured; otherwise\n   * a new entry is made in the cache and the same is returned.\n   *\n   * Whenever a new entry is made, all its extractable features are also\n   * extracted & packed; and if an extractable feature is also new, its entry\n   * is also made via `getFeaturesIndex()` api.\n   *\n   * @param {string} text i.e. the value of the token to be added.\n   * @param {number} category of the token i.e. `word(0)` or `number(1)`, etc.\n   * @return {number[]} index (or hash) of the `text` added.\n   * @private\n  */\n  var add = function ( text, category ) {\n    // Lowercased `text`.\n    var normText = text.toLowerCase();\n    // First start with `text` as its properties are being processed first.\n    var textIndex = getFeaturesIndex( 'lexeme', text );\n    // Then obtain index of its normal.\n    var normIndex = ( normText === text ) ? textIndex : getFeaturesIndex( 'lexeme', normText );\n    // Helpers: cfg of feature, feature, feature's value, feature's value for\n    // packing & loop index.\n    var cfg, f, fv, fv4p, k;\n\n    // Process properties of `text` first.\n    // The `textIndex[ 0 ]` is a indicated if the value is newly added, and if\n    // so then add extract-able features. See `getFeaturesIndex()` above.\n    if ( textIndex[ 0 ] ) {\n      // NOTE: This block of code is repeated below, with an exception that\n      // in the next block we use `normtext` in `fv = feature[ f ]( text )`.\n      // Intialize extractable featires' array with all 0s.\n      efArray.fill( 0 );\n      // For every extractable feature, extract & pack.\n      for ( k = 0; k < efListSize; k += 1 ) {\n        f = efList[ k ];\n        cfg = layout[ f ];\n        // Use `text`.\n        fv = feature[ f ]( text, category, methods );\n        fv4p = ( cfg[ 3 ] ) ? fv : getFeaturesIndex( f, fv )[ 1 ];\n        efArray[ cfg[ 0 ] ] |= ( fv4p << cfg[ 2 ] ); // eslint-disable-line no-bitwise\n      } // for\n      // Pack token type now.\n      f = fTokenType;\n      cfg = layout[ f ];\n      efArray[ cfg[ 0 ] ] |= ( category << cfg[ 2 ] ); // eslint-disable-line no-bitwise\n      // Push all the details i.e. `[ normal, lemma, <extractable features> ]`\n      // into `extrinsicLexicon`.\n      extrinsicLexicon.push( normIndex[ 1 ], normIndex[ 1 ], ...efArray );\n    } // if ( >= lexemeIntrinsicSize )\n\n    // If the normalized text is not same as the original text then the\n    // normalize text's extract-able features could be candidates for addition.\n    if ( textIndex[ 1 ] !== normIndex[ 1 ] ) {\n      // Has it been newly added? If Yes, add its extract-able features.\n      if ( normIndex[ 0 ] ) {\n        // NOTE: This block of code is same as above.\n        // Intialize extractable featires' array with all 0s.\n        efArray.fill( 0 );\n        // For every extractable feature, extract & pack.\n        for ( k = 0; k < efListSize; k += 1 ) {\n          f = efList[ k ];\n          cfg = layout[ f ];\n          // Use `normText`.\n          fv = feature[ f ]( normText, category, methods );\n          fv4p = ( cfg[ 3 ] ) ? fv : getFeaturesIndex( f, fv )[ 1 ];\n          efArray[ cfg[ 0 ] ] |= ( fv4p << cfg[ 2 ] ); // eslint-disable-line no-bitwise\n        } // for\n        // Pack token type now.\n        f = fTokenType;\n        cfg = layout[ f ];\n        efArray[ cfg[ 0 ] ] |= ( category << cfg[ 2 ] ); // eslint-disable-line no-bitwise\n        // Push all the details i.e. `[ normal, lemma, <extractable features> ]`\n        // into `extrinsicLexicon`.\n        extrinsicLexicon.push( normIndex[ 1 ], normIndex[ 1 ], ...efArray );\n      } // if ( >= lexemeIntrinsicSize )\n    } // if ( textIndex !== normIndex )\n\n    // Return the `textIndex` only  this can be sued to extract properties.\n    return ( textIndex[ 1 ] );\n  }; // add()\n\n  // ## lookup\n  /**\n   *\n   * Looks up for the `text` in the cache and returns its index. If the input\n   * text is a contraction then its expansions are returned.\n   *\n   * @param {string} text to be searched in the cache.\n   * @return {number[]} contains either a single element (i.e. `index`) indicating\n   * that it is NOT a contraction or multiple elements indication that the text\n   * is a contraction. Each contraction expands into 4 elements viz. `lexeme`,\n   * `normal`, `lemma` , and `pos`.\n   * @private\n  */\n  var lookup = function ( text ) {\n    // `layout.isContraction` for multiple use later.\n    var layout4isContraction = layout.isContraction;\n    var layout4lemma = layout.lemma;\n    // `index` to `text`.\n    var index = lexemesHash[ text ];\n    // Holds lemma extracted in case of contraction.\n    var lemma;\n    // Contraction Count, Contraction Index, Loop Index.\n    var cc, cx, cxi;\n\n    // If the text is not found, return `null`.\n    if ( index === undefined ) return null;\n    // `text` is found  need to check for contraction if `text` is not an OOV.\n    var tokens = [];\n    var isContraction;\n    if ( index < lexemeIntrinsicSize ) {\n      // Not an OOV, check it it is a contraction.\n      isContraction = ( lexicon[ layout4isContraction[ 0 ] + ( index * pkSize ) ] & layout4isContraction[ 1 ] ) >>> layout4isContraction[ 2 ]; // eslint-disable-line no-bitwise\n      if ( isContraction ) {\n        // It is a contraction, process its expansions.\n        // Start by extracting lemma, as it contains pointer to `expansions` and their count.\n        lemma  = ( lexicon[ layout4lemma[ 0 ] + ( index * pkSize ) ] & layout4lemma[ 1 ] ) >>> layout4lemma[ 2 ]; // eslint-disable-line no-bitwise\n        // Extract pointer (i.e. index) to expansions and their count.\n        cx = lemma & 0x3FFF; // eslint-disable-line no-bitwise\n        cc = ( lemma & ( xcMask << bits4xpPointer ) ) >> bits4xpPointer; // eslint-disable-line no-bitwise\n        // Iterate through `cc` times to push details into the `tokens`.\n        for ( cxi = 0; cxi < cc; cxi += 4 ) {\n          tokens.push(\n            xpansions[ cx + cxi ],      // lexeme\n            cx + cxi + 1,               // normal (pointer to xpansion & not to lexicon)\n            xpansions[ cx + cxi + 2 ],  // lemma\n            xpansions[ cx + cxi + 3 ]   // pos\n          );\n        }\n      } else {\n        // Not a contraction, simply add `text`'s `index` to `tokens`.\n        tokens.push( index );\n      }\n    } else {\n      // An OOV, only add `text`'s `index` to `tokens`.\n      tokens.push( index );\n    }\n    return tokens;\n  }; // lookup()\n\n  // ## value\n  /**\n   *\n   * Returns the value corresponding to the `index`.\n   *\n   * @param {number} index for the value.\n   * @return {string} value corresponding to the `index`.\n   * @private\n  */\n  var value = function ( index ) {\n    return lxm.list[ index ];\n  }; // value()\n\n  // ## normal\n  /**\n   *\n   * Returns the index of normal of the input `index` (of required lexeme) after\n   * taking into account mapping of spelling, if any.\n   *\n   * @param {number} index of the required lexeme.\n   * @return {string} index to the normal.\n   * @private\n  */\n  var normal = function ( index ) {\n    // Temps for `layput.normal`, `layout.isSpellingMapped`, etc.\n    var layout4normal = layout.normal;\n    var layout4mapped = layout.isSpellingMapped;\n    var layout4lemma =  layout.lemma;\n    // Used to remap if its value is `1`. In this case lemma becomes the `normIndex`.\n    var isSpellingMapped;\n    // Index for OOVs i.e. when `index > lexemeIntrinsicSize`.\n    var oovIdx;\n    // Returned: normal's index.\n    var normIndex;\n\n    // Processing is different for native and OOV words or lexemes. For OOVs\n    // properties have to be extracted from `extrinsicLexicon`, whereas for\n    // native words they are exracted from `lexicon`.\n    if ( index < lexemeIntrinsicSize ) {\n      normIndex = ( lexicon[ layout4normal[ 0 ] + ( index * pkSize ) ] & layout4normal[ 1 ] ) >>> layout4normal[ 2 ]; // eslint-disable-line no-bitwise\n      isSpellingMapped = ( lexicon[ layout4mapped[ 0 ] + ( index * pkSize ) ] & layout4mapped[ 1 ] ) >>> layout4mapped[ 2 ]; // eslint-disable-line no-bitwise\n      if ( isSpellingMapped ) {\n        // Mapped, pick up the lemma portion as this points to normal in case of\n        // mapped spellings.\n        normIndex = ( lexicon[ layout4lemma[ 0 ] + ( index * pkSize ) ] & layout4lemma[ 1 ] ) >>> layout4lemma[ 2 ]; // eslint-disable-line no-bitwise\n      } else {\n        // Compute actual index from the relative index.\n        normIndex += index;\n      }\n    } else {\n      oovIdx = index - lexemeIntrinsicSize;\n      // Refer to `extrinsicLexicon` structure at the top of `cache()`.\n      normIndex = extrinsicLexicon[ oovIdx * elPackingSize ];\n      // This `normIndex` may point to an intrinsic lexeme, in which case\n      // mapping needs to be checked.\n      if ( normIndex < lexemeIntrinsicSize ) {\n        isSpellingMapped = ( lexicon[ layout4mapped[ 0 ] + ( normIndex * pkSize ) ] & layout4mapped[ 1 ] ) >>> layout4mapped[ 2 ]; // eslint-disable-line no-bitwise\n        if ( isSpellingMapped ) {\n          normIndex = ( lexicon[ layout4lemma[ 0 ] + ( normIndex * pkSize ) ] & layout4lemma[ 1 ] ) >>> layout4lemma[ 2 ]; // eslint-disable-line no-bitwise\n        }\n      }\n    }\n\n    return normIndex;\n  }; // normal()\n\n  // ## mappedSpelling\n  /**\n   *\n   * Returns the index of mapped spelling's of the input `index` of required lexeme.\n   *\n   * @param {number} index of the required lexeme.\n   * @return {string} index to the normal.\n   * @private\n  */\n  var mappedSpelling = function ( index ) {\n    // Temps for `layout.isSpellingMapped`, etc.\n    var layout4mapped = layout.isSpellingMapped;\n    var layout4lemma =  layout.lemma;\n    // Used to remap if its value is `1`. In this case lemma becomes the `normIndex`.\n    var isSpellingMapped;\n    // Returned: normal's index.\n    var mappedIndex = index;\n\n    // Only applicable to lexems that are inside the vocabulary as there can not\n    // be mapped spelling for OOV words!\n    if ( index < lexemeIntrinsicSize ) {\n      isSpellingMapped = ( lexicon[ layout4mapped[ 0 ] + ( index * pkSize ) ] & layout4mapped[ 1 ] ) >>> layout4mapped[ 2 ]; // eslint-disable-line no-bitwise\n      if ( isSpellingMapped ) {\n        // Mapped, pick up the lemma portion as this points to normal in case of\n        // mapped spellings.\n        mappedIndex = ( lexicon[ layout4lemma[ 0 ] + ( index * pkSize ) ] & layout4lemma[ 1 ] ) >>> layout4lemma[ 2 ]; // eslint-disable-line no-bitwise\n      }\n    }\n\n    return mappedIndex;\n  }; // mappedSpelling()\n\n  // ## nox\n  /**\n   *\n   * Returns the index of normal of the expansion.\n   *\n   * @param {number} binaryWord containing pointer to `xpansions` and `precedingSpaces`;\n   * It is the 2nd (relative) element of a single token's packet of 4-words.\n   * @return {number} index to the normal, whoes value can be found via `value()`.\n   * @private\n  */\n  var nox = function ( binaryWord ) {\n    return xpansions[ ( binaryWord & xnMask) >>> bits4PrecedingSpace ];  // eslint-disable-line no-bitwise\n  }; // nox()\n\n  // ## property\n  /**\n   *\n   * Extracts the property  `prop` of a lexeme (or word) specified by `index`.\n   *\n   * @param {number} index of the lexeme whoes properties are required to be extracted.\n   * @param {string} prop (name) that needs to be extracted  it should be a valid property.\n   * @return {string} extracted property, if `prop` is known/valid otherwise `null`.\n   * @private\n  */\n  var property = function ( index, prop ) {\n    // A property and its value\n    var propValue;\n    // Index for OOVs i.e. when `index > lexemeIntrinsicSize`.\n    var oovIdx;\n    // Temp for `layput[ p ]`\n    var layout4Prop;\n\n    // Processing is different for native and OOV words or lexemes. For OOVs\n    // properties have to be extracted from `extrinsicLexicon`, whereas for\n    // native words they are exracted from `lexicon`.\n    if ( index < lexemeIntrinsicSize ) {\n      layout4Prop = layout[ prop ];\n      if ( layout4Prop  === undefined ) return null;\n      propValue  = ( lexicon[ layout4Prop[ 0 ] + ( index * pkSize ) ] & layout4Prop[ 1 ] ) >>> layout4Prop[ 2 ]; // eslint-disable-line no-bitwise\n      // Use hash/list to update value if required.\n      if ( layout4Prop[ 3 ] === 0 || layout4Prop[ 5 ] === 1 ) propValue = model.features[ prop ].list[ propValue ];\n    } else {\n        // Attempt extraction only if extractable!\n        if ( !efHash[ prop ] ) return 0;\n        // Compute index into `extrinsicLexicon`.\n        oovIdx = index - lexemeIntrinsicSize;\n        layout4Prop = layout[ prop ];\n        // No need for this check as `if ( !efHash[ prop ] )...` ensures return\n        // in case of any unknown property:\n        /* if ( layout4Prop  === undefined ) return null; */\n        // Use `extrinsicLexicon`.\n\n        // Reach to the desired quanta via `oovIdx * elPackingSize`, move forward by `base size` and then go to offset!\n        propValue  = ( extrinsicLexicon[ ( oovIdx * elPackingSize ) + elBasePackingSize + layout4Prop[ 0 ] ] & layout4Prop[ 1 ] ) >>> layout4Prop[ 2 ]; // eslint-disable-line no-bitwise\n        // Use hash/list to update value if required.\n        if ( layout4Prop[ 3 ] === 0 || layout4Prop[ 5 ] === 1 ) propValue = model.features[ prop ].list[ propValue ];\n    }\n    return propValue;\n  }; // property()\n\n  var isMemberPOS = function ( lexemeIdx, posIdx ) {\n    // Dont miss converting posIdx to a number.\n    return posClusters[ property( lexemeIdx, 'lexemeCID' ) ].has( +posIdx );\n  }; // isMemberPOS()\n\n  // ## posOf\n  /**\n   *\n   * Extracts the pos' index of the a lexeme (or word) specified by `index`.\n   *\n   * @param {number} index of the lexeme whoes properties are required to be extracted.\n   * @return {string[]} extracted properties in the same sequence as `list`.\n   * @private\n  */\n  var posOf = function ( index ) {\n    // Value of extracted pos will go here.\n    var posValue;\n    // Index for OOVs i.e. when `index > lexemeIntrinsicSize`.\n    var oovIdx;\n    // Temp for `layput[ p ]`\n    var layout4Prop;\n\n    // Processing is different for native and OOV words or lexemes. For OOVs\n    // properties have to be extracted from `extrinsicLexicon`, whereas for\n    // native words they are exracted from `lexicon`.\n    if ( index < lexemeIntrinsicSize ) {\n        layout4Prop = layout.pos;\n        posValue  = ( lexicon[ layout4Prop[ 0 ] + ( index * pkSize ) ] & layout4Prop[ 1 ] ) >>> layout4Prop[ 2 ]; // eslint-disable-line no-bitwise\n    } else {\n        // Compute index into `extrinsicLexicon`.\n        oovIdx = index - lexemeIntrinsicSize;\n        layout4Prop = layout.pos;\n\n        // Use `extrinsicLexicon`.\n        // Reach to the desired quanta via `oovIdx * elPackingSize`, move forward by `base size` and then go to offset!\n        posValue  = ( extrinsicLexicon[ ( oovIdx * elPackingSize ) + elBasePackingSize + layout4Prop[ 0 ] ] & layout4Prop[ 1 ] ) >>> layout4Prop[ 2 ]; // eslint-disable-line no-bitwise\n    }\n    return posValue;\n  }; // posOf()\n\n  // ## valueOf\n  /**\n   *\n   * Extracts the value of the `prop`erty for its input `index`.\n   *\n   * @param {string} prop to be extracted for the `index`.\n   * @param {number} index of the property.\n   * @return {string[]} extracted properties in the same sequence as `list`.\n   * @private\n  */\n  var valueOf = function ( prop, index ) {\n    return model.features[ prop ].list[ index ];\n  }; // valueOf()\n\n  // ## currentSize\n  /**\n   *\n   * Returns the current size of lexicon including OOVs.\n   *\n   * @return {number} size of the current lexicon.\n   * @private\n  */\n  var currentSize = function () {\n    // Minus `1` becuase at `0` we have OOV symbolic word.\n    return ( lxm.list.length - 1 );\n  }; // size()\n\n  // ## intrinsicSize\n  /**\n   *\n   * Returns the intrinsic i.e. native size of lexicon.\n   *\n   * @return {number} size of the native or intrinsic lexicon.\n   * @private\n  */\n  var intrinsicSize = function () {\n    return lexemeIntrinsicSize;\n  };\n\n  /**\n   * Finds if the text can have `pos` as valid part of speech, provided it is a\n   * base form. Used in **lemmatization** to see if the lemma shares the same pos\n   * with the original word.\n   *\n   * @param  {string} text  the incoming word.\n   * @param  {string} pos   the pos that needs to be checked as one of the valid pos for text.\n   * @return {boolean}       True if it does, otherwise false.\n   */\n  var hasSamePOS = function ( text, pos ) {\n    // Get the word's index\n    var textIndex = lookup( text );\n    // If not found i.e. OOV means that it did not have a pre-defined POS set.\n    if ( !textIndex ) return false;\n    // More then one means it is a contraction.\n    if ( textIndex.length > 1 ) return false;\n    // Outside intrinsic vocab means OOV again.\n    if ( textIndex[ 0 ] >= lexemeIntrinsicSize ) return false;\n    // If it is not a base form so point in checking same POS  basics of\n    // lemmatization. For example, `hiding` becomes `hid` on removal of `-ing`,\n    // which is not in base form (i.e. hid is the past tense of hide); so it should\n    // not take that as the lemma and instead try adding `-e`.\n    if ( property( textIndex, 'isBaseForm' ) === 0 ) return false;\n    // Finally if it is in base form then check for pos membership.\n    return isMemberPOS( textIndex[ 0 ], model.pos.hash[ pos ] );\n  }; // hasSamePOS()\n\n  // ## isOOV\n  /**\n   *\n   * Tests the input `text` for being an OOV.\n   *\n   * @param {text} text that needs to be test for OOV.\n   * @return {boolean} true if OOV otherwise false (in vocab).\n   * @private\n  */\n  var isOOV = function ( text ) {\n    var textIndex = lookup( text );\n    if ( !textIndex ) return true;\n    if ( textIndex.length > 1 ) return false;\n    if ( textIndex[ 0 ] >= lexemeIntrinsicSize ) return true;\n    return false;\n  }; // isOOV()\n\n  methods.add = add;\n  methods.lookup = lookup;\n  methods.value = value;\n  methods.property = property;\n  methods.normal = normal;\n  methods.nox = nox;\n  methods.posOf = posOf;\n  methods.valueOf = valueOf;\n  methods.currentSize = currentSize;\n  methods.intrinsicSize = intrinsicSize;\n  methods.isOOV = isOOV;\n  methods.isMemberPOS = isMemberPOS;\n  methods.hasSamePOS = hasSamePOS;\n  methods.mappedSpelling = mappedSpelling;\n\n  return methods;\n}; // cache()\n\nmodule.exports = cache;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar reconstructSpaces = require( '../reconstruct-spaces.js' );\n\n// ## colTokensOut\n/**\n * Out for collection of tokens. Note: the out always returns a Javascript\n * data type or data structure.\n * @param  {number}   start       The start index of the collection.\n * @param  {number}   end         The end index of the collection.\n * @param  {object}   rdd         Raw Document Data-structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @param  {function} asf         Desired `as` reducer.\n * @param  {object}   addons      The model's addons.\n * @return {*}                    Map-reduced collection of tokens.\n * @private\n */\nvar colTokensOut = function ( start, end, rdd, itsf, asf, addons ) {\n  // Not a vector request, perform map-reduce.\n  var mappedTkns = [];\n  var itsfn = ( itsf && allowed.its4tokens.has( itsf ) ) ? itsf : its.value;\n  var asfn = ( asf && allowed.as4tokens.has( asf ) ) ? asf : as.array;\n\n  if ( itsfn !== its.value && itsfn !== its.normal && itsfn !== its.lemma && asfn === as.vector ) {\n    throw Error( 'winkNLP: as.vector is allowed only with its value or normal or lemma.' );\n  }\n\n  // Note, `as.text/markedUpText` needs special attention to include preceeding spaces.\n  if ( asfn === as.text || asfn === as.markedUpText ) {\n    for ( let i = start; i <= end; i += 1 ) {\n      mappedTkns.push( reconstructSpaces( i, rdd ), itsf( i, rdd, addons ) );\n    }\n  } else {\n    for ( let i = start; i <= end; i += 1 ) {\n      mappedTkns.push( itsfn( i, rdd, addons ) );\n    }\n  }\n\n  return asfn( mappedTkns, rdd, start, end );\n}; // colTokensOut()\n\nmodule.exports = colTokensOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar allowed = require( '../allowed.js' );\n\n// ## itmTokenOut\n/**\n * Out method for a token. Note: the out always returns a Javascript\n * data type or data structure.\n * @param  {number}   index       The index of desired token.\n * @param  {Object}   rdd         Raw Document Data-structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @param  {object}   addons      The model's addons.\n * @return {*}                    Mapped value.\n * @private\n */\nvar itmTokenOut = function ( index, rdd, itsf, addons ) {\n  // Not a vector request, map using `itsf`.\n  var f = ( allowed.its4token.has( itsf ) ) ? itsf : its.value;\n  return f( index, rdd, addons );\n}; // itmTokenOut()\n\nmodule.exports = itmTokenOut;\n","/**\n * Map for collections.\n * @param  {function} f      Call back function that is called on each item.\n * @param  {number}   start  The start index in the collection.\n * @param  {number}   end    The end index.\n * @param  {function} itemFn Item function to create chainable-methods of the item.\n * @return {Array}           The mapped collection.\n * @private\n */\nvar colMap = function ( f, start, end, itemFn ) {\n  const result = [];\n  for ( let k = start; k <= end; k += 1 ) {\n    // Use relative indexing by adding `start` from `k`.\n    result.push(f( itemFn( k ), ( k - start ) ));\n  }\n  return result;\n};\n\nmodule.exports = colMap;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## locate\n/**\n *\n * Locates the `token`'s index in the `spans` and returns the index of the\n * span, where it is found; or the edge  a fraction between the 2-candidate\n * span-elements. Locate dictionary meaning: **discover the exact place or\n * position of.**\n *\n * @param {number} token to be located.\n * @param {array[]} spans where token will be searched.\n * @return {number} index of span where token is found; if it is not found then\n * it returns the edge  a fraction between the 2-candidate span-elements.\n * @private\n*/\nvar locate = function ( token, spans ) {\n  var minIndex = 0;\n  var maxIndex = spans.length - 1;\n  var currIndex;\n  var leftToken;\n  var rightToken;\n  // Edge, if `token` is not found; they are converted to fractions using `sf`.\n  var edge = -1;\n  // `0.5` is a safe fraction as it is `2 ** -1`\n  var sf = 0.5;\n  while ( minIndex <= maxIndex ) {\n    currIndex = ( minIndex + maxIndex ) / 2 | 0; // eslint-disable-line no-bitwise\n    leftToken = spans[ currIndex ][ 0 ];\n    rightToken = spans[ currIndex ][ 1 ];\n\n    if ( token > rightToken ) {\n      minIndex = currIndex + 1;\n      edge = currIndex + sf;\n    } else if ( token < leftToken ) {\n      maxIndex = currIndex - 1;\n      edge = currIndex - sf;\n    } else return currIndex;\n  }\n  // Not found  return the edge!\n  return edge;\n}; // locate()\n\nmodule.exports = locate;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-console */\n/* eslint-disable no-underscore-dangle */\n\nvar recTokenizer = require( './recursive-tokenizer.js' );\n\n/**\n * Creates an instance of tokenizer.\n *\n * @param  {object}   trex        language specific regular expressions needed for\n *                                tokenization. This includes helper, linear and\n *                                recursive.\n * @param  {object}   categories  tokens categories and their map to numeric code.\n * @param  {object}   preserve    language specific suffixes and prefixes to be preserved.\n * @return {function}             that performs the tokenization based on the\n *                                above configuration.\n * @private\n */\nvar tokenizer = function ( trex, categories, preserve ) {\n  // Maximum number of preceding spaces allowed.\n  var maxPrecedingSpaces = 65535;\n  var processFunctions = [];\n  var rgxCatDetectors = trex.ltc;\n  var tokenizeRecursively = recTokenizer( categories, preserve );\n  // Initialize helper regexes.\n  var rgxAnyWithRP = trex.helpers.anyWithRP;\n  var rgxAnyWithLP = trex.helpers.anyWithLP;\n  var rgxLPanyRP = trex.helpers.LPanyRP;\n  var rgxSplitter = trex.helpers.splitter;\n\n  var detectTokenCategory = function ( token ) {\n    // console.log( token );\n    var cat;\n    for ( cat = 0; cat < rgxCatDetectors.length; cat += 1 ) {\n      // console.log( token, rgxCatDetectors[ cat ][ 0 ].test( token ),  rgxCatDetectors[ cat ][ 1 ] )\n      if ( rgxCatDetectors[ cat ][ 0 ].test( token ) ) return rgxCatDetectors[ cat ][ 1 ];\n    }\n    return categories.unk;\n  }; // detectTokenCategory()\n\n\n  var processUnk = function ( text, cat, precedingSpaces, doc, nbsp ) {\n    // Match is captured here.\n    var match;\n    // Splitted non-punctuation portion's category.\n    var splitCat;\n\n    // Match with any thing followed by a **right** punctuation.\n    match = text.match( rgxAnyWithRP );\n    // Non-null indicates that there was a right punctuation in the end.\n    if ( match ) {\n      // Safely add the text prior to punkt if in cache.\n      splitCat = doc._addTokenIfInCache( match[ 1 ], precedingSpaces, nbsp );\n      if ( splitCat === categories.unk ) {\n        // Try detecting token category before falling back to recursion.\n        splitCat = detectTokenCategory( match[ 1 ] );\n        if ( splitCat  === categories.unk ) {\n          // Still 'unk', handle it via recursive tokenizer.\n          tokenizeRecursively( trex.rtc, text, precedingSpaces, doc, nbsp );\n        } else {\n          // Because it is a detected category use `processFunctions()`.\n          processFunctions[ splitCat ]( match[ 1 ], splitCat, precedingSpaces, doc, nbsp );\n          doc._addToken( match[ 2 ], categories.punctuation, 0, nbsp );\n        }\n      } else {\n        // The split is a added via `addTokenIfInCache()`, simply add the balance.\n        doc._addToken( match[ 2 ], categories.punctuation, 0, nbsp );\n      }\n      // All done so,\n      return;\n    }\n    // Match with any thing followed by a **left** punctuation.\n    match = text.match( rgxAnyWithLP );\n    // Now non-null indicates that there was a left punctuation in the beginning.\n    if ( match ) {\n      // If match 2 is a valid lexeme, can safley add tokens. Notice insertion\n      // sequence has reversed compared to the previous if block.\n      if ( doc.isLexeme( match[ 2 ] ) ) {\n        doc._addToken( match[ 1 ], categories.punctuation, precedingSpaces, nbsp );\n        doc._addTokenIfInCache( match[ 2 ], 0, nbsp );\n      } else {\n        // Try detecting token category before falling bac k to recursion.\n        splitCat = detectTokenCategory( match[ 2 ] );\n        if ( splitCat  === categories.unk ) {\n          // Still 'unk', handle it via recursive tokenizer.\n          tokenizeRecursively( trex.rtc, text, precedingSpaces, doc, nbsp );\n        } else {\n          // Because it is a detected category use `processFunctions()`.\n          doc._addToken( match[ 1 ], categories.punctuation, precedingSpaces, nbsp );\n          processFunctions[ splitCat ]( match[ 2 ], splitCat, 0, doc, nbsp );\n        }\n      }\n      // All done so,\n      return;\n    }\n    // Punctuation on both sides!\n    match = text.match( rgxLPanyRP );\n    if ( match ) {\n      // If match 2 is a valid lexeme, can safley add tokens.\n      if ( doc.isLexeme( match[ 2 ] ) ) {\n        doc._addToken( match[ 1 ], categories.punctuation, precedingSpaces, nbsp );\n        doc._addTokenIfInCache( match[ 2 ], 0, nbsp );\n        doc._addToken( match[ 3 ], categories.punctuation, 0, nbsp );\n      } else {\n        // Try detecting token category before falling bac k to recursion.\n        splitCat = detectTokenCategory( match[ 2 ] );\n        if ( splitCat  === categories.unk ) {\n          // Still 'unk', handle it via recursive tokenizer.\n          tokenizeRecursively( trex.rtc, text, precedingSpaces, doc, nbsp );\n        } else {\n          // Because it is a detected category use `processFunctions()`.\n          doc._addToken( match[ 1 ], categories.punctuation, precedingSpaces, nbsp );\n          processFunctions[ splitCat ]( match[ 2 ], splitCat, 0, doc, nbsp );\n          doc._addToken( match[ 3 ], categories.punctuation, 0, nbsp );\n        }\n      }\n      // All done so,\n      return;\n    }\n\n    // Nothing worked, treat the whole thing as `unk` and fallback to recursive tokenizer.\n    tokenizeRecursively( trex.rtc, text, precedingSpaces, doc, nbsp );\n  }; // processUnk()\n\n  // var processWord = function ( token, cat, precedingSpaces, doc ) {\n  //   doc._addToken( token, cat, precedingSpaces );\n  // }; // processWord()\n\n  var processWordRP = function ( token, cat, precedingSpaces, doc, nbsp ) {\n    // Handle **special case**, `^[a-z]\\.$` will arrive here instead of `shortForm`!\n    var tl = token.length;\n    if ( tl > 2 ) {\n      doc._addToken( token.slice( 0, -1 ), categories.word, precedingSpaces, nbsp );\n      doc._addToken( token.slice( -1 ), categories.punctuation, 0, nbsp );\n    } else if ( tl === 2 && token[ tl - 1 ] === '.' ) {\n        doc._addToken( token, categories.word, precedingSpaces, nbsp );\n      } else {\n        doc._addToken( token.slice( 0, -1 ), categories.word, precedingSpaces, nbsp );\n        doc._addToken( token.slice( -1 ), categories.punctuation, 0, nbsp );\n      }\n  }; // processWordRP()\n\n  var processDefault = function ( token, cat, precedingSpaces, doc, nbsp ) {\n    doc._addToken( token, cat, precedingSpaces, nbsp );\n  }; // processDefault()\n\n  var tokenize = function ( doc, text ) {\n    // Raw tokens, obtained by splitting them on spaces.\n    var rawTokens = [];\n    // Contains the number of spaces preceding a token.\n    var precedingSpaces = 0;\n    // Non breaking spaces.\n    var nbSpaces = null;\n    // Pointer to the `rawTokens`, whereas `pp` is the previous pointer!\n    var p;\n    // Token category as detected by the `detectTokenCategory()` function.\n    var cat;\n    // A temporary token!\n    var t;\n\n    rawTokens = text.split( rgxSplitter );\n\n    // Now process each raw token.\n    for ( p = 0; p < rawTokens.length; p += 1 ) {\n      t = rawTokens[ p ];\n      // Skip empty (`''`) token.\n      if ( !t ) continue; // eslint-disable-line no-continue\n      // Non-empty token:\n      const hasNBSP = ( /[\\u00a0\\u2002-\\u2005\\u2009\\u200a\\u202f\\u205f]/ ).test( t );\n      if ( t[ 0 ] === ' ' || hasNBSP ) {\n        // This indicates spaces: count them.\n        precedingSpaces = t.length;\n        if ( hasNBSP ) {\n          nbSpaces = t;\n          precedingSpaces = maxPrecedingSpaces;\n        } else if ( precedingSpaces > maxPrecedingSpaces - 1 ) precedingSpaces = maxPrecedingSpaces - 1;\n        // Cap precedingSpaces to a limit if it exceeds it.\n        // if ( precedingSpaces > maxPrecedingSpaces - 1 ) precedingSpaces = maxPrecedingSpaces - 1;\n      } else {\n        // A potential token: process it.\n        cat = doc._addTokenIfInCache( t, precedingSpaces, nbSpaces );\n        if ( cat === categories.unk ) {\n          cat = detectTokenCategory( t );\n          processFunctions[ cat ]( t, cat, precedingSpaces, doc, nbSpaces );\n        }\n        precedingSpaces = 0;\n        nbSpaces = null;\n      }\n    } // for\n  }; // tokenize()\n\n  // Main Code:\n  // Specific Processes.\n  processFunctions[ categories.unk ] = processUnk;\n  processFunctions[ categories.wordRP ] = processWordRP;\n\n  // Default process.\n  processFunctions[ categories.emoji ] = processDefault;\n  processFunctions[ categories.word ] = processDefault;\n  processFunctions[ categories.shortForm ] = processDefault;\n  processFunctions[ categories.number ] = processDefault;\n  processFunctions[ categories.url ] = processDefault;\n  processFunctions[ categories.email ] = processDefault;\n  processFunctions[ categories.mention ] = processDefault;\n  processFunctions[ categories.hashtag ] = processDefault;\n  processFunctions[ categories.emoticon ] = processDefault;\n  processFunctions[ categories.time ] = processDefault;\n  processFunctions[ categories.ordinal ] = processDefault;\n  processFunctions[ categories.currency ] = processDefault;\n  processFunctions[ categories.punctuation ] = processDefault;\n  processFunctions[ categories.symbol ] = processDefault;\n  processFunctions[ categories.tabCRLF ] = processDefault;\n  processFunctions[ categories.apos ] = processDefault;\n  processFunctions[ categories.alpha ] = processDefault;\n  processFunctions[ categories.decade ] = processDefault;\n\n  return tokenize;\n}; // tokenizer()\n\nmodule.exports = tokenizer;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/**\n * Stable sort function for frequency table i.e. `[ [ term, frequency ] ... ]`.\n * It first sorts on the frequency and then an alpha-numeric sort on term.\n *\n * @param  {array}  a first term-frequency pair element sent by sort.\n * @param  {array}  b second term-frequency pair element sent by sort.\n * @return {number}   number: -1 or 0 or +1.\n */\nmodule.exports = ( a, b ) => {\n  if ( b[ 1 ] > a[ 1 ] ) {\n    return 1;\n  } else if ( b[ 1 ] < a[ 1 ] ) {\n           return -1;\n         } else if ( a[ 0 ] > b[ 0 ] ) return 1;\n  return -1;\n};\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar helper = Object.create( null );\n\n/**\n * Tests if argument `v` is a JS object.\n *\n * @param {*} v       is tested for a valid JS object.\n * @returns {boolean} ture if `v` is a valid JS object, otherwise false.\n */\nhelper.isObject = function ( v ) {\n  return ( Object.prototype.toString.call( v ) === '[object Object]' );\n}; // isObject()\n\n/**\n * Tests if argument `v` is a JS array.\n *\n * @param {*} v       is tested for a valid JS array.\n * @returns {boolean} ture if `v` is a valid JS array, otherwise false.\n */\nhelper.isArray = function ( v ) {\n  return ( Object.prototype.toString.call( v ) === '[object Array]' );\n}; // isArray()\n\n/**\n * Tests if argument `n` is a finite integer.\n *\n * @param {*} n       is tested for a finite integer.\n * @returns {boolean} ture if `n` is a finite integer, otherwise false.\n */\nhelper.isFiniteInteger = function ( n ) {\n  return (\n    ( typeof n === 'number' ) &&\n    !isNaN( n ) &&\n    isFinite( n ) &&\n    ( n === Math.round( n ) )\n  );\n}; // isFiniteInteger()\n\n/**\n * Tests if argument `a` contains one or more finite integers.\n *\n * @param {*} a       is tested for an array of finite integers.\n * @returns {boolean} ture if `n` is an array of finite integers, otherwise false.\n */\nhelper.isIntegerArray = function ( a ) {\n  // If it is not an array, return `false`.\n  if ( !helper.isArray( a ) ) return false;\n\n  // Has no element i.e. no finite integer  return `false`.\n  if ( a.length === 0 ) return false;\n\n  // Test every element for a finite integer.\n  for ( let i = 0; i < a.length; i += 1 ) {\n    // Any failure means immediately return `false`.\n    if ( !helper.isFiniteInteger( a[ i ] ) ) return false;\n  }\n\n  // It is an array and contains all finite integers, return `true`.\n  return true;\n}; // isIntegerArray()\n\nmodule.exports = helper;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar colTokensOut = require( './col-tokens-out.js' );\n\n// ## itmSentenceOut\n/**\n * Out method for a sentence. Note: the out always returns a Javascript\n * data type or data structure.\n * @param  {number}   index       The index of desired sentence.\n * @param  {Object}   rdd         Raw Document Data-structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @param  {object}   addons      The model's addons.\n * @return {*}                    Mapped value.\n * @private\n */\nvar itmSentenceOut = function ( index, rdd, itsf, addons ) {\n  var sentence = rdd.sentences[ index ];\n\n  var itsfn = ( itsf && allowed.its4sentence.has( itsf ) ) ? itsf : its.value;\n\n  if ( itsfn === its.span || itsfn === its.sentiment ) {\n    return itsfn( sentence );\n  }\n\n  // Handle `its.negationFlag` seprately here.\n  if ( itsfn === its.negationFlag ) {\n    return ( sentence[ 2 ] === 1 );\n  }\n\n  // Setup the correct `as.fn` becuase the current markedup text would have\n  // returned the `value`. Refer to `its.markedUpText`.\n  var asfn = ( itsfn === its.markedUpText ) ? as.markedUpText : as.text;\n\n  return colTokensOut( sentence[ 0 ], sentence[ 1 ], rdd, itsfn, asfn, addons );\n}; // itmSentenceOut()\n\nmodule.exports = itmSentenceOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar regex = /\\[.*?\\]/g;\n\n// ## extractEnclosedText\n/**\n *\n * Extracts the text enclosed in square brackets.\n *\n * @param {string} text from which enclosed text is extracted.\n * @returns {string[]} texts enclosed within square brackets.\n * @private\n*/\nvar extractEnclosedText = function ( text ) {\n  var // Extracted elements are captured here.\n      elements = [],\n      // Extract matches with quotes\n      matches = text.match( regex );\n  if ( !matches || ( matches.length === 0 ) ) return null;\n  // Collect elements after removing the quotes.\n  for ( var k = 0, kmax = matches.length; k < kmax; k += 1 ) {\n    elements.push( matches[ k ].substr( 1, matches[ k ].length - 2 ) );\n  }\n  return ( elements );\n}; // extractEnclosedText();\n\n// ## productReducer\n/**\n *\n * Callback function used by `reduce` inside the `product()` function.\n * Follows the standard guidelines of `reduce()` callback function.\n *\n * @param {array} prev refer to JS reduce function.\n * @param {array} curr refer to JS reduce function.\n * @returns {array} reduced value.\n * @private\n*/\nvar productReducer = function ( prev, curr ) {\n  var c,\n      cmax = curr.length;\n  var p,\n      pmax = prev.length;\n  var result = [];\n\n  for ( p = 0; p < pmax; p += 1 ) {\n    for ( c = 0; c < cmax; c += 1 ) {\n      result.push( prev[ p ].concat( curr[ c ] ) );\n    }\n  }\n  return ( result );\n}; // productReducer()\n\n/**\n *\n * Finds the Cartesian Product of arrays present inside the array `a`. Therefore\n * the array `a` must be an array of 1-dimensional arrays. For example,\n * `product( [ [ 9, 8 ], [ 1, 2 ] ] )` will produce\n * `[ [ 9, 1 ], [ 9, 2 ], [ 8, 1 ], [ 8, 2 ] ]`.\n *\n * @param {array} a whose cartesian product is computed.\n * @returns {array} reduced value.\n * @private\n*/\nvar product = function ( a ) {\n  return (\n    a.reduce( productReducer, [ [] ] )\n  );\n}; // product()\n\n\n// ## composeCorpus\n/**\n *\n * Generates all possible patterns from the input argument string.\n * The string s must follow a special syntax as illustrated in the\n * example below:<br/>\n * `'[I] [am having|have] [a] [problem|question]'`<br/>\n *\n * Each phrase must be quoted between `[ ]` and each possible option of phrases\n * (if any) must be separated by a `|` character. The patterns are composed by\n * computing the cartesian product of all the phrases.\n *\n * If a single patterns expands to a large size then it issues console\n * warning/error at 512/65536 level.\n *\n * @param {string} str the input string.\n * @return {string[]} of all possible patterns.\n * @private\n*/\nvar composePatterns = function ( str ) {\n  if ( !str || ( typeof str !== 'string' ) ) return [];\n\n  const LIMIT1 = 512;\n  const LIMIT2 = 65536;\n  var quotedTextElems = extractEnclosedText( str );\n  var patterns = [];\n  var finalPatterns = [];\n\n  if ( !quotedTextElems ) return [ [ str ] ];\n  quotedTextElems.forEach( function ( e ) {\n    patterns.push( e.split( '|' ) );\n  } );\n\n  // Compute the size of the array that will be produced as a result of processing\n  // the pattern.\n  const size = patterns.reduce( ( ( prev, curr ) => prev * curr.length ), 1 );\n\n  // Issue warning/error if the size is prohibitively large from the end-user\n  // prespective. Note: while winkNLP can handle even larger sizes, it can\n  // still break down in the event of explosion!\n  if ( size > LIMIT1 && size < LIMIT2 ) {\n    console.warn( 'winkNLP: complex pattern detected, consider simplifying it!' );\n  } else if ( size > LIMIT2 ) console.error(\n                              'winkNLP: very complex pattern detected, please review and simplify.\\n' +\n                              '         === It may slow down further execution! ===\\n\\n'\n                             );\n\n  product( patterns ).forEach( function ( e ) {\n    finalPatterns.push( e.join( ' ' ).trim().split( /\\s+/ ) );\n  } );\n  return ( finalPatterns );\n}; // composePatterns()\n\nmodule.exports = composePatterns;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## selEach\n/**\n * Iterator for selection.\n * @param  {function} f         Call back function that is called on each item.\n * @param  {number[]} selection Array containing indexes to the selected items.\n * @param  {function} itemFn    Item function to create chainable-methods of the item.\n * @return {void}               Nothing!\n * @private\n */\nvar selEach = function ( f, selection, itemFn ) {\n  for ( let k = 0; k < selection.length; k += 1 ) {\n    f( itemFn( selection[ k ] ), k );\n  }\n}; // selEach()\n\nmodule.exports = selEach;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n\n// Used in accessing the regex and its category from `rgxs`.\nconst RGX = 0;\nconst CAT = 1;\n// SPECIAL REGULAR EXPRESSIONS:\n// Regex to handle short forms or abbreviations.\nvar rgxShortFormDot = /^(?:(?:[A-Z])(?:\\.))+$/i;\nvar rgxShortForm = /^(?:(?:[A-Z])(?:\\.))+[a-z]?$/i;\n// Regex process hyphenated words.\nvar rgxHyphens = /[\\-\\\\]/gi;\nvar rgxPeriod = /[\\.]/gi;\nvar rgxNumber = /[0-9]/;\n\n// ### tokenizer\n/**\n *\n * Creates an instance of `tokenizer`.\n *\n * @param {object} categories token categories, as obtained via the language model.\n * @param {object} preserve rules for hyphenation preservation.\n * @return {function} for recursive tokenization.\n * @private\n*/\nvar tokenizer = function ( categories, preserve ) {\n  // Function to add tokens to the `doc()`.\n  var addToken;\n  var addTokenIfInCache;\n  // Function to test if lexeme exists via `doc()`.\n  var isLexeme;\n  // Preceding Spaces  special need for recursive tokenizer.\n  var ps = 0;\n  // Will only be needed for the first token, after that it si all zero (ps)!\n  var nonBreakingSpaces = null;\n\n  // ### pushHyphenatedToken\n  /**\n   *\n   * Pushes the incoming `tkn` after handling hyphens, if any:\n   * 1. Use it as-is if it is a valid lexeme or contains a number.\n   * 2. Use it as-is if does not contain hyphens.\n   * 3. Otherwise apply rules.\n   *\n   * @param {string} tkn to be processed as per rules hyphenation rules in `preserve`.\n   * @param {array} tokens into which the (split) `tkn` is pushed.\n   * @returns {void} nothing!\n   * @private\n  */\n  var pushHyphenatedToken = function ( tkn, tokens ) {\n    // Will contain pure alpha words, obtained by splitting on `rgxHyphens`.\n    var words;\n    // Will contain mathed hyphens.\n    var hyphens;\n    // Helper variables.\n    var i, k, last;\n\n    // If a token is a valid lexeme or contains one or more number, dont touch it.\n    if ( isLexeme( tkn) || rgxNumber.test( tkn ) ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n\n    hyphens = tkn.match( rgxHyphens );\n    // If there are no hyphens in the word, dont touch it.\n    if ( hyphens === null ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n\n    // Word is hyphenated, process it according to the rules specified in `preserve`.\n    words = tkn.split( rgxHyphens );\n    last = words.length - 1;\n    if ( preserve.prefix[ words[ 0 ] ] || preserve.suffix[ words[ last ] ] ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n    k = 0;\n    for ( i = 0; i < words.length; i += 1 ) {\n      // Do not push any empty token!\n      if ( words[ i ] !== '' ) {\n        tokens.push( [ words[ i ], categories.word ] );\n      }\n\n      if ( k < hyphens.length ) {\n        tokens.push( [ hyphens[ k ], categories.punctuation ] );\n      }\n      k += 1;\n    }\n  }; // pushHyphenatedToken()\n\n  // ### pushWordToken\n  /**\n   *\n   * Pushes the incoming `tkn` after handling periods and hyphens present:\n   * 1. Use it as-is if it is a valid lexeme or a short form ending with a period.\n   * 2. Split on period and the successively assemble tokens using matches & splits.\n   * 3. Finally send each such assembled token down for handling hyphenated word.\n   *\n   * @param {string} tkn to be processed and pushed.\n   * @param {array} tokens into which the (split) `tkn` is pushed.\n   * @returns {void} nothing!\n   * @private\n  */\n  var pushWordToken = function ( tkn, tokens ) {\n    // Will contain words, obtained by splitting on `rgxPeriod`.\n    var words;\n    // Will contain matched periods.\n    var periods;\n    // Helper variables:<br/>\n    // Index variables\n    var i, k;\n    // Used in successively assembling a potential token from matches & words\n    // (i.e. splits), if word has periods.\n    var currBuild = '';\n    var nextBuild = '';\n\n\n    // If a token is a **valid lexeme**, or it is **short form ending with a\n    // period** (e.g. dot) then _dont touch it._\n    if ( isLexeme( tkn ) || rgxShortFormDot.test( tkn ) ) {\n      tokens.push( [ tkn, categories.word ] );\n      return;\n    }\n\n    // Start by matching with periods\n    periods = tkn.match( rgxPeriod );\n    // If there are no periods in the word, dont touch it.\n    if ( periods === null ) {\n      pushHyphenatedToken( tkn, tokens );\n      return;\n    }\n\n    // Word has periods, therefore process it:\n    words = tkn.split( rgxPeriod );\n    k = 0;\n\n    for ( i = 0; i < words.length; i += 1 ) {\n      // Build next potential token by joining the current build with the next word.\n      nextBuild = currBuild + words[ i ];\n      // If it is a valid possibility, then continue building it.\n      if ( rgxShortForm.test( nextBuild ) || ( isLexeme( nextBuild ) && nextBuild.length > 2 ) || ( currBuild === '' ) ) {\n        currBuild = nextBuild;\n      } else {\n        // Else send it down to handle hyphenated word.\n        pushHyphenatedToken( currBuild, tokens );\n        // Reset builds.\n        currBuild = words[ i ];\n        nextBuild = '';\n      }\n\n      if ( k < periods.length ) {\n        // In the same manner handle period sign.\n        nextBuild = currBuild + periods[ k ];\n        if ( rgxShortForm.test( nextBuild ) || ( isLexeme( nextBuild ) && nextBuild.length > 2 ) ) {\n          currBuild = nextBuild;\n        } else {\n          pushHyphenatedToken( currBuild, tokens );\n          tokens.push( [ periods[ k ], categories.punctuation ] );\n          currBuild = '';\n          nextBuild = '';\n        }\n      }\n      k += 1;\n    }\n    // Handle the last piece if applicable.\n    if ( currBuild !== '' ) pushHyphenatedToken( currBuild, tokens );\n  }; // pushWordToken()\n\n  // ### tokenizeTextUnit\n  /**\n   *\n   * Attempts to tokenize the input `text` using the `rgxSplit`. The tokenization\n   * is carried out by combining the regex matches and splits in the right sequence.\n   * The matches are the *real tokens*, whereas splits are text units that are\n   * tokenized in later rounds! The real tokens (i.e. matches) are pushed as\n   * `object` and splits as `string`.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} rgxSplit object containing the regex and it's category.\n   * @return {array} of tokens.\n   * @private\n  */\n  var tokenizeTextUnit = function ( text, rgxSplit ) {\n    // Regex matches go here; note each match is a token and has the same tag\n    // as of regex's category.\n    var matches = text.match( rgxSplit[ RGX ] );\n    // Balance is \"what needs to be tokenized\".\n    var balance = text.split( rgxSplit[ RGX ] );\n    // The result, in form of combination of tokens & matches, is captured here.\n    var tokens = [];\n    // The tag;\n    var tag = rgxSplit[ CAT ];\n    // Helper variables.\n    var i,\n        imax,\n        k,\n        t; // Temp token.\n        // tp; // Temp token with a period sign in end.\n\n    // console.log( matches, balance, text, tag, balance[ 1 ] ); // eslint-disable-line no-console\n    // A `null` value means it is equivalent to no matches i.e. an empty array.\n    matches = ( matches ) ? matches : [];\n    // Handle cases where the word is ending with period for **word category**.\n    // Iterate in [ m0 b1 m1 ... ] pattern as `b0` has no value here.\n    // *** COMMENTED out after `pushWordToken()`:\n    // k = 0;\n    // if ( tag === categories.word ) {\n    //   for ( i = 1, imax = balance.length; i < imax; i += 1 ) {\n    //     t = balance[ i ];\n    //     if ( k < matches.length && t[ 0 ] === '.' ) {\n    //       tp = matches[ k ] + '.';\n    //       if ( isLexeme( tp ) || rgxShortForm.test( tp ) ) {\n    //         matches[ k ] = tp;\n    //         balance[ i ] = t.slice( 1 );\n    //       }\n    //     }\n    //     k += 1;\n    //   }\n    // }\n\n    // console.log( matches, balance, text, tag, balance[ 1 ] ); // eslint-disable-line no-console\n    // Combine tokens & matches in the following pattern [ b0 m0 b1 m1 ... ]\n    k = 0;\n    for ( i = 0, imax = balance.length; i < imax; i += 1 ) {\n      t = balance[ i ];\n      t = t.trim();\n      if ( t ) tokens.push( t );\n      if ( k < matches.length ) {\n        if ( tag === categories.word ) {\n          // Handle special cases for words via:\n          pushWordToken( matches[ k ], tokens );\n        } else {\n          tokens.push( [ matches[ k ], tag ] );\n        }\n      }\n      k += 1;\n    }\n\n    return ( tokens );\n  }; // tokenizeTextUnit()\n\n  // ### tokenizeTextRecursively\n  /**\n   *\n   * Tokenizes the input text recursively using the array of `regexes` and then\n   * the `tokenizeTextUnit()` function. If (or whenever) the `regexes` becomes\n   * empty, it simply splits the text on non-word characters instead of using\n   * the `tokenizeTextUnit()` function.\n   *\n   * @param {string} text unit that is to be tokenized.\n   * @param {object} regexes object containing the regex and it's category.\n   * @return {undefined} nothing!\n   * @private\n  */\n  var tokenizeTextRecursively = function ( text, regexes ) {\n    var sentence = text.trim();\n    var tokens = [];\n    // Helpers  for loop variables & token category.\n    var i, imax;\n    var cat;\n\n    if ( !regexes.length ) {\n      // No regex left, this is the true **unk**.\n      // Becuase it is `UNK`, we can use `addToken` instead of attempting\n      // `addTokenIfInCache`.\n      addToken( text, categories.unk, ps, nonBreakingSpaces );\n      ps = 0;\n      return;\n    }\n\n    var rgx = regexes[ 0 ];\n    tokens = tokenizeTextUnit( sentence, rgx );\n\n    for ( i = 0, imax = tokens.length; i < imax; i += 1 ) {\n      if ( typeof tokens[ i ] === 'string' ) {\n        // Strings become candidates for further tokenization.\n        tokenizeTextRecursively( tokens[ i ], regexes.slice( 1 ) );\n      } else {\n        // Use the passed value of preceding spaces only once!\n        // First try cache, otherwise make a direct addition. This ensures\n        // processing of expansions.\n        cat = addTokenIfInCache( tokens[ i ][ 0 ], ps, nonBreakingSpaces );\n        if ( cat === categories.unk ) addToken( tokens[ i ][ 0 ], tokens[ i ][ 1 ], ps, nonBreakingSpaces );\n        // Reset `ps` to **0** as there can never be spaces in a text passed to\n        // this tokenizer.\n        ps = 0;\n      }\n    }\n  }; // tokenizeTextRecursively()\n\n  // ### tokenize\n  /**\n   *\n   * Tokenizes the input `sentence` using the function `tokenizeTextRecursively()`.\n   * This acts as the fall back tokenizer to the **linear tokenizer**.\n   *\n   * @method Tokenizer#tokenize\n   * @param {RegExp} rgxs containg regexes for parsing.\n   * @param {string} text the input sentence.\n   * @param {number} precedingSpaces to the text\n   * @param {object} doc contains the document; used here for adding tokens.\n   * @param {array}  nbsp contains non breaking spaces details.\n   * @return {void} nothing!\n   * `value` and its `tag` identifying the type of the token.\n   * @private\n  */\n  var tokenize = function ( rgxs, text, precedingSpaces, doc, nbsp ) {\n    // Cache frequently used doc methods.\n    addToken = doc._addToken;\n    addTokenIfInCache = doc._addTokenIfInCache;\n    isLexeme = doc.isLexeme;\n    // Set `ps` to the passed value of preceding spaces, it will be reset to **0**\n    // after first use during recursion.\n    ps = precedingSpaces;\n    nonBreakingSpaces = nbsp;\n    tokenizeTextRecursively( text, rgxs, precedingSpaces );\n  }; // tokenize()\n\n  return tokenize;\n};\n\nmodule.exports = tokenizer;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar constants = require( '../constants.js' );\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Mask for preceding spaces.\nvar psMask = constants.psMask;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// Mask for extracting pos\nvar posMask = constants.posMask;\n\n\n// ### printTokens\n/**\n *\n * Prints a table of tokens along with their properties on console.\n *\n * @param {number[]} tokens The tokens.\n * @param {object} cache The language `cache`.\n * @returns {void} Nothing!\n * @private\n*/\nvar printTokens = function ( tokens, cache ) {\n  var imax = tokens.length;\n  var i, j;\n  var t, tv;\n  var pad = '                         ';\n  var str;\n  var props = [ 'prefix', 'suffix', 'shape', 'lutCase', 'nerHint', 'tokenType' ];\n\n  // Print header.\n  console.log( '\\n\\ntoken      p-spaces   prefix  suffix  shape   case    nerHint type     normal/pos' );\n  console.log( '' );\n  for ( i = 0; i < imax; i += tkSize ) {\n    str = '';\n    t = tokens[ i ];\n    tv = cache.value( t );\n    str += ( JSON.stringify( tv ).replace( /\"/g, '' )  + pad ).slice( 0, 18 );\n    str += ( ( tokens[ i + 1 ] & psMask ) + pad ).slice( 0, 4 );  // eslint-disable-line no-bitwise\n    for ( j = 0; j < props.length; j += 1 ) {\n      str += ( JSON.stringify( cache.property( t, props[ j ] ) ).replace( /\"/g, '' ) + pad ).slice( 0, 8 );\n    }\n    if ( tokens[ i + 1 ] > 65535 ) {\n      str += ' ' + cache.value( cache.nox( tokens[ i + 1 ] ) ); // eslint-disable-line no-bitwise\n      str += ' / ' + cache.valueOf( 'pos', ( tokens[ i + 2 ] & posMask ) >>> bits4lemma ); // eslint-disable-line no-bitwise\n    } else {\n      str += ' ' + JSON.stringify( cache.value( cache.normal( t ) ) ).replace( /\"/g, '' );\n      str += ' / ' + cache.property( t, 'pos' );\n    }\n\n    // str += '/' + cache.property( t, 'nerHint' );  // eslint-disable-line no-bitwise\n    console.log( str );\n    // Not being used as of now; to use move it before the console.log!\n    str += ' / ' + cache.valueOf( 'pos', ( tokens[ i + 2 ] & posMask ) >>> bits4lemma );  // eslint-disable-line no-bitwise\n  }\n\n  // Print total number of tokens.\n  console.log( '\\n\\ntotal number of tokens: %d', tokens.length / tkSize );\n}; // printTokens()\n\nmodule.exports = printTokens;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## colFilter\n/**\n * Filter for collections.\n * @param  {function} f             Predicate function to test each item of\n *                                  the array. Return true to select the item,\n *                                  false to reject or exclude.\n * @param  {number}   start         The start index.\n * @param  {number}   end           The end index.\n * @param  {function} itemFn        Item function to create chainable-methods of the item.\n * @param  {function} colSelectedFn The function to create chainable-methods for\n *                                  the collection of selection, which are returned.\n * @return {object}                 Object containing the applicable chainable-methods.\n */\nvar colFilter = function ( f, start, end, itemFn, colSelectedFn ) {\n  var filtered = [];\n  for ( let k = start; k <= end; k += 1 ) {\n    // Use relative indexing by adding `start` from `k`.\n    if ( f( itemFn( k ), ( k - start ) ) ) filtered.push( k );\n  }\n  return colSelectedFn( filtered );\n}; // colFilter()\n\nmodule.exports = colFilter;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar consts = Object.create( null );\n// Unknown or the UNK!\nconsts.UNK = 0;\n// Bits reserved for `precedingSpaces`.\nconsts.bits4PrecedingSpace = 16;\n// Bits reserved for `lemma`.\nconsts.bits4lemma = 20;\n// Mask for pos extraction from tokens\nconsts.posMask = 0x3F00000;\n// Mask for preceding spaces.\nconsts.psMask = 0xFFFF;\n// Mask for pointer to normal in `xpansions`.\nconsts.xnMask = 0x3FFF0000;\n// Mask for lemma extraction in case of contractions.\nconsts.lemmaMask = 0xFFFFF;\n// Size of a single token.\nconsts.tkSize = 4;\n// Size of a single expansion.\nconsts.xpSize = 4; // can't: ca can can MD i.e. expansion, normal, lemma, pos.\n// Expansion count mask.\nconsts.xcMask = 0x1F;\n// Bits reserved for point to expansions in `lemma` space.\nconsts.bits4xpPointer = 14;\n// Negation Flag.\nconsts.negationFlag = Math.pow( 2, 31 );\n\nmodule.exports = consts;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## selGetItemAt\n/**\n * Obtains an item at the specified index from a collection.\n * @param  {number}   k         Relative index of the required item.\n * @param  {number[]} selection Array containing indexes to the selected items.\n * @param  {function} itemFn    Item function to create chainable-methods of the item.\n * @return {object}             Object containing the applicable chainable-methods\n *                              for the item found at `k`; otherwise `undefined`.\n * @private\n */\nvar selGetItemAt = function ( k, selection, itemFn ) {\n  if ( k < 0 || k >= selection.length ) {\n    throw Error( `wink-nlp: wink-nlp: ${k} is an invalid or out of bounds index.`);\n  } else return itemFn( selection[ k ] );\n}; // selGetItemAt()\n\nmodule.exports = selGetItemAt;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n/* eslint-disable no-console */\n\nvar containedEntities = require( './contained-entities.js' );\n\n// ### Helper Functions\n\n// Get **item at** collection, selection & parent.\nvar getParentItem = require( './api/get-parent-item.js' );\nvar colGetItemAt = require( './api/col-get-item.js' );\nvar selGetItemAt = require( './api/sel-get-item.js' );\n\n// **Each** iterator for collection & selection.\nvar colEach = require( './api/col-each.js' );\nvar selEach = require( './api/sel-each.js' );\n\nvar colMap = require( './api/col-map.js' );\nvar selMap = require( './api/sel-map.js' );\n\n// **Filter** for collection & selection.\nvar colFilter = require( './api/col-filter.js' );\nvar selFilter = require( './api/sel-filter.js' );\n\n// **Token's out** for item, collection & selection.\nvar itmTokenOut = require( './api/itm-token-out.js' );\nvar colTokensOut = require( './api/col-tokens-out.js' );\nvar selTokensOut = require( './api/sel-tokens-out.js' );\n\n// **Entity's out** for item, collection & selection.\nvar itmEntityOut = require( './api/itm-entity-out.js' );\nvar colEntitiesOut = require( './api/col-entities-out.js' );\nvar selEntitiesOut = require( './api/sel-entities-out.js' );\n\n// **Sentence's out** for item, collection & selection.\nvar itmSentenceOut = require( './api/itm-sentence-out.js' );\nvar colSentencesOut = require( './api/col-sentences-out.js' );\n\n// **Document's out** for item.\nvar itmDocumentOut = require( './api/itm-document-out.js' );\n\n// Print tokens, it is primarily for command line output.\nvar printTokens = require( './api/print-tokens.js' );\n\nvar its = require( './its.js' );\n\n// <hr/>\n\n// # Doc\n/**\n *\n * The wink-nlp **doc**ument  constructed in `wink-nlp.js`  publishes the\n * developer APIs.\n *\n * @param  {object} docData     It encapsulates the document data.\n * @param  {object} addons      The model's addon, may contain word vectors, stemmer etc.\n * @return {object}             conatining APIs.\n * @private\n */\nvar doc = function ( docData, addons ) {\n  // Extract `cache` as it is frequently accessed.\n  var cache = docData.cache;\n\n  // Document's tokens; each token is represented as an array of numbers:\n  // ```\n  // [\n  //   hash, // of tokenized lexeme\n  //   (nox) + preceding spaces, // expansion's normal\n  //   pos + lemma, // pos & lemma are contextual\n  //   entity + sentence // 12bit + 20bits\n  // ]\n  // ```\n  var tokens = docData.tokens;\n\n  // Entities  sorted as array of `[ start, end, entity type ].`\n  var entities = docData.entities;\n  var customEntities = docData.customEntities;\n\n  // Sentences  sorted as array of pairs of `[ start, end ]` pointing to the `tokens`.\n  var sentences = docData.sentences;\n\n  // Markings are 4-tuples of `start`, `end` **token indexes**,  and `begin & end markers`.\n  // The begin & end markers are used to markup the tokens specified.\n  var markings = docData.markings;\n\n\n  // #### API core functions:\n\n  // Collection APIs.\n  var colEntities;\n  var colCustomEntities;\n  var colTokens;\n  var colSentences;\n\n  // Selection  obtained via `filter`  APIs. It is also like a collection.\n  var colSelectedEntities;\n  var colSelectedCustomEntities;\n  var colSelectedTokens;\n\n  // Item APIs.\n  var itemToken;\n  var itemEntity;\n  var itemCustomEntity;\n  var itemSentence;\n\n  // Vectors API\n  var contextualVectors;\n\n  // Others.\n  var isLexeme = cache.lookup;\n\n  // The Document  Returned!\n  var methods = Object.create( null );\n\n  // ## Token\n  // **Item, Collection, and Selection APIs.**\n\n  // ### itemToken\n  /**\n   *\n   * Makes item of the token specified at `index`.\n   *\n   * @param  {number} index The index of the token, which is required to be returned as item token.\n   * @return {object}       containing applicable API methods.\n   * @private\n   */\n  itemToken = function ( index ) {\n    var api = Object.create( null );\n    // Access the parent document.\n    api.parentDocument = () => methods;\n    // Access the parent entity, **if any.**\n    api.parentEntity = () => getParentItem( index, entities, itemEntity );\n    // Access the parent cuustom entity, **if any.**\n    api.parentCustomEntity = () => getParentItem( index, customEntities, itemCustomEntity );\n    // Markup this token.\n    api.markup = ( beginMarker, endMarker ) => markings.push( [ index, index, beginMarker, endMarker ] );\n    // Output this token or its properties using mapper function  `f`.\n    api.out = ( f ) => itmTokenOut( index, docData, f, addons );\n    // Access the parent sentence.\n    api.parentSentence = () => getParentItem( index, sentences, itemSentence );\n    // Index within the document.\n    api.index = () => ( index );\n    return api;\n  }; // itemToken()\n\n  // ### colSelectedTokens\n  /**\n   *\n   * Makes collection of tokens identified by the `selectedTokens` array.\n   *\n   * @param  {array} selectedTokens The array of selected tokens, using which the\n   *                                collection is made.\n   * @return {object}               containing applicable API methods.\n   * @private\n   */\n  colSelectedTokens = function ( selectedTokens ) {\n    var api = Object.create( null );\n    // Iterator.\n    api.each = ( f ) => selEach( f, selectedTokens, itemToken );\n    // Map.\n    api.map = ( f ) => selMap( f, selectedTokens, itemToken );\n    // Filter.\n    api.filter = ( f ) => selFilter( f, selectedTokens, itemToken, colSelectedTokens );\n    // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n    api.itemAt = ( k ) => selGetItemAt( k, selectedTokens, itemToken );\n    // Number of selected tokens.\n    api.length = () => ( selectedTokens.length );\n    // Output this collection of selected tokens as a reduced values or properties\n    // using map/reduce functions  `f/g`.\n    api.out = ( f, g ) => selTokensOut( selectedTokens, docData, f, g, addons );\n    return api;\n  }; // colTokens()\n\n  // ### colTokens\n  /**\n   *\n   * Makes collection of tokens beginning from `start` index to `end` index.\n   *\n   * @param  {number} start The start index.\n   * @param  {number} end   The end index.\n   * @return {object}       containing applicable API methods.\n   * @private\n   */\n  colTokens = function ( start, end ) {\n    return (\n      function () {\n        var api = Object.create( null );\n        // Iterator.\n        api.each = ( f ) => colEach( f, start, end, itemToken );\n        // Map.\n        api.map = ( f ) => colMap( f, start, end, itemToken );\n        // Filter.\n        api.filter = ( f ) => colFilter( f, start, end, itemToken, colSelectedTokens );\n        // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n        // No need to handle relative indexing as `colGetItemAt` handles it.\n        api.itemAt = ( k ) => colGetItemAt( k, start, end, itemToken );\n        // Length of this collection.\n        api.length = () => ( end - start + 1 );\n        // Output this token collection as a reduced values or properties using\n        // map/reduce functions  `f/g`.\n        api.out = ( f, g ) => colTokensOut( start, end, docData, f, g, addons );\n\n        return api;\n      }\n    );\n  }; // colTokens()\n\n  // <hr/>\n\n  // ## Entity\n  // **Item, Collection, and Selection APIs.**\n\n  // ### itemEntity\n  /**\n   *\n   * Makes item of the entity specified at `index`.\n   *\n   * @param  {number} index The index of the entity, which is required to be\n   *                        returned as item entity.\n   * @return {object}       containing applicable API methods.\n   * @private\n   */\n  itemEntity = function ( index ) {\n    var api = Object.create( null );\n    // Access the parent document.\n    api.parentDocument = () => methods;\n    // Markup this entity.\n    api.markup = ( beginMarker, endMarker ) => markings.push( [ entities[ index ][ 0 ], entities[ index ][ 1 ], beginMarker, endMarker ] );\n    // Output this entity or its properties using mapper function  `f`.\n    api.out = ( f ) => itmEntityOut( index, entities, docData, f );\n    // Access the parent sentence.\n    api.parentSentence =  () => getParentItem( entities[ index ][ 0 ], sentences, itemSentence );\n    // Retun collection of tokens contained in this entity.\n    api.tokens = colTokens( entities[ index ][ 0 ], entities[ index ][ 1 ] );\n    // Index within the document.\n    api.index = () => ( index );\n    return api;\n  }; // itemEntity()\n\n  // ### colSelectedEntities\n  /**\n   *\n   * Makes collection of entities identified by the `selectedEntities` array.\n   *\n   * @param  {array} selectedEntities The array of selected entities, using which\n   *                                  the collection is made.\n   * @return {object}                 containing applicable API methods.\n   * @private\n   */\n  colSelectedEntities = function ( selectedEntities ) {\n    var api = Object.create( null );\n    // Iterator.\n    api.each = ( f ) => selEach( f, selectedEntities, itemEntity );\n    // Map.\n    api.map = ( f ) => selMap( f, selectedEntities, itemEntity );\n    // Filter.\n    api.filter = ( f ) => selFilter( f, selectedEntities, itemEntity, colSelectedEntities );\n    // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n    api.itemAt = ( k ) => selGetItemAt( k, selectedEntities, itemEntity );\n    // Number of selected entities.\n    api.length = () => ( selectedEntities.length );\n    // Output this collectionn of selected of entities as a reduced value\n    // using map/reduce functions  `f/g`.\n    api.out = ( f, g ) => selEntitiesOut( selectedEntities, entities, docData, f, g );\n    return api;\n  }; // colSelectedEntities()\n\n  // ### colEntities\n  /**\n   *\n   * Makes collection of all the entities.\n   *\n   * @return {object} containing applicable API methods.\n   * @private\n   */\n  colEntities = function () {\n    var api = Object.create( null );\n    // Iterator.\n    api.each = ( f ) => colEach( f, 0, entities.length - 1, itemEntity );\n    // Map.\n    api.map = ( f ) => colMap( f, 0, entities.length - 1, itemEntity );\n    // Filter.\n    api.filter = ( f ) => colFilter( f, 0, entities.length - 1, itemEntity, colSelectedEntities );\n    // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n    api.itemAt = ( k ) => colGetItemAt( k, 0, ( entities.length - 1 ), itemEntity );\n    // Length of this collection.\n    api.length = () => ( entities.length );\n    // Output this collection of entities as a reduced value\n    // using map/reduce functions  `f/g`.\n    api.out = ( f, g ) => colEntitiesOut( entities, docData, f, g );\n    return api;\n  }; // colEntities()\n\n  // <hr/>\n\n  // ## Entity\n  // **Item, Collection, and Selection APIs.**\n\n  // ### itemCustomEntity\n  /**\n   *\n   * Makes item of the entity specified at `index`.\n   *\n   * @param  {number} index The index of the entity, which is required to be\n   *                        returned as item entity.\n   * @return {object}       containing applicable API methods.\n   * @private\n   */\n  itemCustomEntity = function ( index ) {\n    var api = Object.create( null );\n    // Access the parent document.\n    api.parentDocument = () => methods;\n    // Markup this entity.\n    api.markup = ( beginMarker, endMarker ) => markings.push( [ customEntities[ index ][ 0 ], customEntities[ index ][ 1 ], beginMarker, endMarker ] );\n    // Output this entity or its properties using mapper function  `f`.\n    api.out = ( f ) => itmEntityOut( index, customEntities, docData, f );\n    // Access the parent sentence.\n    api.parentSentence =  () => getParentItem( customEntities[ index ][ 0 ], sentences, itemSentence );\n    // Retun collection of tokens contained in this entity.\n    api.tokens = colTokens( customEntities[ index ][ 0 ], customEntities[ index ][ 1 ] );\n    // Index within the document.\n    api.index = () => ( index );\n    return api;\n  }; // itemCustomEntity()\n\n  // ### colSelectedCustomEntities\n  /**\n   *\n   * Makes collection of entities identified by the `selectedEntities` array.\n   *\n   * @param  {array} selectedCustomEntities The array of selected entities, using which\n   *                                        the collection is made.\n   * @return {object}                       containing applicable API methods.\n   * @private\n   */\n  colSelectedCustomEntities = function ( selectedCustomEntities ) {\n    var api = Object.create( null );\n    // Iterator.\n    api.each = ( f ) => selEach( f, selectedCustomEntities, itemCustomEntity );\n    // Map.\n    api.map = ( f ) => selMap( f, selectedCustomEntities, itemCustomEntity );\n    // Filter.\n    api.filter = ( f ) => selFilter( f, selectedCustomEntities, itemCustomEntity, colSelectedCustomEntities );\n    // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n    api.itemAt = ( k ) => selGetItemAt( k, selectedCustomEntities, itemCustomEntity );\n    // Number of selected entities.\n    api.length = () => ( selectedCustomEntities.length );\n    // Output this collectionn of selected of entities as a reduced value\n    // using map/reduce functions  `f/g`.\n    api.out = ( f, g ) => selEntitiesOut( selectedCustomEntities, customEntities, docData, f, g );\n    return api;\n  }; // colSelectedCustomEntities()\n\n  // ### colCustomEntities\n  /**\n   *\n   * Makes collection of all the entities.\n   *\n   * @return {object} containing applicable API methods.\n   * @private\n   */\n  colCustomEntities = function () {\n    var api = Object.create( null );\n    // Iterator.\n    api.each = ( f ) => colEach( f, 0, customEntities.length - 1, itemCustomEntity );\n    // Map.\n    api.map = ( f ) => colMap( f, 0, customEntities.length - 1, itemCustomEntity );\n    // Filter.\n    api.filter = ( f ) => colFilter( f, 0, customEntities.length - 1, itemCustomEntity, colSelectedCustomEntities );\n    // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n    api.itemAt = ( k ) => colGetItemAt( k, 0, ( customEntities.length - 1 ), itemCustomEntity );\n    // Length of this collection.\n    api.length = () => ( customEntities.length );\n    // Output this collection of entities as a reduced value\n    // using map/reduce functions  `f/g`.\n    api.out = ( f, g ) => colEntitiesOut( customEntities, docData, f, g );\n    return api;\n  }; // colCustomEntities()\n\n  // <hr/>\n\n  // ## Sentence\n  // **Item, Collection, and Selection APIs.**\n\n  // ### itemSentence\n  /**\n   *\n   * Makes item of the sentence specified by `index` of the sentence.\n   *\n   * @param  {number} index The index of the sentence.\n   * @return {object}       containing applicable API methods.\n   * @private\n   */\n  itemSentence = function ( index ) {\n    var api = Object.create( null );\n    // Access the parent document.\n    api.parentDocument = () => methods;\n    // Markup this sentence.\n    api.markup = ( beginMarker, endMarker ) => markings.push( [ sentences[ index ][ 0 ], sentences[ index ][ 1 ], beginMarker, endMarker ] );\n    // Output this sentence as text.\n    api.out = ( f ) => itmSentenceOut( index, docData, f, addons );\n    // Outputs the collection of entities, if any, contained in this sentence.\n    api.entities = () => colSelectedEntities( containedEntities( entities, sentences[ index ][ 0 ], sentences[ index ][ 1 ] ) );\n    // Outputs the collection of custom entities, if any, contained in this sentence.\n    api.customEntities = () => colSelectedCustomEntities( containedEntities( customEntities, sentences[ index ][ 0 ], sentences[ index ][ 1 ] ) );\n    // Outputs the collection of tokens in this sentence.\n    api.tokens = colTokens( sentences[ index ][ 0 ], sentences[ index ][ 1 ] );\n    // Index within the document.\n    api.index = () => ( index );\n    return api;\n  }; // itemSentence()\n\n  // ### colSentences\n  /**\n   *\n   * Makes collection of sentences in this document.\n   *\n   * @return {object} containing applicable API methods.\n   * @private\n   */\n  colSentences = function () {\n    var api = Object.create( null );\n    // Iterator.\n    api.each = ( f ) => colEach( f, 0, sentences.length - 1, itemSentence );\n    // Map.\n    api.map = ( f ) => colMap( f, 0, sentences.length - 1, itemSentence );\n    // Item at `k`th index. If `k` is outside valid range, return `undefined` like JS.\n    api.itemAt = ( k ) => colGetItemAt( k, 0, ( sentences.length - 1 ), itemSentence );\n    // Length of this collection.\n    api.length = () => ( sentences.length );\n    // Output this collection of sentences as an array of strings.\n    api.out = ( f ) => colSentencesOut( docData, f, addons );\n    return api;\n  }; // colSentences()\n\n  // <hr/>\n\n  // ### contextualVectors\n  /**\n   *\n   * Makes a JSON of contextually relevant words in the winkNLP format.\n   *\n   * @return {string} containing the JSON.\n  */\n  // eslint-disable-next-line complexity\n  contextualVectors = function ( { lemma = true, specificWordVectors = [], similarWordVectors = false, wordVectorsLimit = 0 } = {} ) {\n    // Error handling!\n    if ( docData.wordVectors === null )\n      throw Error( 'wink-nlp: word vectors are not loaded: load them winkNLP\\'s instantiation time.' );\n    if ( !Array.isArray( specificWordVectors ) )\n      throw Error( `wink-nlp: expecting a valid Javascript array for similarWordVectos, instead found \"${typeof specificWordVectors}\".`);\n    if ( !Number.isInteger( wordVectorsLimit ) || wordVectorsLimit >= docData.wordVectors.size )\n      throw Error( 'wink-nlp: invalid value or type encountered for wordVectorsLimit.' );\n    if ( lemma && !docData.currPipe.pos )\n      throw Error( 'wink-nlp: Can\\'t create lemma vectors without pos: add a \"pos\" to NLP pipe.' );\n    // Initialize contextual vectors.\n    const cv = Object.create( null );\n    // Following properties are constants, therefore can be directly copied.\n    cv.precision = docData.wordVectors.precision;\n    cv.l2NormIndex = docData.wordVectors.l2NormIndex;\n    cv.wordIndex = docData.wordVectors.wordIndex;\n    cv.dimensions = docData.wordVectors.dimensions;\n    cv.unkVector = docData.wordVectors.unkVector.slice( 0 );\n    // Following properties will be determined on the basis of the context.\n    cv.size = 0;\n    cv.words = [];\n    cv.vectors = Object.create( null );\n    // Shortcut all word vectors.\n    const awvs = docData.wordVectors.vectors;\n\n    // Extract all document's tokens.\n    const docTokens = colTokens( 0, docData.numOfTokens - 1 )()\n                      .out()\n                      .map( ( t ) => t.toLowerCase() );\n    let docTokensLemma = [];\n    if ( lemma ) docTokensLemma = colTokens( 0, docData.numOfTokens - 1 )()\n                                           .out( its.lemma )\n                                           .map( ( t ) => t.toLowerCase() );\n\n    // NOTE: For UNK words an all zero vector is set up, with `l2Norm = 0`, which may be used in as.vector helper\n    // to detect an UNK word.\n    for ( let i = 0; i < docTokens.length; i += 1 ) cv.vectors[ docTokens[ i ] ] = ( awvs[ docTokens[ i ] ] || cv.unkVector ).slice( 0 );\n    for ( let i = 0; i < docTokensLemma.length; i += 1 ) cv.vectors[ docTokensLemma[ i ] ] = ( awvs[ docTokensLemma[ i ] ] || cv.unkVector ).slice( 0 );\n    for ( let i = 0; i < specificWordVectors.length; i += 1 ) {\n      const spWord = ( specificWordVectors[ i ] ) ? specificWordVectors[ i ].toString().trim() : false;\n      if ( spWord )\n        cv.vectors[ specificWordVectors[ i ] ] = ( awvs[ specificWordVectors[ i ] ] || cv.unkVector ).slice( 0 );\n    }\n\n    if ( similarWordVectors ) {\n      // Extract similar words on the basis of shortest Manhattan distance.\n      const allUniqueTokens = Object.keys( cv.vectors );\n      // Set up similar words array, with the size of all unique tokens.\n      const similarWords = new Array( allUniqueTokens.length );\n      // Placeholder for maintaining the similarity score based on Manhattan distance.\n      const similarWordsScore = new Array( allUniqueTokens.length );\n      // Initialize to a large distance!\n      similarWordsScore.fill( 1000000 );\n\n      // Initialize contextual vectors size i.e. vocab.\n      cv.size = allUniqueTokens.length;\n\n      // Now search each one of them in the entire word vectors space.\n      // Keep updating the smallest distance.\n      for ( let i = 0; i < allUniqueTokens.length; i += 1 ) {\n        const cwv = cv.vectors[ allUniqueTokens[ i ] ];\n\n        for ( const word in awvs ) { // eslint-disable-line guard-for-in\n          if ( word === allUniqueTokens[ i ] ) continue; // eslint-disable-line no-continue\n          const wv = awvs[ word ];\n          let distance = 0;\n\n          for ( let k = 0; k < cv.dimensions && distance < similarWordsScore[ i ]; k += 1 ) {\n            distance += Math.abs( cwv[ k ] - wv[ k ] );\n          } // Mahattan distance computation loop.\n\n          if ( distance < similarWordsScore[ i ] ) {\n            similarWordsScore[ i ] = distance;\n            similarWords[ i ] = word;\n          }\n        } // Traversing all the word vectors.\n      } // Traversing all the tokens in the corpus.\n\n      // Update contextual vectors using the list of similar words; also update their size.\n      for ( let i = 0; i < similarWords.length; i += 1 ) {\n        if ( cv.vectors[ similarWords[ i ] ] === undefined ) {\n          // Similar word must exist in `awvs`.\n          cv.vectors[ similarWords[ i ] ] = awvs[ similarWords[ i ] ].slice( 0 );\n          cv.size += 1;\n        }\n      }\n\n    } else cv.size = Object.keys( cv.vectors ).length;\n\n    // Fill the balance space, if any, on the basis of wordVectorsLimit.\n    for ( let i = 0; cv.size < wordVectorsLimit; i += 1 ) {\n      const word = docData.wordVectors.words[ i ];\n      if ( !cv.vectors[ word ] ) {\n        cv.vectors[ word ] = awvs[ word ].slice( 0 );\n        cv.size += 1;\n      }\n    }\n\n    // Sort words on the basis of their usage frequency.\n    cv.words = Object.keys( cv.vectors )\n                        .map( ( w ) => ( { w: w, i: (cv.vectors[ w ][ cv.wordIndex ] < 0 ) ? Infinity : cv.vectors[ w ][ cv.wordIndex ] } ) )\n                        .sort( (a, b) => a.i - b.i )\n                        .map( ( o ) => o.w );\n\n    // Update the word index entry inside every vector.\n    for ( let i = 0; i < cv.size; i += 1 ) cv.vectors[ cv.words[ i ] ][ cv.wordIndex ] = i;\n\n    return JSON.stringify( cv );\n  }; // contextualVectors()\n\n  // Published chainable methods.\n  methods.entities = colEntities;\n  methods.customEntities = colCustomEntities;\n  methods.isLexeme = isLexeme;\n  methods.isOOV = cache.isOOV;\n  methods.out = ( f ) => itmDocumentOut( docData, f, addons );\n  methods.sentences = colSentences;\n  methods.tokens = colTokens( 0, docData.numOfTokens - 1 );\n\n  methods.printTokens = () => printTokens( tokens, cache );\n\n  // Enusre that we make a deep copy of config before returning to avoid corruption!\n  methods.pipeConfig = () => JSON.parse( JSON.stringify( docData.currPipe ) );\n\n  methods.contextualVectors = contextualVectors;\n\n  return methods;\n};\n\nmodule.exports = doc;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar constants = require( './constants.js' );\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// Mask for extracting pos\nvar posMask = constants.posMask;\n\nvar mappers = Object.create( null );\n\n// ## mapRawTokens2UIDn\n/**\n * Maps the raw tokens to an array of uid of normal of tokens.\n * @private\n *\n * @param {object} rdd The raw document data-structure.\n * @returns {array} conatining the uid of normals.\n * @private\n*/\nvar mapRawTokens2UIdOfNormal = function ( rdd ) {\n  // Extract tokens & cache.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Will contain only the hash of normal of tokenized lexemes.\n  var mappedTokens = new Array( rdd.numOfTokens );\n  var i, k;\n  for ( i = 0; i < tokens.length; i += tkSize ) {\n    k = i + 1;\n    mappedTokens[ i / tkSize ] = ( tokens[ k ] > 65535 ) ?\n                              // Handle contraction's expansion.\n                              cache.nox( tokens[ k ] ) :\n                              // Handle all other words.\n                              cache.normal( tokens[ i ] );\n  } // for ( i = 0; i < tokens.length...\n\n  return mappedTokens;\n}; // mapRawTokens2UIdOfNormal()\n\n// ## mapRawTokens2UIDn\n/**\n * Maps the raw tokens to an array of uid of value of tokens.\n * @private\n *\n * @param {object} rdd The raw document data-structure.\n * @returns {array} conatining the uid of values.\n * @private\n*/\nvar mapRawTokens2UIdOfValue = function ( rdd ) {\n  // Extract tokens.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Will contain only the hash of value of tokenized lexemes.\n  var mappedTokens = new Array( rdd.numOfTokens );\n  var i;\n  for ( i = 0; i < tokens.length; i += tkSize ) {\n    // Use mapped spelling  this ensure correct pos tagging & lemmatization etc.\n    // as mapped spelling is the gold spelling.\n    mappedTokens[ i / tkSize ] = cache.mappedSpelling( tokens[ i ] );\n  } // for ( i = 0; i < tokens.length...\n  return mappedTokens;\n}; // mapRawTokens2UIdOfValue()\n\n// ## mapRawTokens2UIdOfPOS\n/**\n * Extracts the default or most likely pos tag for every token.\n * @private\n *\n * @param {object} rdd the raw document data.\n * @returns {array} conatining the default pos tags.\n * @private\n*/\nvar mapRawTokens2UIdOfDefaultPOS = function ( rdd ) {\n  // Extract tokens & cache.\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  var posTags = new Array( rdd.numOfTokens );\n  let pk = 0;\n  for ( let i = 0; i < tokens.length; i += tkSize, pk += 1 ) {\n    posTags[ pk ] = ( tokens[ ( i ) + 2 ] === 0 ) ?\n                      // Make UNK to NOUN to handle the remote possibility of ML POS being undefined!\n                      // Also use mapped spelling  this ensure correct pos tagging & lemmatization etc.\n                      // as mapped spelling is the gold spelling.\n                      ( cache.posOf( cache.mappedSpelling( tokens[ i ] ) ) || 8 ) :\n                      ( ( tokens[ ( i ) + 2 ] & posMask ) >>> bits4lemma ); // eslint-disable-line no-bitwise\n  }\n  return posTags;\n}; // mapRawTokens2UIdOfDefaultPOS()\n\nmappers.mapRawTokens2UIdOfNormal = mapRawTokens2UIdOfNormal;\nmappers.mapRawTokens2UIdOfValue = mapRawTokens2UIdOfValue;\nmappers.mapRawTokens2UIdOfDefaultPOS = mapRawTokens2UIdOfDefaultPOS;\n\nmodule.exports = mappers;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-sync */\n\n\nvar makeRegexes = function ( config ) {\n  var rgx = [];\n  var imax = config.length;\n  var i;\n\n  for ( i = 0; i < imax; i += 1 ) {\n    rgx.push( [ ( new RegExp( config[ i ][ 0 ], config[ i ][ 1 ] ) ), config[ i ][ 2 ] ] );\n  }\n  return rgx;\n}; // makeRegexes()\n\nvar compileTRex =  function ( trex ) {\n  var rtc;\n  var ltc;\n  var helpers = Object.create( null );\n\n  try {\n    rtc = makeRegexes( trex.rtc );\n\n    ltc = makeRegexes( trex.ltc );\n\n    // Helper regexes.\n    for ( const h in trex.helpers ) { // eslint-disable-line guard-for-in\n      helpers[ h ] = new RegExp( trex.helpers[ h ][ 0 ], trex.helpers[ h ][ 1 ] );\n    }\n\n    // file = path.join( __dirname, 'languages', language, 'normalization-map.json' );\n    // nmap = JSON.parse( fs.readFileSync( file, 'utf8' ) );\n  } catch ( ex ) {\n    throw Error( 'wink-nlp: Invalid trex.\\n\\nDetails:\\n' + ex.message );\n  }\n  return  { rtc: rtc, ltc: ltc, helpers: helpers };\n}; // readLangConfig()\n\nmodule.exports = compileTRex;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-underscore-dangle */\n\nvar constants = require( './constants.js' );\n\n// Bits reserved for `precedingSpaces`.\nvar bits4PrecedingSpace = constants.bits4PrecedingSpace;\n// Size of a single expansion.\nvar xpSize = constants.xpSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// The UNK!\nvar UNK = constants.UNK;\n// Size of a single token.\nvar tkSize = constants.tkSize;\n\nvar docDataWrapper = function ( data ) {\n  // Extract frequently referred data elements:\n  // Extract `cache`.\n  var cache = data.cache;\n  // Extract `tokens`.\n  var tokens = data.tokens;\n\n  // Returned!\n  var methods = Object.create( null );\n\n  // ## addToken\n  /**\n   *\n   * It first creates a new lexeme entry into the `cache` and then this entry\n   * is pushed into the `tokens` array alongwith the `precedingSpaces` and\n   * rest of the token properties are initialized to `0`.\n   *\n   * @param {string} text to be added as token.\n   * @param {string} category of the token.\n   * @param {number} precedingSpaces to the `text` as parsed by tokenizer.\n   * @param {array} nbsp, containing details of nbsp.\n   * @returns {boolean} always `true`.\n   * @private\n  */\n  var addToken = function ( text, category, precedingSpaces, nbsp ) {\n    // Non-normalized index of the token being pushed.\n    var idx;\n    idx = tokens.push( cache.add( text, category ), precedingSpaces, 0, 0 );\n    // See comments in `addTokenIfInCache()`\n    if ( nbsp !== null && precedingSpaces > 0 ) data.nonBreakingSpaces[ ( idx / tkSize ) - 1 ] = nbsp;\n    return true;\n  }; // addToken()\n\n  // ## addTokenIfInCache\n  /**\n   *\n   * Adds a token corresponding to the input `text` if it is found in cache i.e.\n   * not an OOV. The addition process ensures the following:\n   * 1. Preceding spaces are added.\n   * 2. If text is a contraction, it expansions are added. Since expansins\n   * consists of lexeme, normal, lemma and pos, all of these are added to the\n   * token structure.\n   *\n   * @param {string} text to be added as token.\n   * @param {number} precedingSpaces to the `text` as parsed by tokenizer.\n   * @param {string} nbsp non breaking spaces\n   * @returns {boolean} `truthy` if `text` is found in cache otherwise `falsy`.\n   * @private\n  */\n  var addTokenIfInCache = function ( text, precedingSpaces, nbsp ) {\n    // The array `tokenIndex` will contain 1-element if `text` is not a predefined\n    // contraction; otherwise it will contain `n x 4` elements, where `n` is the\n    // number of expansions.\n    var tokenIndex = cache.lookup( text );\n    // Temp for preceding space in case of contarction.\n    var ps;\n    // Temp for lemma & pos.\n    var lemma, pos;\n    // Non-normalized index of the token being pushed.\n    var idx;\n\n    // `UNK` means 0 or `falsy`; it flags that token has not been added.\n    if ( tokenIndex === null ) return UNK;\n\n    if ( tokenIndex.length === 1 ) {\n      idx = tokens.push( tokenIndex[ 0 ], precedingSpaces, 0, 0 );\n      // Store non breaking spaces preceding this token. Do it only if `precedingSpaces > 0` (Note:\n      // it is zero in case of expansion of a contraction) AND `nbsp` is defined (Note: in this case\n      // precedingSpaces would be set to max i.e. 0xFFFF with only exception when the token is being\n      // expanded: the first one will have nbsp but the subsequent ones with have 0 preceding spaces).\n      // The storage index should be the normalaized token index.\n      if ( nbsp !== null && precedingSpaces > 0 ) data.nonBreakingSpaces[ ( idx / tkSize ) - 1 ] = nbsp;\n    } else {\n      // Contraction, itereate through each expansion.\n      for ( let k = 0; k < tokenIndex.length; k += xpSize ) {\n        // The `precedingSpaces` will be 0 except for the first expansion.\n        ps = ( k === 0 ) ? precedingSpaces : 0;\n        // Concatenate pointer to normal contained in `xpansions` with preceding\n        // spaces.\n        ps |= ( tokenIndex[ k + 1 ] << bits4PrecedingSpace ); // eslint-disable-line no-bitwise\n        // Lemma & POS are fixed mostly for all contractions.\n        lemma = tokenIndex[ k + 2 ];\n        pos   = tokenIndex[ k + 3 ];\n        // Add token; annotations may be filled later in the pipeline.\n        idx = tokens.push( tokenIndex[ k ], ps, ( lemma | ( pos << bits4lemma ) ), 0 ); // eslint-disable-line no-bitwise\n        // See comment above in the then block of this if-statement.\n        if ( nbsp !== null && precedingSpaces > 0 ) data.nonBreakingSpaces[ ( idx / tkSize ) - 1 ] = nbsp;\n      }\n    }\n    // Return `truthy`, indicating that token(s) has been added successfully.\n    return 99;\n  }; // addTokenIfInCache()\n\n  // ## isLexeme\n  /**\n   *\n   * Tests if the `text` is a valid lexeme or not.\n   *\n   * @param {string} text to be added as token.\n   * @returns {boolean} `truthy` if `text` is a valid lexeme otherwise `falsy`.\n   * @private\n  */\n  var isLexeme = function ( text ) {\n    // Return `truthy` if the text is valid i.e. found. Note for `$%^OOV^%$`, it returns\n    // `0` i.e. `falsy`!\n    return cache.lookup( text );\n  }; // isLexeme()\n\n  var clean = function () {\n    tokens = null;\n    cache = null;\n  }; // clean()\n\n  methods._addToken = addToken;\n  methods._addTokenIfInCache = addTokenIfInCache;\n  methods.isLexeme = isLexeme;\n  methods.clean = clean;\n\n  return methods;\n}; // docDataWrapper()\n\nmodule.exports = docDataWrapper;\n","/**\n * Map selected items.\n * @param  {function} f         Call back function that is called on each item.\n * @param  {number[]} selection Array containing indexes to the selected items.\n * @param  {function} itemFn    Item function to create chainable-methods of the item.\n * @return {Array}              Array of mapped items.\n * @private\n */\nvar selMap = function ( f, selection, itemFn ) {\n  return selection.map( ( item, i ) => f( itemFn( item ), i ) );\n}; // selMap()\n\nmodule.exports = selMap;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( './its.js' );\nvar as = require( './as.js' );\nvar allowed = Object.create( null );\n\nallowed.its4token = new Set( [\n  its.case,\n  its.uniqueId,\n  its.negationFlag,\n  its.normal,\n  its.contractionFlag,\n  its.pos,\n  its.precedingSpaces,\n  its.prefix,\n  its.shape,\n  its.stopWordFlag,\n  its.abbrevFlag,\n  its.suffix,\n  its.type,\n  its.value,\n  its.stem,\n  its.lemma\n] );\n\nallowed.its4tokens = allowed.its4token;\n\nallowed.its4selTokens = allowed.its4token;\n\nallowed.as4tokens = new Set( [\n  as.array,\n  as.set,\n  as.text,\n  as.bow,\n  as.freqTable,\n  as.bigrams,\n  as.unique,\n  as.markedUpText,\n  as.vector\n] );\n\n// NOTE: it should exclude `as.markedUpText`, whenever this is included in the above.\nallowed.as4selTokens = new Set( [\n  as.array,\n  as.set,\n  as.text,\n  as.bow,\n  as.freqTable,\n  as.bigrams,\n  as.unique,\n  as.vector\n] );\n\nallowed.its4entity = new Set( [\n  its.value,\n  its.normal,\n  its.type,\n  its.detail,\n  its.span\n] );\n\nallowed.as4entities = new Set( [\n  as.array,\n  as.set,\n  as.bow,\n  as.freqTable,\n  as.unique\n] );\n\nallowed.as4selEntities = allowed.as4entities;\n\nallowed.its4sentence = new Set( [\n  its.value,\n  its.normal,\n  its.span,\n  its.markedUpText,\n  its.negationFlag,\n  its.sentiment,\n  its.stem\n] );\n\nallowed.its4document = new Set( [\n  its.value,\n  its.normal,\n  its.span,\n  its.markedUpText,\n  its.negationFlag,\n  its.sentiment,\n  its.stem,\n  its.readabilityStats,\n  its.sentenceWiseImportance\n] );\n\n\nmodule.exports = allowed;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## identifyMarkedArea\n/**\n *\n * Identifies the area to be marked within the detected entitity's span, which is\n * extracted as the value.\n *\n * @param {number[]} mark contains the target area to be extracted from within\n *                        the entitity's span, defined as `[ firstIndex, lastIndex ]`.\n * @param {number} length of the entity's span.\n * @return {number[]}     array containing the modifiers for the orginal span.\n * @private\n*/\nconst identifyMarkedArea = function ( mark, length ) {\n  // Length Minus 1.\n  const lm1 = length - 1;\n  let [ firstIndex, lastIndex ] = mark;\n\n  if ( firstIndex < 0 ) firstIndex += length;\n  firstIndex = Math.max( firstIndex, 0 );\n  if ( firstIndex > lm1 ) firstIndex = 0;\n\n  if ( lastIndex < 0 ) lastIndex += length;\n  lastIndex = Math.min( lastIndex, lm1 );\n  if ( lastIndex < firstIndex ) lastIndex = lm1;\n\n  // The `lastIndex` manoeuvre is required to keep identical approach\n  // being followed in `learnSinglePattern()` of automaton.js, where\n  // the `firstIndex` **was** being added and the `lastIndex` **was** being\n  // subtracted from the span of entity.\n  lastIndex = length - lastIndex - 1;\n  return [ firstIndex, lastIndex ];\n}; // identifyMarkedArea()\n\nmodule.exports = identifyMarkedArea;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar itmSentenceOut = require( './itm-sentence-out.js' );\n\n// ## colSentencesOut\n/**\n * Out for collection of sentences. Note: the out always returns a Javascript\n * data type or data structure.\n * @param  {object}   rdd          Raw Document Data-structure.\n * @param  {function} itsf         Desired `its` mapper.\n * @param  {object}   addons       The model's addons.\n * @return {*}                     Mapped sentences.\n * @private\n */\nvar colSentencesOut = function ( rdd, itsf, addons ) {\n  var sents = [];\n  for ( let i = 0; i < rdd.sentences.length; i += 1 ) {\n    sents.push( itmSentenceOut( i, rdd, itsf, addons ) );\n  }\n  return sents;\n}; // colSentencesOut()\n\nmodule.exports = colSentencesOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## colEach\n/**\n * Iterator for collections.\n * @param  {function} f      Call back function that is called on each item.\n * @param  {number}   start  The start index in the collection.\n * @param  {number}   end    The end index.\n * @param  {function} itemFn Item function to create chainable-methods of the item.\n * @return {void}            Nothing!\n * @private\n */\nvar colEach = function ( f, start, end, itemFn ) {\n  for ( let k = start; k <= end; k += 1 ) {\n    // Use relative indexing by adding `start` from `k`.\n    f( itemFn( k ), ( k - start ) );\n  }\n}; // colEach()\n\nmodule.exports = colEach;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n/* eslint-disable no-console */\n/* eslint-disable guard-for-in */\nconst composePatterns = require( './compose-patterns.js' );\nconst identifyMarkedArea = require( './identify-marked-area.js' );\n\nconst eosTokenN = 2070000;\nconst eosTokenX = '$%^EoS^%$';\nconst otherwiseN = 2070003;\nconst otherwiseX = ' otherwise';\n\nvar simpleFSM = function ( cache, token2Ignore ) {\n  // Returned!\n  var methods = Object.create( null );\n  // Holds FSM in the following structure:<br/>\n  // curr state > event > next state <br/>\n  // One of the event is `otherwise`, whose next state defines the default state.\n  var fsm = Object.create( null );\n  // The root or the beginning state of the `fsm`.\n  const root = 0;\n  // Tracks the last used state. Whenever a new state is needed, its value is\n  // incremented and returned. See `getNextState()`.\n  var lastUsedState =  0;\n  // The terminal states i.e. the detected patterns: maps state to name.\n  var terminalStates = Object.create( null );\n  // The terminal states, where part of pattern has been marked out.\n  var markedStates = Object.create( null );\n  // Add-ons value is stored here.\n  var customPropertyAtStates = Object.create( null );\n  // Use to substitute tokens by patterns in a multi-pass scenario.\n  var substitutions;\n  // On pattern detection function.\n  var onPatternDetectionFn;\n  // By default always ignore the new line character, else use the value supplied\n  // by `token2Ignore`; this will usually be the OOV lexeme, i.e. `$%^oov^%$`.\n  const toBeIgnoredToken =  ( token2Ignore === undefined ) ? '\\n' : token2Ignore;\n  // The `cache` is `undefined`, when things have to work on token text  for\n  // learning & recognition both. For native case of learning (i.e. generation),\n  // it can be `null` or real value; and native mode recognition will always\n  // need real value of the `cache`.\n  // Setup `keyLF/eosToken` to use during entity detection on the basis of `cache`\n  // value  It is critical for model generation.\n  const keyLF = ( cache === undefined || cache === null ) ? toBeIgnoredToken : cache.lookup( toBeIgnoredToken )[ 0 ];\n  const eosToken = ( cache === undefined || cache === null ) ? eosTokenX : eosTokenN;\n  // The `otherwise` event; including a space to ensure that such an input can\n  // never arrive from the token stream. Later on it will be changed to numeric\n  // value > `0xFFFFF` i.e. the limit of vocabulary.\n  const otherwise = ( cache === undefined ) ? otherwiseX : otherwiseN;\n\n  // ## getNextState\n  /**\n   *\n   * Returns the next state to be assigned i.e. the next unused state or\n   * a state corresponding to target, if defined.\n   *\n   * @param {number} index of current token.\n   * @param {number} last index of last token.\n   * @param {number} target state of the pattern being processed; could be\n   * `undefined` if it is being encountered for the first time.\n   * @returns {number} next state that should be assigned for the current event.\n   * @private\n  */\n  var getNextState = function ( index, last, target ) {\n    // Check its invocation in the of fsm.\n    if ( index === last && target ) return target;\n    // Compute next unused state & return. Note this now becomes the last\n    // used state!\n    lastUsedState += 1;\n    return lastUsedState;\n  }; // getNextState()\n\n  // ## learnSinglePattern\n  /**\n   *\n   * Learns a single pattern.\n   *\n   * @param {string} name of the pattern to be learned.\n   * @param {array} pattern to be learned.\n   * @param {array} mark `[ start, end ]`.\n   * @param {any} customProperty contains definable value(s).\n   * @returns {undefined} Nothing!\n   * @private\n  */\n  var learnSinglePattern = function ( name, pattern, mark, customProperty ) {\n    const length = pattern.length;\n    // Last element.\n    const last = length - 1;\n    // Target state for this pattern, would be `undefined` if this pattern type is\n    // enountered for the first time (`undefined` disables collapse of states).\n    const target = undefined;\n    // Tracks the `state` as the FSM builds up, specially useful if there are\n    // machines with shared path i.e. common `(state, events)` pairs.\n    let state = root;\n    // Assigned for `otherwise` events.\n    let goBackTo = root;\n    // Temp for event & next state.\n    let ev, nextState;\n\n    // Iterate through the pattern's tokens, while discovering any existing\n    // machine that can share path.\n    for ( let k = 0; k < length; k += 1 ) {\n      ev = pattern[ k ];\n      // Create new state & intialize, if required.\n      if ( fsm[ state ] === undefined ) {\n        fsm[ state ] = Object.create( null );\n        fsm[ state ][ otherwise ] = goBackTo;\n      }\n      // Check for machines that may share path.\n      if ( fsm[ state ][ ev ] === undefined ) {\n        // None found, create new state transition by assigning the next state for\n        // the current event  `ev`.\n        nextState = getNextState( k, last, target );\n        fsm[ state ][ ev ] = nextState;\n        // Always compute state transition from the perspective of discovering\n        // shared path: here the `fsm[ state ][ ev ]` has been just assigned\n        // `nextState`, therefore `state` needs to transition to this state only.\n        state = nextState;\n      } else if ( terminalStates[ fsm[ state ][ ev ] ] ) {\n          // Case when shared path is found and the next state on the path is a\n          // terminal state.\n          if ( fsm[ state ][ otherwise ] === root ) fsm[ state ][ otherwise ] = goBackTo;\n          goBackTo = fsm[ state ][ ev ];\n          nextState = getNextState( k, last, target );\n          fsm[ state ][ ev ] = nextState;\n          // Compute state transition; again like earlier case, it would be `nextState`.\n          state = nextState;\n        } else if ( k === last ) {\n            // Case when shared path is found and the next state on the path is NOT\n            // a terminal state AND current token is the LAST one.\n            nextState = getNextState( k, last, target );\n            fsm[ fsm[ state ][ ev ] ][ otherwise ] = nextState;\n            state = nextState;\n          } else {\n            // Case when shared path is found and the next state on the path is NOT\n            // a terminal state AND current token is NOT the LAST one.<br/>\n            // Simply compute state transition, no other work to be done!\n            state = fsm[ state ][ ev ];\n          }\n    }\n    terminalStates[ state ] = name;\n\n    if ( mark ) {\n      // Update last element of `mark` to simplifies computations during fsm\n      // execution. Update must happen as a deep copy & not directly!\n      markedStates[ state ] = identifyMarkedArea( mark, length );\n    }\n\n    if ( customProperty !== undefined ) {\n      customPropertyAtStates[ state ] = customProperty;\n    }\n  }; // learnSinglePattern()\n\n  // ## learn\n  /**\n   *\n   * Learns the patterns that must be detected via recognize() API calls.\n   *\n   * @param {Object[]} patterns to be learned.\n   *\n   * @param {string} patterns[].name of the pattern.\n   * @param {string} patterns[].structure of the pattern.\n   * @returns {number} of uniquely named patterns.\n   * `[ pattern-id, start-token, end-token ]` format.\n   * @private\n  */\n  var learn = function ( patterns ) {\n    // Temp for counting unique.\n    var obj = Object.create( null );\n    // Composed Patterns\n    var cp = [];\n    for ( let i = 0; i < patterns.length; i += 1 ) {\n      const pi = patterns[ i ];\n      if ( typeof pi.pattern === 'string' ) {\n        const all = composePatterns( pi.pattern );\n        for ( let j = 0; j < all.length; j += 1 )\n          cp.push( { name: pi.name, pattern: all[ j ], mark: pi.mark, customProperty: pi.customProperty } );\n      } else cp.push( { name: pi.name, pattern: pi.pattern, mark: pi.mark, customProperty: pi.customProperty } );\n    }\n    // Sort to get the longest pattern on the top.\n    cp.sort( ( a, b ) => ( b.pattern.length - a.pattern.length ) );\n    // All set, now learn using composed patterns  `cp`!\n    for ( let i = 0; i < cp.length; i += 1 ) {\n      learnSinglePattern( cp[ i ].name, cp[ i ].pattern, cp[ i ].mark, cp[ i ].customProperty );\n    }\n    // Return number of uniquely named patterns.\n    for ( const ts in terminalStates ) obj[ terminalStates[ ts ] ] = true;\n    return ( ( Object.keys( obj ) ).length );\n  }; // learn()\n\n  // ## setOnPatternDetectionFn\n  /**\n   *\n   * Defines the function that is called on every detected pattern, provided\n   * the detected pattern had an `customProperty` property defined.\n   * @param {function} f to be called with `match` & `customProperty` value as parameters.\n   * @returns {boolean} `true` if it was a success otherwise `false`.\n   * @private\n  */\n  var setOnPatternDetectionFn = function ( f ) {\n    if ( typeof f === 'function' ) {\n      onPatternDetectionFn = f;\n      return true;\n    }\n    return false;\n  }; // setOnPatternDetectionFn()\n\n  // ## pushMatch2Patterns\n  /**\n   *\n   * Pushes a `match`ed pattern details into the `patterns` array after handling\n   * marking and calling the on pattern detection function, if required. Before\n   * pushing a `match` to patterns, the state (numeric) at `match[ 2 ]` is mapped\n   * to its name using `terminalStates`; remember the `state` passed here is\n   * always the terminal state. Passing state in match ensures that respective\n   * `mark` and `customProperty` are handled differently if they have different values in\n   * a state-machine rows, even though the `names` are identical.\n   *\n   * @param {array} patterns where the `match` is pushed.\n   * @param {array} match pushed in to the `patterns`. The `match` conntains\n   * 3-entries viz. 0state, 1 & 2start & end indexes of `tokens`.\n   * @returns {undefined} Nothing.\n   * @private\n  */\n  var pushMatch2Patterns = function ( patterns, match ) {\n    // Extract the state at match[ 0 ].\n    var m0 = match[ 2 ];\n    // Pattern name `'0'`  simply ignore it!\n    if ( terminalStates[ m0 ] === '0' ) return;\n    // Not to be ignored  process it.\n    var mark = markedStates[ m0 ];\n    var customProperty = customPropertyAtStates[ m0 ];\n    if ( mark ) {\n      match[ 0 ] += mark[ 0 ];\n      match[ 1 ] -= mark[ 1 ];\n    }\n\n    // Removed `customProperty !== undefined &&` check while coding pos experiment\n    if ( onPatternDetectionFn )\n      onPatternDetectionFn( match, customProperty );\n\n    match[ 2 ] = terminalStates[ m0 ];\n\n    patterns.push( match );\n  }; // pushPattern()\n\n  // ## setPatternSwap\n  /**\n   *\n   * Sets up the patterns to be used for token substitution/swap in the\n   * `recognize()` api.\n   *\n   * @param {array[]} patterns to be used for substitutions in `recognize()`.\n   * @returns {undefined} Nothing.\n   * @private\n  */\n  var setPatternSwap = function ( patterns ) {\n    if ( !patterns || !Array.isArray( patterns ) ) {\n      substitutions = undefined;\n      return;\n    }\n    // Old `substitutions` are re-initialized.\n    substitutions = Object.create( null );\n    // Sort patterns by the start of pattern index.\n    patterns.sort( ( a, b ) => ( a[ 0 ] > b[ 0 ] ) );\n    // Index it by start of pattern.\n    patterns.forEach( ( e ) => ( substitutions[ e[ 0 ] ] = [ e[ 1 ], e[ 2 ] ] ) );\n  }; // setPatternSwap()\n\n  // ## recognize\n  /**\n   *\n   * Recognizes patterns present in the input tokens in a greedy manner.\n   *\n   * @param {array} tokens in which the patterns need to be recognized.\n   * @param {function} [transformToken] an optional function that is called before\n   * processing every token.\n   * @param {*} [param] that has to be passed as the last param to `transformToken()`\n   * function.\n   * @returns {array[]} where each element follows\n   * `[ pattern-id, start-token, end-token ]` format.\n   * @private\n  */\n  var recognize = function ( tokens, transformToken, param ) {\n    // Length of the `tokens.`\n    const length = tokens.length;\n    // Check if `transformToken` is a valid function.\n    var transformTokenFn = ( typeof transformToken === 'function' ) ? transformToken : null;\n    // Detected patterns are captured here. Each element has the following format: <br/>\n    // `[ pattern-id, start-token, end-token ]`\n    var patterns = [];\n    // We don't need a separate state machines unlike `recognize()`, as the\n    // following set of variables together act like a singleton machine.\n    var first = 0;\n    var state = root;\n    // Next State.\n    var ns = root;\n    // Temp. for a single pattern.\n    var p = null;\n    // Last non-root otherwise state & index\n    var lastOtherwiseIndex;\n    var lastOtherwiseState;\n    // Temp. for a token.\n    var t;\n    // Used to increment `j` and computing span of pattern correctly, may become\n    // > 1 if an earlier detected pattern is longer that 1-token.\n    var delta = 1;\n\n    for ( let i = 0; i <= length; i += 1 ) {\n      // **Attempt greedy lookup**:<br/>\n      // Keep digging until next state becomes `root` or a terminal state is\n      // encountered. Upon failure after a partial match, roll back is required\n      // so that the extra consumed tokens can be explored by machine.\n      for ( let j = i; j <= length; j += delta ) {\n        // Extract current token.\n        t = ( j === length ) ?  eosToken : tokens[ j ];\n\n        // Skip the newline character; TODO: will replace by the hash value!\n        // Use direct hash for the time being later, it must be obtained via cache\n        if ( t === keyLF ) continue; // eslint-disable-line no-continue\n\n        // Perform replacements using earlier detected patterns.\n        if ( substitutions && substitutions[ j ] ) {\n          t = substitutions[ j ][ 1 ];\n          delta = substitutions[ j ][ 0 ] - j + 1;\n        } else delta = 1;\n\n        // Apply token transformation function, if defined. Must not be called\n        // for the `eosToken`.\n        if ( transformTokenFn && ( j < length ) ) t = transformTokenFn( t, cache, param, j );\n\n        // Find next state on the basis of current `state` and current token  `t`.\n        ns = fsm[ state ][ t ] || root;\n        // Detect the state transition to capture `first` token of a potential upcoming\n        // pattern. If state is `root` and the next state is `non-root` indicates\n        // that we have just starting chasing for a new pattern.\n        if ( !state && ns ) first = j;\n\n        if ( terminalStates[ ns ] ) {\n          // Terminal state encountered, save this pattern. Update span using `delta`.\n          p = [ first, j + delta - 1, ns ];\n          pushMatch2Patterns( patterns, p );\n          // Set index to `j`, so that iterations can commence from `j + 1` as\n          // for-loop increments the index variable at the end of loop!\n          i = j;\n          // Ensures that the inner loop terminates!\n          j = length + 100;\n          // Pattern has been discovered, so next state must be set to `root`.\n          ns = root;\n          // Same is true for the last saved otherwise state.\n          lastOtherwiseState = root;\n        } else if ( ns === root ) {\n          // Not a terminal state but the next state has hit the `root`.\n          if ( lastOtherwiseState ) {\n            // But we have a `non-root` last saved otherwise state; this means\n            // we must save this pattern.\n            p = [ first, lastOtherwiseIndex, lastOtherwiseState ];\n            pushMatch2Patterns( patterns, p );\n            // Set index to the index corresponding to the above last saved otherwise\n            // state.\n            i = lastOtherwiseIndex;\n            // Ensure that the inner loop terminates;\n            j = length + 100;\n            // Pattern has been discovered, so next state must be set to `root`.\n            ns = root;\n            // Same is true for the last saved otherwise state.\n            lastOtherwiseState = root;\n          } else {\n            // The last saved otherwise state is pointing to `root`: terminate\n            // the inner loop without updating the index variable  this ensures\n            // complete roll back.\n            j = length + 100;\n          }\n        }\n        // Update the current state.\n        state = ns;\n        // Save (last) non-root otherwise state & index, if any.\n        if ( fsm[ state ][ otherwise ] ) {\n          // Update span using `delta`.\n          lastOtherwiseIndex = j + delta - 1;\n          lastOtherwiseState = fsm[ state ][ otherwise ];\n        }\n      }\n    }\n\n    return patterns;\n  }; // recognize()\n\n  // ## exportJSON\n  /**\n   * Exports the learning as a JSON, which may be saved as a text file for\n   * later use via `importJSON()`.\n   *\n   * @return {string} Learning in JSON format.\n   * @private\n  */\n  var exportJSON = function () {\n    return JSON.stringify(\n      [ 100, lastUsedState, fsm, terminalStates, markedStates, customPropertyAtStates ]\n    );\n  }; // exportJSON()\n\n  // ## emptyModelJSON\n  /**\n   * Exports the an empty model's JSON. Useful in model generation.\n   *\n   * @return {string} Learning in JSON format.\n   * @private\n  */\n  var emptyModelJSON = function () {\n    // Empty machine!\n    const m0 = Object.create( null );\n    m0[ 0 ] = Object.create( null );\n    return JSON.stringify(\n      [ 100,\n        0,                      // `lastUsedState`.\n        m0,                     // `fsm`,\n        Object.create( null ),  // `terminalStates`,\n        Object.create( null ),  // `markedStates`,\n        Object.create( null ),  // `customPropertyAtStates`\n      ]\n    );\n  }; // emptyModelJSON()\n\n  // ## importJSON\n  /**\n   * Imports an existing JSON learning for recognition.\n   *\n   * @param {JSON} json containing learnings in as exported by `exportJSON()`.\n   * @return {void} Nothing!\n   * @throws Error if `json` is invalid.\n   * @private\n  */\n  var importJSON = function ( json ) {\n    var model =  JSON.parse( json );\n    lastUsedState = model[ 1 ];\n    fsm = model[ 2 ];\n    terminalStates = model[ 3 ];\n    markedStates = model[ 4 ];\n    customPropertyAtStates = model[ 5 ];\n  }; // importJSON()\n\n  // Prints the model in terms of the state machine & terminal states.\n  var printModel = function () {\n    console.log( 'State Machine:' );\n    console.log( JSON.stringify( fsm, null, 2 ) );\n    console.log();\n    console.log( 'Terminal States:' );\n    console.log( JSON.stringify( terminalStates, null, 2 ) );\n    console.log();\n    console.log( 'Marked States:' );\n    console.log( JSON.stringify( markedStates, null, 2 ) );\n    console.log();\n    console.log( 'customProperty States:' );\n    console.log( JSON.stringify( customPropertyAtStates, null, 2 ) );\n  }; // printModel()\n\n\n  methods.learn = learn;\n  methods.recognize = recognize;\n  methods.setPatternSwap = setPatternSwap;\n  methods.setOnPatternDetectionFn = setOnPatternDetectionFn;\n  methods.exportJSON = exportJSON;\n  methods.importJSON = importJSON;\n  methods.emptyModelJSON = emptyModelJSON;\n\n  methods.printModel = printModel;\n\n  // This a dummy statement to ensure 100% coverage; because feature of\n  // collapsing shared states into single one was **disabled** due to `mark`.\n  getNextState( 0, 0, 99 );\n  return methods;\n}; // fsm()\n\nmodule.exports = simpleFSM;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar itmEntityOut = require( './itm-entity-out.js' );\n\n// ## selEntitiesOut\n/**\n * Out for selection of entities. Note: the out always returns a Javascript\n * data type or data structure. Word vectors do not apply to entities.\n * @param  {number[]} selEntities Array containing indexes to the selected entities.\n * @param  {obejct}   entities    Entities from `rdd`; could be customEntities.\n * @param  {obejct}   rdd         Raw document data structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @param  {function} asf         Desired `as` reducer.\n * @return {*}                    Reduced value.\n * @private\n */\nvar selEntitiesOut = function ( selEntities, entities, rdd, itsf, asf ) {\n  var ents = [];\n  for ( let i = 0; i < selEntities.length; i += 1 ) {\n    ents.push( itmEntityOut( selEntities[ i ], entities, rdd, itsf ) );\n  }\n  // No application of allowed function if detail or span is needed, fall back to `as.array`.\n  var asfn = ( allowed.as4selEntities.has( asf ) && itsf !== its.detail && itsf !== its.span ) ? asf : as.array;\n  return asfn( ents );\n}; // selEntitiesOut()\n\nmodule.exports = selEntitiesOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## colGetItemAt\n/**\n * Obtains an item at the specified index from a collection.\n * @param  {number}   k      Relative index of the required item.\n * @param  {number}   start  The start index of collection.\n * @param  {number}   end    The end index of the collection.\n * @param  {function} itemFn Item function to create chainable-methods of the item.\n * @return {object}          Object containing the applicable chainable-methods\n *                           for the item found at `k`; otherwise `undefined`.\n * @private\n */\nvar colGetItemAt = function ( k, start, end, itemFn ) {\n  // To handle relative indexing, compute actual `k` by adding `start`.\n  var ak = k + start;\n  if ( ak < start || ak > end ) {\n    throw Error( `wink-nlp: ${k} is an invalid or out of bounds index.`);\n  } else return itemFn( ak );\n}; // colGetItemAt()\n\nmodule.exports = colGetItemAt;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar DocDataWrapper = require( './dd-wrapper.js' );\nvar Automata = require( './automaton.js' );\nvar mappers = require( './tokens-mappers.js' );\nvar mapRawTokens2UIdOfValue = mappers.mapRawTokens2UIdOfValue;\nvar mapRawTokens2UIdOfNormal = mappers.mapRawTokens2UIdOfNormal;\n\nvar cerAutomata = Automata(); // eslint-disable-line new-cap\n\nvar rgxOr = /^\\[((?:[^| ]+\\|)+?|(?:\\|[^| ]+)+?|(?:[^| ]+\\|[^| ]+)+?|(?:[^| ]+))\\]$/;\nvar rgxPipe = /\\|/g;\n\n// ## mergeSplitsAndMatches\n/**\n * Helper function to merge the two input array elements by picking elements\n * alternatively from each array.\n * @param  {string[]} splts obtained by splitting on pipe.\n * @param  {string[]} mtchs obtained by matching on pipe.\n * @return {string[]}       the merged array.\n * @private\n */\nvar mergeSplitsAndMatches = function ( splts, mtchs ) {\n  const [ s0, ...splits ] = splts;\n  return ( ( s0 === undefined ) ? mtchs : [ s0, ...mergeSplitsAndMatches( mtchs, splits ) ] );\n}; // mergeSplitsAndMatches()\n\n// # compiler\n/**\n * It transforms the input patterns for custom entity recognition into a model,\n * which is run by winkNLP's `readDoc()` method. The model is created by\n * the `learnCustomEntities()` method of core winkNLP using this compiler. Brefore\n * the compiler can be **run**, its instance must be created using the following\n * parameters:\n *\n * @param  {JSON}     cerModel    precompiled custom entity meta model  handles escaping\n *                                of entity literals. For example `^ADJ` will match\n *                                with token `ADJ` (or `adj` based on `matchValue` in\n *                                `cerConfig`), whereas `ADJ` will match with the\n *                                adjective part-of-speech of a token.\n * @param  {object}   cache       of lexicon, which is required to deliver performance.\n * @param  {function} tokenize    is instantiated from core tokenizer, which tokenises the\n *                                input patterns. It is used in the `tokenizeText()` private\n *                                method of compiler.\n * @param  {boolean}  matchValue  match value flag  defines match on either `value` or\n *                                `normal` of tokens.<br/>\n * @return {object}               contains **run** function, which can compile the input\n *                                pattern into a model.\n * @private\n */\nvar compiler = function ( cerModel, cache, tokenize, matchValue ) {\n  // Returned!\n  var methods = Object.create( null );\n  // Map of literals to be preserved.\n  var preserve;\n\n  cerAutomata.importJSON( cerModel );\n  // On pattern detection, we need to save the custom property  `preserve`\n  // created by the `cerModel's` execution.\n  cerAutomata.setOnPatternDetectionFn( ( match, customProperty ) => ( match.push( customProperty ) ) );\n\n  // ## hasOrPattern\n  /**\n   * Test the presence of or-pattern in the tokens and returns the index of the\n   * same.\n   * @param  {string[]} tokens of each word, split on spaces.\n   * @return {number}          the index where token is found otherwise -1.\n   * @private\n   */\n  var hasOrPattern = function ( tokens ) {\n    // Use findIndex with regex to locate.\n    return ( tokens.findIndex( ( e ) => rgxOr.test( e ) ) !== -1 );\n  }; // hasOrPattern()\n\n  // ## encloseInSquareBracket\n  /**\n   * Heper function to enclose incoming text element within square brackets.\n   * @param  {string} e input text element.\n   * @return {string}   enclosed text element.\n   * @private\n   */\n  var encloseInSquareBracket = function ( e ) {\n    // Enclose!\n    return '[' + e +  ']';\n  }; // encloseInSquareBracket()\n\n  // ## tokenizeText\n  /**\n   * Tokenizes the incoming text using wink-nlp's tokenizer.\n   * @param  {string} text   input text string.\n   * @return {object[]}      where each object contains normal & value of the token.\n   * @private\n   */\n  var tokenizeText = function ( text ) {\n    // Mimic wink-nlp like manoeuvre!\n    var rdd = Object.create( null );\n    rdd.cache = cache;\n    rdd.tokens = [];\n    var wrappedDocData = DocDataWrapper( rdd );  // eslint-disable-line new-cap\n\n    tokenize( wrappedDocData, text ); // eslint-disable-line new-cap\n    const tokens = [];\n    const values = mapRawTokens2UIdOfValue( rdd ).map( ( t ) => cache.value( t ) );\n    const normals = mapRawTokens2UIdOfNormal( rdd ).map( ( t ) => cache.value( t ) );\n    for ( let i = 0; i < values.length; i += 1 ) tokens.push( { value: values[ i ], normal: normals[ i ] } );\n    return tokens;\n  }; // tokenizeText()\n\n  // ## compileSimplePattern\n  /**\n   * Compiles a simple pattern.\n   *\n   * @param  {string} text    input simple pattern string.\n   * @return {string[]}       of compiled pattern.\n   * @private\n   */\n  var compileSimplePattern = function ( text ) {\n    // Compiled pattern build here.\n    const cp = [];\n    // Tokenized `text`.\n    const tokens = tokenizeText( text );\n    // Spans of recognized patterns from tokens' value because patterns are always\n    // in UPPER case.\n    const spans = cerAutomata.recognize( tokens.map( ( t ) => t.value ) );\n    // The spans are mapped into `replacements` and are indexed by `spans[ i ][ 0 ]`.\n    // `e[ 0 ]` & e[ 1 ] are start & end indexes, `e[ 2 ]` is entity name, and\n    // `e[ 3 ]` is customProperty, where true mean preserve replacement.\n    const replacements = Object.create( null );\n    spans.forEach( ( e ) => ( replacements[ e[ 0 ] ] = [ e[ 1 ], e[ 2 ], e[ 3 ] ] ) );\n    // Perform replacements.\n    for ( let i = 0; i < tokens.length; i += 1 ) {\n      // Replacement defined for this index  `i`? **Yes** means it could be a property\n      // or esacped property or a lone escape character or an esacped escape character. **No**\n      // means a literal.\n      if ( replacements[ i ] ) {\n        // **Empty** entity name indicates a lone escape character.\n        if ( replacements[ i ][ 1 ] !==  '' ) {\n          // Preserve? **Yes** means it is an escaped property or escape char;\n          // **No** means property.\n          if ( replacements[ i ][ 2 ].preserve ) {\n            // Since it has to be preserved, `matchValue` drives both the `cp` &\n            // `preserve` contents i.e. **normal** or **value**\n\n            // This contains escaped `<property>`.\n            const tri0 = ( matchValue ) ? tokens[ replacements[ i ][ 0 ] ].value : tokens[ replacements[ i ][ 0 ] ].normal;\n            // This conntains `<property>&`.\n            const ri1 = ( matchValue ) ? replacements[ i ][ 1 ] : replacements[ i ][ 1 ].toLowerCase();\n            // Map escaped `<property>` to `<property>&`.\n            preserve[ tri0 ] = ri1;\n            cp.push( ri1 );\n          } else {\n            // It is a **property**, therefore it has to go to the state machine\n            // **as-is**.\n            cp.push( replacements[ i ][ 1 ] );\n          }\n        }\n        // Skip by moving `i` to the end index.\n        i = replacements[ i ][ 0 ];\n      } else {\n        // **Literal**: Extract token's normal or value based on `matchValue` flag.\n        const ti = ( matchValue ) ? tokens[ i ].value : tokens[ i ].normal;\n        cp.push( ti );\n        preserve[ ti ] = ti;\n      }\n    }\n    // Return compiled pattern.\n    return cp;\n  }; // compileSimplePattern()\n\n  // ## compileOrPattern\n  /**\n   * Compiles the tokens containing \"or\" patterns.\n   * @param  {string[]} tokens  contains the incoming tokens.\n   * @return {string}           compiled text string.\n   * @private\n   */\n  var compileOrPattern = function ( tokens ) {\n    const pattern = [];\n    for ( let i = 0; i < tokens.length; i += 1 ) {\n      if ( rgxOr.test( tokens[ i ] ) ) {\n        // Strip the opening/closing square brackets.\n        const ti = tokens[ i ].substring( 1, tokens[ i ].length - 1 );\n        // Find matches with `rgxPipe`; if they are null set to an empty array.\n        const matches = ti.match( rgxPipe ) || [];\n        // Find splits on `rgxPipe`.\n        const splits = ti.split( rgxPipe );\n        // Iterate through `splits` to check that each element cannot be tokenized\n        // further.\n        for ( let j = 0; j < splits.length; j += 1 ) {\n          const st = ( splits[ j ] === '' ) ? [ '' ] : compileSimplePattern( splits[ j ] );\n          if ( st.length > 1 ) {\n           throw Error( `wink-nlp: incorrect token \"${st.join( '' )}\" encountered in examples of learnCustomEntities() API.` );\n          }\n          splits[ j ] = st[ 0 ];\n        } // splits iterations\n        // Merge matches & splits to create the pattern.\n        pattern.push( encloseInSquareBracket( mergeSplitsAndMatches( splits, matches ).join( '' ) ) );\n      } else {\n        // Simple part of text, just enclose it in square brackets after replacement (if any).\n        compileSimplePattern( tokens[ i ] ).forEach( ( t ) => pattern.push( encloseInSquareBracket( t ) ) );\n      }\n    }\n    return pattern.join( ' ' );\n  }; // compileOrPattern()\n\n  // ## compileSinglePattern\n  /**\n   * Compiles a single pattern text. It invokes compilation of \"or\" or \"simple\"\n   * pattern based on input text type.\n   *\n   * @param  {string} text      input pattern text.\n   * @return {(array|string)}   depending onn type of pattern.\n   * @private\n   */\n  var compileSinglePattern = function ( text ) {\n    // Split on spaces.\n    const atoms = text.trim().split( /\\s+/ );\n    // Invoke required compilation based on the type of `atoms` i.e. the text.\n    if ( hasOrPattern( atoms ) ) {\n      return compileOrPattern( atoms );\n    }\n    return compileSimplePattern( text );\n  }; // compileSinglePattern()\n\n  // ## run\n  /**\n   * Runs the compiler to compile the examples. It calls `compileSinglePattern()`\n   * on each example iteratively.\n   *\n   * @param  {object[]} examples containing objects, where each object defines an\n   *                             entity in terms of name and pattern.\n   * @return {object}            compiled examples ready for automata and literals\n   *                             preserve.\n   * @private\n   */\n  var run = function ( examples ) {\n    // Compiled examples are captured here.\n    const ces = [];\n    // Intialize preserve every time a new compilation happens.\n    preserve = Object.create( null );\n    for ( let i = 0; i < examples.length; i += 1 ) {\n      const example = examples[ i ];\n      const patterns = example.patterns;\n      for ( let j = 0; j < patterns.length; j += 1 ) {\n        const cp = compileSinglePattern( patterns[ j ] );\n        const ce = Object.create( null );\n        ce.name = example.name;\n        ce.pattern = cp;\n        if ( example.mark ) ce.mark = example.mark;\n        ces.push( ce );\n      }\n    }\n\n    return { examples: ces, preserve: preserve };\n  }; // run()\n\n  methods.run = run;\n\n  return methods;\n}; // compiler()\n\nmodule.exports = compiler;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar itmEntityOut = require( './itm-entity-out.js' );\n\n// ## colEntitiesOut\n/**\n * Out for collection of entities. Note: the out always returns a Javascript\n * data type or data structure. Word vectors do not apply to entities.\n * @param  {obejct}   entities entities from `rdd`; could be customEntities.\n * @param  {obejct}   rdd      Raw document data structure.\n * @param  {function} itsf     Desired `its` mapper.\n * @param  {function} asf      Desired `as` reducer.\n * @return {*}                 Reduced value.\n * @private\n */\nvar colEntitiesOut = function ( entities, rdd, itsf, asf ) {\n  var ents = [];\n  for ( let i = 0; i < entities.length; i += 1 ) {\n    ents.push( itmEntityOut( i, entities, rdd, itsf ) );\n  }\n  // No application of allowed function if detail or span is needed, fall back to `as.array`.\n  var asfn = ( allowed.as4entities.has( asf ) && itsf !== its.detail && itsf !== its.span ) ? asf : as.array;\n  return asfn( ents );\n}; // colEntitiesOut()\n\nmodule.exports = colEntitiesOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar search = require( '../search.js' );\n\n// ## getParentItem\n/**\n * Obtains the parent of the required item from a parent collection of spans.\n * @param  {number}   currItemIndex    Index of the item whose parent is needed.\n * @param  {array[]}  parentCollection Parent collection of spans.\n * @param  {function} parentItemFn     Required to instantiate the found parent item.\n * @return {object}                    Object containing the applicable chainable-methods\n *                                     of parent item, if found; otherwise `undefined`.\n * @private\n */\nvar getParentItem = function ( currItemIndex, parentCollection, parentItemFn ) {\n  var k = search( currItemIndex, parentCollection );\n  if ( k === null ) return undefined;\n  return parentItemFn( k );\n}; // getParentItem()\n\nmodule.exports = getParentItem;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar locate = require( './locate.js' );\n\n// ## containedMarkings\n/**\n *\n * Returns the range of contained markings, if any within the span defined by the\n * `start` and the `end`.\n *\n * @param {array} markings from where contained ones will be returned, if any.\n * @param {number} start The start of the span.\n * @param {number} end The end of the span.\n * @return {array} range of contained markings, `null` if none are contained.\n * @private\n*/\nvar containedMarkings = function ( markings, start, end ) {\n  if ( markings === undefined || start === undefined || end === undefined ) {\n    return null;\n  }\n\n  // Left & right indexes into the `markings` array.\n  var left = locate( start, markings );\n  var right = locate( end, markings );\n  var maxIndex = markings.length - 1;\n  var kl, kr;\n\n  // Return just the text if span is completely on the left or right side of the\n  // `markings`.\n  if ( ( left < 0 && right < 0 ) || ( left > maxIndex && right > maxIndex ) ) {\n    return null;\n  }\n\n  // The `left` must move to the next integer value to get the first index.\n  // To avoid `-0`!\n  kl = ( left < 0 ) ? 0 : Math.ceil( left );\n\n  // If both `left` and `right` are fractions & equal means nothing is contained.\n  // Return just the text, no markups!\n  if ( ( left === right ) && ( kl !== left ) ) {\n    return null;\n  }\n\n  kr = Math.floor( right );\n  // Mark those markings, which are completely contained in the closed interval\n  // `[ start, end ]` i.e. no partially contained markings.\n  if ( markings[ kl ][ 0 ] < start ) kl += 1;\n  if ( markings[ kr ][ 1 ] > end )   kr -= 1;\n  if ( kl > kr ) {\n    return null;\n  }\n\n  var range = Object.create( null );\n  range.left = kl;\n  range.right = kr;\n\n  return range;\n}; // containedMarkings\n\nmodule.exports = containedMarkings;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar sort4FT = require( './sort4FT.js' );\nvar constants = require( './constants.js' );\nvar caseMap = [ 'other', 'lowerCase', 'upperCase', 'titleCase' ];\nvar swi = require( './sentence-wise-importance.js' );\nvar reconstructSpaces = require( './reconstruct-spaces.js' );\n\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Bits reserved for `lemma`.\nvar bits4lemma = constants.bits4lemma;\n// Mask for extracting pos\nvar posMask = constants.posMask;\n// Mask for lemma in case of contraction.\nvar lemmaMask = constants.lemmaMask;\n\nvar its = Object.create( null );\n\nits.case = function ( index, rdd ) {\n  return caseMap[ rdd.cache.property( rdd.tokens[ index * tkSize ], 'lutCase' ) ];\n}; // case()\n\nits.uniqueId = function ( index, rdd ) {\n  return rdd.tokens[ index * tkSize ];\n}; // uniqueId()\n\nits.negationFlag = function ( index, rdd ) {\n  return rdd.tokens[ ( index * tkSize ) + 3 ] >= constants.negationFlag;\n}; // negationFlag()\n\nits.normal = function ( index, rdd ) {\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  return (\n    ( tokens[ ( index * tkSize ) + 1 ] > 65535 ) ?\n      cache.value( cache.nox( tokens[ ( index * tkSize ) + 1 ] ) ) :\n      cache.value( cache.normal( tokens[ index * tkSize ] ) )\n  );\n}; // normal()\n\nits.contractionFlag = function ( index, rdd ) {\n  return ( rdd.tokens[ ( index * tkSize ) + 1 ] > 65535 );\n}; // contractionFlag()\n\nits.pos = function ( index, rdd ) {\n  return rdd.cache.valueOf( 'pos', ( rdd.tokens[ ( index * tkSize ) + 2 ] & posMask ) >>> bits4lemma );  // eslint-disable-line no-bitwise\n}; // pos()\n\nits.precedingSpaces = function ( index, rdd ) {\n  return reconstructSpaces( index, rdd );\n}; // precedingSpaces()\n\nits.prefix = function ( index, rdd ) {\n  return rdd.cache.property( rdd.tokens[ index * tkSize ], 'prefix' );\n}; // prefix()\n\nits.shape = function ( index, rdd ) {\n  return rdd.cache.property( rdd.tokens[ index * tkSize ], 'shape' );\n}; // shape()\n\nits.stopWordFlag = function ( index, rdd ) {\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // Apply check on normalized token and not the original value, because\n  // stop words are always defined in the lowercase.\n  var normal = ( tokens[ ( index * tkSize ) + 1 ] > 65535 ) ?\n    cache.nox( tokens[ ( index * tkSize ) + 1 ] ) :\n    cache.normal( tokens[ index * tkSize ] );\n  return ( cache.property( normal, 'isStopWord' ) === 1 );\n}; // stopWordFlag()\n\nits.abbrevFlag = function ( index, rdd ) {\n  return ( rdd.cache.property( rdd.tokens[ index * tkSize ], 'isAbbrev' ) === 1 );\n}; // abbrevFlag()\n\nits.suffix = function ( index, rdd ) {\n  return rdd.cache.property( rdd.tokens[ index * tkSize ], 'suffix' );\n}; // suffix()\n\nits.type = function ( index, rdd ) {\n  return rdd.cache.property( rdd.tokens[ index * tkSize ], 'tokenType' );\n}; // type()\n\nits.value = function ( index, rdd ) {\n  return rdd.cache.value( rdd.tokens[ index * tkSize ] );\n}; // value()\n\nits.stem = function ( index, rdd, addons ) {\n  return addons.stem( rdd.cache.value( rdd.tokens[ index * tkSize ] ) );\n}; // stem()\n\nits.lemma = function ( index, rdd, addons ) {\n  var tokens = rdd.tokens;\n  var cache = rdd.cache;\n  // If it is a contraction that lemma is already available in the token's data structure.\n  if ( tokens[ ( index * tkSize ) + 1 ] > 65535 ) {\n    return cache.value( tokens[ ( index * tkSize ) + 2 ] & lemmaMask ); // eslint-disable-line no-bitwise\n  }\n  // Handle mapped spelling if any.\n  const mappedIdx = cache.mappedSpelling( tokens[ index * tkSize ] );\n  // If the token has single lemma then no further processing is needed.\n  if ( cache.property( mappedIdx, 'isSLemma' ) === 1 ) {\n    return cache.value( cache.property( mappedIdx, 'lemma' ) );\n  }\n  // Exhausted all possibilities to avoid processing! Now lemmatize!\n  const pos = its.pos( index, rdd );\n  const value = cache.value( cache.normal( tokens[ index * tkSize ] ) );\n  return addons.lemmatize( value, pos, cache );\n}; // lemmas()\n\nits.vector = function ( ) {\n  return ( new Array( 100 ).fill( 0 ) );\n}; // vector()\n\nits.detail = function ( ) {\n  return true;\n}; // detail()\n\nits.markedUpText = function ( index, rdd ) {\n  // This is a special case because `tokens.out()` allows `as.markedUpText`.\n  // Therefore simply return the value and rest is handled by `colTokensOut` with\n  // `as.markedUpText()`` or `as.text()` as one of the arugments.\n  return its.value( index, rdd );\n}; // markedUpText()\n\nits.span = function ( spanItem ) {\n  return spanItem.slice( 0, 2 );\n}; // span()\n\nits.sentiment = function ( spanItem ) {\n  return spanItem[ 3 ];\n}; // span()\n\nits.readabilityStats = function ( rdd, addons ) {\n  return addons.readabilityStats( rdd, its );\n}; // readabilityStats()\n\nits.sentenceWiseImportance = function ( rdd ) {\n  return swi( rdd );\n}; // sentenceWiseImportance()\n\n/* ------ utilities ------ */\n\nits.terms = function ( tf, idf, terms ) {\n  return terms;\n}; // terms()\n\nits.docTermMatrix = function ( tf, idf, terms ) {\n  const dtm = new Array( tf.length );\n  for ( let id = 0; id < tf.length; id += 1 ) {\n    dtm[ id ] = [];\n    for ( let i = 0; i < terms.length; i += 1 ) {\n      dtm[ id ].push( tf[ id ][ terms[ i ] ] || 0 );\n    }\n  }\n  return dtm;\n}; // getDocTermMatrix()\n\nits.docBOWArray = function ( tf ) {\n  return tf;\n}; // docBOWArray()\n\nits.bow = function ( tf ) {\n  return tf;\n}; // bow()\n\nits.idf = function ( tf, idf ) {\n  var arr = [];\n  for ( const t in idf ) { // eslint-disable-line guard-for-in\n    arr.push( [ t, idf[ t ] ] );\n  }\n  // Sort on frequency followed by the term.\n  return arr.sort( sort4FT );\n}; // idf()\n\nits.tf = function ( tf ) {\n  const arr = [];\n  for ( const t in tf ) {  // eslint-disable-line guard-for-in\n    arr.push( [ t, tf[ t ] ] );\n  }\n  // Sort on frequency followed by the term.\n  return arr.sort( sort4FT );\n}; // tf()\n\nits.modelJSON = function ( tf, idf, terms, docId, sumOfAllDLs ) {\n  return JSON.stringify( {\n      uid: 'WinkNLP-BM25Vectorizer-Model/1.0.0',\n      tf: tf,\n      idf: idf,\n      terms: terms,\n      docId: docId,\n      sumOfAllDLs: sumOfAllDLs\n   } );\n}; // model()\n\nmodule.exports = its;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n// ## selFilter\n/**\n * Filter for selection.\n * @param  {function} f             Predicate function to test each item of\n *                                  the array. Return true to select the item,\n *                                  false to reject or exclude.\n * @param  {number[]} selection     Array containing indexes to the selected items.\n * @param  {function} itemFn        Item function to create chainable-methods of the item.\n * @param  {function} colSelectedFn The function to create chainable-methods for\n *                                  the collection of selection, which are returned.\n * @return {object}                 Object containing the applicable chainable-methods.\n * @private\n */\nvar selFilter = function ( f, selection, itemFn, colSelectedFn ) {\n  var filtered = [];\n  for ( let k = 0; k < selection.length; k += 1 ) {\n    if ( f( itemFn( selection[ k ] ), k ) ) filtered.push( selection[ k ] );\n  }\n  return colSelectedFn( filtered );\n}; // selFilter()\n\nmodule.exports = selFilter;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar reconstructSpaces = require( '../reconstruct-spaces.js' );\nvar constants = require( '../constants.js' );\n// Size of a single token.\nvar tkSize = constants.tkSize;\n// Mask for preceding spaces.\nvar psMask = constants.psMask;\n\n// ## selTokensOut\n/**\n * Out for selection of tokens. Note: the out always returns a Javascript\n * data type or data structure.\n * @param  {number[]} selTokens   Array containing indexes to the selected tokens.\n * @param  {obejct}   rdd         Raw document data structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @param  {function} asf         Desired `as` reducer.\n * @param  {object}   addons      The addons from the model.\n * @return {*}                    Reduced value.\n * @private\n */\nvar selTokensOut = function ( selTokens, rdd, itsf, asf, addons ) {\n  // Not a vector request, perform map-reduce.\n  var mappedTkns = [];\n  var itsfn = ( itsf && allowed.its4selTokens.has( itsf ) ) ? itsf : its.value;\n  var asfn = ( asf && allowed.as4selTokens.has( asf ) ) ? asf : as.array;\n\n  if ( itsfn !== its.value && itsfn !== its.normal && itsfn !== its.lemma && asfn === as.vector ) {\n    throw Error( 'winkNLP: as.vector is allowed only with its value or normal or lemma.' );\n  }\n\n  // Note, `as.text` needs special attention to include preceeding spaces.\n  // No `markedUpText` allowed here.\n  if ( asfn === as.text ) {\n    for ( let i = 0; i < selTokens.length; i += 1 ) {\n      mappedTkns.push( reconstructSpaces( selTokens[ i ], rdd ), itsf( selTokens[ i ], rdd, addons ) );\n    }\n  } else {\n    for ( let i = 0; i < selTokens.length; i += 1 ) {\n      mappedTkns.push( itsfn( selTokens[ i ], rdd, addons ) );\n    }\n  }\n\n  return asfn( mappedTkns, rdd );\n}; // selTokensOut()\n\nmodule.exports = selTokensOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar its = require( '../its.js' );\nvar as = require( '../as.js' );\nvar allowed = require( '../allowed.js' );\nvar colTokensOut = require( './col-tokens-out.js' );\n\n// ## itmDocumentOut\n/**\n * Out method for the document. Note: the out always returns a Javascript\n * data type or data structure.\n * @param  {Object}   rdd         Raw Document Data-structure.\n * @param  {function} itsf        Desired `its` mapper.\n * @param  {Object}   addons      The model's addons.\n * @return {*}                    Mapped value.\n * @private\n */\nvar itmDocumentOut = function ( rdd, itsf, addons ) {\n  var document = rdd.document;\n\n  var itsfn = ( itsf && allowed.its4document.has( itsf ) ) ? itsf : its.value;\n\n  if ( itsfn === its.span || itsfn === its.sentiment ) {\n    return itsfn( document );\n  }\n\n  // Handle its.negationFlag seprately here.\n  if ( itsfn === its.negationFlag ) {\n    return ( document[ 2 ] === 1 );\n  }\n\n  if ( itsfn === its.readabilityStats ) {\n    return itsfn( rdd, addons );\n  }\n\n  if ( itsfn === its.sentenceWiseImportance ) {\n    return itsfn( rdd );\n  }\n\n  // Setup the correct `as.fn` becuase the current markedup text would have\n  // returned the `value`. Refer to `its.markedUpText`.\n  var asfn = ( itsfn === its.markedUpText ) ? as.markedUpText : as.text;\n\n  return colTokensOut( document[ 0 ], document[ 1 ], rdd, itsfn, asfn, addons );\n}; // itmDocumentOut()\n\nmodule.exports = itmDocumentOut;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\n// ## search\n/**\n *\n * Searches the `token`'s index in the `spans` and returns the index of the\n * span, where it is found.\n *\n * @param {number} token to be searched.\n * @param {array[]} spans where token will be searched.\n * @return {number} index of span where token is found; if it is not found then\n * it returns `null`.\n * @private\n*/\nvar search = function ( token, spans ) {\n  var minIndex = 0;\n  var maxIndex = spans.length - 1;\n  var currIndex;\n  var leftToken;\n  var rightToken;\n\n  while ( minIndex <= maxIndex ) {\n    currIndex = ( minIndex + maxIndex ) / 2 | 0; // eslint-disable-line no-bitwise\n    leftToken = spans[ currIndex ][ 0 ];\n    rightToken = spans[ currIndex ][ 1 ];\n\n    if ( token > rightToken ) {\n      minIndex = currIndex + 1;\n    } else if ( token < leftToken ) {\n      maxIndex = currIndex - 1;\n    } else return currIndex;\n  }\n\n  return null;\n}; // search()\n\nmodule.exports = search;\n","//     wink-nlp\n//\n//     Copyright (C) GRAYPE Systems Private Limited\n//\n//     This file is part of wink-nlp.\n//\n//     Permission is hereby granted, free of charge, to any\n//     person obtaining a copy of this software and\n//     associated documentation files (the \"Software\"), to\n//     deal in the Software without restriction, including\n//     without limitation the rights to use, copy, modify,\n//     merge, publish, distribute, sublicense, and/or sell\n//     copies of the Software, and to permit persons to\n//     whom the Software is furnished to do so, subject to\n//     the following conditions:\n//\n//     The above copyright notice and this permission notice\n//     shall be included in all copies or substantial\n//     portions of the Software.\n//\n//     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF\n//     ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n//     TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\n//     PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n//     THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n//     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\n//     CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n//     CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n//     DEALINGS IN THE SOFTWARE.\n\n//\n\nvar locate = require( './locate.js' );\n\n// ## containedEntities\n/**\n *\n * Returns the contained entities, if any within the span defined by the\n * `sentenceStart` and the `sentenceEnd`.\n *\n * @param {array} entities from where contained ones will be returned, if any.\n * @param {number} sentenceStart start of the sentence.\n * @param {number} sentenceEnd end of the sentence.\n * @return {array} of contained entities, empty if none are contained.\n * @private\n*/\nvar containedEntities = function ( entities, sentenceStart, sentenceEnd ) {\n  var left = locate( sentenceStart, entities );\n  var right = locate( sentenceEnd, entities );\n  var maxIndex = entities.length - 1;\n  // Contained entities.\n  var contained = [];\n  // Index left & right.\n  var kl, kr;\n  // Helper.\n  var i;\n\n  // Return empty array if span is completely on the left or right side of the\n  // `entities`.\n  if ( ( left < 0 && right < 0 ) || ( left > maxIndex && right > maxIndex ) ) {\n    return contained;\n  }\n\n  // The `left` must move to the next integer value to get the first index.\n  // To avoid `-0`!\n  kl = ( left < 0 ) ? 0 : Math.ceil( left );\n\n  // If both `left` and `right` are fractions & equal means nothing is contained.\n  if ( ( left === right ) && ( kl !== left ) ) {\n    return contained;\n  }\n\n  // Something is conatined for sure, capture it and return!\n  kr = Math.floor( right );\n  for ( i = kl; i <= kr; i += 1 ) {\n    contained.push( i );\n  }\n\n  return contained;\n}; // containedEntities()\n\nmodule.exports = containedEntities;\n"],"names":["its","require","as","allowed","colTokensOut","module","exports","index","entities","rdd","itsf","detail","entity","itsfn","its4entity","has","value","Object","create","text","type","span","constants","tkSize","psMask","count","tokens","padEnd","nonBreakingSpaces","bits4lemma","posMask","openClassPOS","ADJ","ADV","INTJ","NOUN","PROPN","VERB","NUM","SYM","sentences","cache","posGroupWeightTable","s","length","pos","start","end","t","p","valueOf","push","k","pos4Gram","slice","initInfoContent","reduce","pv","cv","posGroup","join","group","weight","undefined","iv","posGroupWeights","keys","map","e","filter","sentenceWiseWeights","Array","fill","forEach","pgw","max","Math","i","importance","toFixed","sort4FT","containedMarkings","array","set","Set","bow","freqTable","table","sort","bigrams","imax","bgs","unique","from","twps","trim","markedUpText","markings","offset","range","left","right","first","last","beginMarker","endMarker","vector","wordVectors","Error","size","dimensions","precision","vectors","l2NormIndex","v","numOfTokens","tv","toLowerCase","j","l2Norm","sqrt","DocDataWrapper","Doc","Cache","tokenizer","compileTRex","mappers","itsHelpers","asHelpers","mapRawTokens2UIdOfNormal","mapRawTokens2UIdOfDefaultPOS","Compiler","fsm","search","locate","helper","theModel","pipe","arguments","wordEmbeddings","trex","model","tokenize","nerAutomata","nerTransformers","sbdAutomata","sbdTransformers","sbdSetter","negAutomata","negSetter","saAutomata","saSetter","posAutomata","posTransformers","posSetter","posUpdater","cerAutomata","cerTransformer","cerPreserve","cerConfig","compiler","cerMetaModel","methods","cerLearnings","validAnnotations","currPipe","onlyTokenization","isObject","core","sbd","negation","sentiment","sa","ner","cer","metaCER","numOfKeys","wordVectorKeys","wordIndex","unkVector","words","key","tempPipe","isArray","at","featureFn","tcat","hash","preserve","sbdModel","machines","importJSON","transformers","setter","nerModel","negModel","saModel","posModel","updater","cmModel","load","readDoc","wrappedDocData","document","px","tokens4Automata","setPatternSwap","recognize","numOfSentences","posTags","useEntity","customEntities","doc","addons","clean","learnCustomEntities","examples","config","ex","JSON","stringify","name","patterns","mark","isIntegerArray","parse","matchValue","usePOS","compiled","run","learn","vectorOf","word","safe","sliceUpTo","xnMask","bits4PrecedingSpace","xcMask","bits4xpPointer","fTokenType","lexemesHash","features","lexeme","lxm","lexemeIntrinsicSize","intrinsicSize","layout","packing","pkSize","efSize","efList","efListSize","lexicon","xpansions","posClusters","list","extrinsicLexicon","elPackingSize","efArray","Uint32Array","feature","efHash","tokenType","ef","getFeaturesIndex","f","h","l","isNewValue","lookup","lemma","cc","cx","cxi","layout4isContraction","isContraction","layout4lemma","property","prop","propValue","oovIdx","layout4Prop","isMemberPOS","lexemeIdx","posIdx","add","category","cfg","fv","fv4p","normText","textIndex","normIndex","normal","layout4normal","layout4mapped","isSpellingMapped","nox","binaryWord","posOf","posValue","currentSize","isOOV","hasSamePOS","mappedSpelling","mappedIndex","reconstructSpaces","asf","mappedTkns","its4tokens","asfn","as4tokens","its4token","itemFn","result","token","spans","currIndex","leftToken","minIndex","maxIndex","edge","recTokenizer","categories","maxPrecedingSpaces","processFunctions","rgxCatDetectors","ltc","tokenizeRecursively","rgxAnyWithRP","helpers","anyWithRP","rgxAnyWithLP","anyWithLP","rgxLPanyRP","LPanyRP","rgxSplitter","splitter","detectTokenCategory","cat","test","unk","processDefault","precedingSpaces","nbsp","_addToken","match","splitCat","_addTokenIfInCache","rtc","punctuation","isLexeme","wordRP","tl","emoji","shortForm","number","url","email","mention","hashtag","emoticon","time","ordinal","currency","symbol","tabCRLF","apos","alpha","decade","rawTokens","nbSpaces","split","hasNBSP","a","b","prototype","toString","call","isFiniteInteger","n","isNaN","isFinite","round","sentence","its4sentence","negationFlag","regex","productReducer","prev","curr","c","cmax","pmax","concat","str","quotedTextElems","elements","matches","kmax","substr","extractEnclosedText","finalPatterns","console","warn","error","selection","rgxShortFormDot","rgxShortForm","rgxHyphens","rgxPeriod","rgxNumber","addToken","addTokenIfInCache","ps","pushHyphenatedToken","tkn","hyphens","prefix","suffix","pushWordToken","periods","currBuild","nextBuild","tokenizeTextRecursively","regexes","rgxSplit","balance","tag","tokenizeTextUnit","rgxs","pad","props","log","replace","colSelectedFn","filtered","consts","UNK","lemmaMask","xpSize","pow","containedEntities","getParentItem","colGetItemAt","selGetItemAt","colEach","selEach","colMap","selMap","colFilter","selFilter","itmTokenOut","selTokensOut","itmEntityOut","colEntitiesOut","selEntitiesOut","itmSentenceOut","colSentencesOut","itmDocumentOut","printTokens","docData","colEntities","colCustomEntities","colTokens","colSentences","colSelectedEntities","colSelectedCustomEntities","colSelectedTokens","itemToken","itemEntity","itemCustomEntity","itemSentence","contextualVectors","api","parentDocument","parentEntity","parentCustomEntity","markup","out","parentSentence","selectedTokens","each","itemAt","g","selectedEntities","selectedCustomEntities","specificWordVectors","similarWordVectors","wordVectorsLimit","Number","isInteger","awvs","docTokens","docTokensLemma","allUniqueTokens","similarWords","similarWordsScore","cwv","wv","distance","abs","w","Infinity","o","pipeConfig","mappedTokens","mapRawTokens2UIdOfValue","pk","makeRegexes","rgx","RegExp","message","data","idx","tokenIndex","item","case","uniqueId","contractionFlag","shape","stopWordFlag","abbrevFlag","stem","its4selTokens","as4selTokens","as4entities","as4selEntities","its4document","readabilityStats","sentenceWiseImportance","lm1","firstIndex","lastIndex","min","sents","composePatterns","identifyMarkedArea","token2Ignore","substitutions","onPatternDetectionFn","lastUsedState","terminalStates","markedStates","customPropertyAtStates","toBeIgnoredToken","keyLF","eosToken","otherwise","getNextState","target","learnSinglePattern","pattern","customProperty","ev","nextState","state","goBackTo","pushMatch2Patterns","m0","obj","cp","pi","all","ts","transformToken","param","lastOtherwiseIndex","lastOtherwiseState","transformTokenFn","ns","delta","setOnPatternDetectionFn","exportJSON","json","emptyModelJSON","printModel","selEntities","ents","ak","Automata","rgxOr","rgxPipe","mergeSplitsAndMatches","splts","mtchs","s0","splits","cerModel","encloseInSquareBracket","compileSimplePattern","values","normals","tokenizeText","replacements","tri0","ri1","ti","compileSinglePattern","atoms","findIndex","substring","st","compileOrPattern","ces","example","ce","currItemIndex","parentCollection","parentItemFn","kl","kr","ceil","floor","caseMap","swi","mappedIdx","lemmatize","spanItem","terms","tf","idf","docTermMatrix","dtm","id","docBOWArray","arr","modelJSON","docId","sumOfAllDLs","uid","selTokens","sentenceStart","sentenceEnd","contained"],"sourceRoot":""}